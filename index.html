<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>The health effects of demand side cost sharing in European health insurance</title>
<meta name="author" content="Jan Boone@@latex:\thanks{Tilburg University, Department of Economics, Tilec and CEPR, E-mail: \textit{j.boone@uvt.nl}.}@@" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" href="./latex-css/style.css">
<link rel="stylesheet" href="https://latex.now.sh/prism/prism.css">
<script src="https://cdn.jsdelivr.net/npm/prismjs/prism.min.js"></script>

<script src="http://orgmode.org/org-info.js">
// @license magnet:?xt=urn:btih:1f739d935676111cfff4b4693e3816e664797050&amp;dn=gpl-3.0.txt GPL-v3-or-Later
// @license-end
</script>

<script>
// @license magnet:?xt=urn:btih:1f739d935676111cfff4b4693e3816e664797050&amp;dn=gpl-3.0.txt GPL-v3-or-Later
org_html_manager.set("TOC_DEPTH", "3");
org_html_manager.set("LINK_HOME", "");
org_html_manager.set("LINK_UP", "");
org_html_manager.set("LOCAL_TOC", "1");
org_html_manager.set("VIEW_BUTTONS", "0");
org_html_manager.set("MOUSE_HINT", "underline");
org_html_manager.set("FIXED_TOC", "0");
org_html_manager.set("TOC", "1");
org_html_manager.set("VIEW", "info");
org_html_manager.setup();  // activate after the parameters are set
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">The health effects of demand side cost sharing in European health insurance</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org5d65201">How does this work?&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></a></li>
<li><a href="#org6cca007">preamble&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></a>
<ul>
<li><a href="#orgec839f2">loading data</a></li>
</ul>
</li>
<li><a href="#org01654de">1. Introduction</a>
<ul>
<li><a href="#org8ae1d48">1.1. Map&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></a></li>
</ul>
</li>
<li><a href="#orgd4eb45d">2. Theory</a>
<ul>
<li><a href="#org5ee7c77">2.1. parametric function&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></a></li>
</ul>
</li>
<li><a href="#org3d22ffe">3. Data</a>
<ul>
<li><a href="#org8fa56dd">3.1. data&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></a>
<ul>
<li><a href="#org269e9aa">3.1.1. standardizing data</a></li>
<li><a href="#orgbca2873">3.1.2. figure with extended age range</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org2f9546c">4. Estimation</a>
<ul>
<li><a href="#org182ae52">4.1. Empirical model</a></li>
<li><a href="#org4cd41d9">4.2. Bayesian estimation</a></li>
<li><a href="#org7889438">4.3. baseline model&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></a>
<ul>
<li><a href="#org1ff6026">4.3.1. model</a></li>
<li><a href="#org1841c09">4.3.2. run model and save trace</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org5836620">5. Results</a>
<ul>
<li><a href="#org6af2583">5.1. model fit</a></li>
<li><a href="#org526ef29">5.2. size of effects</a></li>
<li><a href="#org1b851f8">5.3. model fit and size of the effects&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></a>
<ul>
<li><a href="#orgd134383">5.3.1. reading in existing trace</a></li>
<li><a href="#org3d971ae">5.3.2. model fit</a></li>
<li><a href="#org40dcbe4">5.3.3. size of the effects</a></li>
<li><a href="#org1ca7642">5.3.4. comparing to other causes of death</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org67aa40e">6. Robustness checks</a>
<ul>
<li><a href="#org9f1dddb">6.1. code of the robustness checks&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></a>
<ul>
<li><a href="#orgb08cee5">6.1.1. Generating the samples</a></li>
<li><a href="#orgf841cca">6.1.2. creating Figure fig:robustness_summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org1190444">7. Discussion and policy implications</a></li>
<li><a href="#orgadf81b7">8. Bibliography</a></li>
<li><a href="#orgea6a12b">9. Proof of results</a></li>
<li><a href="#org4b0354e">10. Data</a></li>
<li><a href="#org11eafba">11. Estimation</a>
<ul>
<li><a href="#org1025c52">11.1. trace plots</a></li>
<li><a href="#org816174e">11.2. table of coefficients baseline model</a></li>
<li><a href="#orgadf9726">11.3. derivation of the effect of oop on mortality</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="abstract" id="orge8e5293">
<p>
The rationale for demand side cost sharing in health insurance is to deter patients from using low value care. But if agents are cash constrained, demand side cost sharing can lead them to postpone or forgo valuable treatments. We use data on European (NUTS 2) regions to show that the interaction between poverty rate and out-of-pocket payments leads to unmet medical needs and higher mortality.
</p>

</div>


<p>
<b>JEL codes:</b> I11, I13, I18
</p>

<p>
<b>Keywords:</b> out-of-pocket payments, mortality, health insurance, poverty, unmet medical needs
</p>




<div id="outline-container-org5d65201" class="outline-2">
<h2 id="org5d65201">How does this work?&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></h2>
<div class="outline-text-2" id="text-org5d65201">
<p>
With this document, any reader can retrace the code which we used to produce the results, figures, tables etc. for this paper.
</p>

<p>
This file is written in <a href="https://www.gnu.org/software/emacs/">Emacs</a> <a href="https://orgmode.org/">org mode</a> which allows us to combine text and code. The file is exported to pdf (via latex) and to html for the web-version. The web-version &#x2013;which you are reading now&#x2013; contains the sections tagged <code>code</code> which are not exported to the pdf version of the paper.
</p>

<p>
Here you can download <a href="./out_of_pocket_payments_and_health.pdf">the pdf of the paper</a>.
</p>

<p>
For the export to html we use <a href="https://github.com/vincentdoerig/latex-css">LaTeX.CSS</a> with some small tweaks to make it compatible with the org-exporter that we use which is based on <a href="https://github.com/jkitchin/org-ref">org-ref</a>. The export of the org file to html is almost perfect, but some issues are not yet resolved. To illustrate, the html export has trouble with latex environments like <code>align</code>, <code>split</code> in equations etc. For the time being this is resolved by using multiple <code>equation</code> environments. Further, whereas latex drops the label on equations that are not cited, the html exporter is not able to do this. Hence, there are more numbered equations in the web-version of the paper. This is all a bit clumsy but otherwise works fine.
</p>

<p>
We use <a href="https://www.python.org/">Python</a> to program the model and <a href="https://docs.pymc.io/">PyMC</a> for the Bayesian analysis. All these resources are open source and freely available. If you want to install Python, <a href="https://www.anaconda.com/products/individual">Anaconda</a> is a good place to start.
</p>

<p>
There is a separate <a href="./getting_data.html">file</a> which describes how we get the data from Eurostat.
</p>

<p>
The repository itself can be found <a href="https://github.com/janboone/out_of_pocket_payments_and_health">here</a>.
</p>
</div>
</div>

<div id="outline-container-org6cca007" class="outline-2">
<h2 id="org6cca007">preamble&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></h2>
<div class="outline-text-2" id="text-org6cca007">
<div class="org-src-container">
<pre class="src src-jupyter-python">  <span style="color: #89DDFF;">import</span> xarray <span style="color: #89DDFF;">as</span> xr
  <span style="color: #89DDFF;">import</span> numpy <span style="color: #89DDFF;">as</span> np
  <span style="color: #89DDFF;">import</span> pymc <span style="color: #89DDFF;">as</span> pm
  <span style="color: #89DDFF;">import</span> aesara.tensor <span style="color: #89DDFF;">as</span> at
  <span style="color: #89DDFF;">import</span> aesara
  <span style="color: #89DDFF;">import</span> pandas <span style="color: #89DDFF;">as</span> pd
  <span style="color: #89DDFF;">import</span> arviz <span style="color: #89DDFF;">as</span> az
  <span style="color: #89DDFF;">import</span> scipy <span style="color: #89DDFF;">as</span> sp
  <span style="color: #89DDFF;">import</span> seaborn <span style="color: #89DDFF;">as</span> sns
  <span style="color: #89DDFF;">import</span> matplotlib.pyplot <span style="color: #89DDFF;">as</span> plt
  plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
  <span style="color: #89DDFF;">from</span> country_codes <span style="color: #89DDFF;">import</span> eurostat_dictionary
  <span style="color: #89DDFF;">from</span> tabulate <span style="color: #89DDFF;">import</span> tabulate
</pre>
</div>
</div>

<div id="outline-container-orgec839f2" class="outline-3">
<h3 id="orgec839f2">loading data</h3>
<div class="outline-text-3" id="text-orgec839f2">
<p>
We read in the data. We drop rows (combination of calendar year, NUTS 2 region, age and gender) where mortality measures (<code>deaths</code>, <code>population</code> or <code>lagged_mortality</code>) or oop (<code>HF3_PC_CHE</code>) and fraction of population that postponed treatment because it was too expensive (<code>TOOEXP</code>) are missing.
</p>

<p>
We select ages between <code>age_min</code> and <code>age_max</code> and calendar years between <code>first_year</code> and <code>last_year</code>. We drop rows where the number of deaths during a year exceeds the population at January 1st in that age-gender-year-region category.
</p>

<p>
The file <a href="getting_data.html">file:./getting_data.org</a> in this repository provides the code for downloading the relevant data from the Eurostat website.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">age_min</span> = 35
<span style="color: #ffcb6b;">age_max</span> = 85
<span style="color: #ffcb6b;">age_range</span> = np.arange(age_max-age_min+1)[:,np.newaxis]
<span style="color: #ffcb6b;">plot_age</span> = np.arange(age_min,age_max+1)
<span style="color: #ffcb6b;">first_year</span> = 2009
<span style="color: #ffcb6b;">last_year</span> = 2019

<span style="color: #ffcb6b;">df</span> = pd.read_csv(<span style="color: #c3e88d;">'./data/data_deaths_by_age_nuts_2.csv'</span>)
<span style="color: #ffcb6b;">df</span>[<span style="color: #c3e88d;">'poverty'</span>] = df[<span style="color: #c3e88d;">'at risk of poverty'</span>]
<span style="color: #ffcb6b;">df</span>[<span style="color: #c3e88d;">'deprivation'</span>] = df[<span style="color: #c3e88d;">'percentage_material_deprivation'</span>]

df.dropna(subset=[<span style="color: #c3e88d;">'deaths'</span>,<span style="color: #c3e88d;">'population'</span>, <span style="color: #c3e88d;">'TOOEXP'</span>,\
                  <span style="color: #c3e88d;">'HF3_PC_CHE'</span>,<span style="color: #c3e88d;">'lagged_mortality'</span>],
                    axis=0, how =<span style="color: #c3e88d;">'any'</span>,inplace=<span style="color: #f78c6c;">True</span>)
df = df[(df.population &gt; df.deaths) &amp; (df.age &gt;= age_min) &amp; \
        (df.age &lt;= age_max) &amp; (df.year &lt;= last_year) &amp;\
        (df.year &gt;= first_year)]
df[<span style="color: #c3e88d;">'mortality'</span>] = df.deaths/df.population*100 \
    <span style="color: #676E95;"># </span><span style="color: #676E95;">mortality as a percentage</span>

<span style="color: #676E95;"># </span><span style="color: #676E95;">lagged mortality as fraction of mean lagged mortality</span>
<span style="color: #676E95;"># </span><span style="color: #676E95;">per age/gender group</span>
df[<span style="color: #c3e88d;">'lagged_mortality_s'</span>] = (df[<span style="color: #c3e88d;">'lagged_mortality'</span>])/\
    df.groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>])[<span style="color: #c3e88d;">'lagged_mortality'</span>].\
    transform(<span style="color: #c3e88d;">'mean'</span>)

df[<span style="color: #c3e88d;">'unmet'</span>] = df[<span style="color: #c3e88d;">'UNMET'</span>]
<span style="color: #82aaff;">len</span>(df)
</pre>
</div>


<pre class="example">
52612
</pre>
</div>
</div>
</div>


<div id="outline-container-org01654de" class="outline-2">
<h2 id="org01654de"><span class="section-number-2">1.</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
Most developed economies face rising healthcare expenditures. In many countries the healthcare sector grows faster than the economy as a whole (<a href="#citeproc_bib_item_22">OECD 2021</a>). One of the instruments that governments have to curb this expenditure growth is demand side cost sharing. The effect of demand side cost sharing on healthcare utilization is well known. As cost sharing increases, healthcare becomes more expensive for the individual and demand for treatments falls. It is less clear whether and to which extent demand side cost sharing induces people to forgo low value care only (<a href="#citeproc_bib_item_20">Newhouse and the Insurance Experiment Group 1993</a>; <a href="#citeproc_bib_item_24">Schokkaert and van de Voorde 2011</a>).
</p>

<p>
The traditional view is that health insurance subsidizes health consumption thereby inducing people to get (expensive) treatments with small health benefits. Economists tend to refer to this as moral hazard. As the social costs (in contrast to an individual's out-of-pocket &#x2013;oop&#x2013; expenditure) of such treatments exceed their value (utility gain), an increase in demand side cost-sharing that reduces moral hazard is seen as welfare enhancing. The traditional trade off is between this increase in efficiency (due to reduced moral hazard) and the increased oop risk faced by a risk averse agent.
</p>

<p>
Here we focus on behavioral hazard which refers to the case where cost-sharing leads patients to forgo valuable treatments (<a href="#citeproc_bib_item_2">Baicker, Mullainathan, and Schwartzstein 2015</a>). If a patient decides to skip a treatment where value exceeds costs then social welfare is reduced. In this paper, we concentrate on the case where people skip or postpone treatment because it is too expensive.
</p>

<p>
The goal of this paper is to develop a simple model that can be estimated with aggregate data to identify whether demand side cost sharing has negative health effects. In particular, we are interested in the mechanism where demand side cost sharing reduces health because valuable treatments become too expensive. We start from the following two ideas. First, if demand side cost sharing reduces valuable healthcare by making it (too) expensive, this effect will be stronger for people on low income. Health is a normal good and people with high (enough) income pay for valuable treatments even if they become expensive in terms of oop expenditure. Low income can force a patient to postpone or forgo treatment due to liquidity constraints. Second, if there is a substantial demand reduction for high value care, we should be able to detect this in aggregate mortality statistics.
</p>


<div id="org37ac9d8" class="figure">
<p><img src="./figures/Europe_mortality_40_F_2018.png" alt="Europe_mortality_40_F_2018.png" />
</p>
<p><span class="figure-number">Figure 1: </span>Mortality in NUTS 2 regions in Europe</p>
</div>

<p>
To identify the health effects of cost-sharing we use mortality statistics of Eurostat at the NUTS 2 (Nomenclature of Territorial Units for Statistics) regional level. Figure <a href="#org37ac9d8">1</a> illustrates NUTS 2 regions used in this paper. Mortality varies by region/year/age/sex. In regions where the percentage of people on low income is high and demand side cost sharing is high, we expect to see high mortality. Since we have panel data, we control for NUTS 2 fixed effects.
</p>

<p>
Measuring the generosity of a health insurance system is non-trivial. Systems tend to combine coinsurance with health expenditure caps, like a deductible. This leads to non-linearities in the oop price of healthcare. To address this, we introduce a model that links observed variables related to mortality, poverty, oop expenditures and people forgoing treatment because it is too expensive. The combination of the model and these variables allows us to identify the mechanism from reduced health insurance generosity via poverty to people forgoing treatment thereby raising mortality.
</p>

<p>
Figure <a href="#orgeff8d5d">2</a> summarizes our main results in the following way. For each country in our data, we consider the NUTS 2 region where poverty is highest and therefore the effect likely to be the strongest at the regional level. Using the estimated model, we simulate the effect of a 500 euro increase in oop on mortality. We report this effect as the increase in deaths (due to the increase in oop) per 1000 dead. The motivation for this measure is two-fold. First, mortality is &#x2013;thankfully&#x2013; low and hence the effect of a change in oop on mortality is going to be (very) small. Reporting the increase in mortality per 1000 dead helps to interpret the numbers. Below we also present this measure for diseases that have similar orders of magnitude, like pneumonia. Second, in our model this measure (per 1000 dead) is age-independent. That is, the number of people dying due to an increase in oop varies with age (as 25 year olds are less likely to die than 80 year olds). But the fraction of people dying due to the oop increase as a fraction of the total number of deceased is the same across age (and gender). This formulation reduces the number of parameters that we need to estimate and fits the data rather well.
</p>

<p>
The blue bars indicate the average simulated effect of the 500 euro increase for this region within each country; the black lines indicate the 95% probability interval of the effect. The four countries with the biggest effects &#x2013;Bulgaria, Greece, Hungary and Romania&#x2013; have the highest poverty levels in our sample. For these countries we can easily see that the 95% probability interval of the effect is bounded away from 0. For the Scandinavian countries, Slovenia and Switzerland the effects are close to zero at the region level because poverty is very low (even in the NUTS 2 region with highest poverty level per country). Another potential reason for small simulated effects is a government scheme targeted at the poor helping to finance healthcare expenditures. The poor then face lower oop than our country wide oop variable would suggest.
</p>


<div id="orgeff8d5d" class="figure">
<p><img src="./figures/change_mortality_countries_baseline.png" alt="change_mortality_countries_baseline.png" />
</p>
<p><span class="figure-number">Figure 2: </span>Increase in number of deaths per 1000 dead due to a 500 euro increase in oop for the region in each country where poverty is highest.</p>
</div>


<p>
The results suggest the following policy implications. An increase in oop has a measurable/significant effect on mortality in regions where poverty is high. Policies to address this include a scheme that subsidizes healthcare expenditure (on top of health insurance) for poor people; e.g. through means-tested cost-sharing. A downside of such a targeted intervention is a higher marginal tax rate at low income levels contributing to a poverty trap. Indeed, if by earning more, the oop subsidy falls, the increase in net income is reduced. This makes such an increase in income less attractive. Alternatively, a government can introduce co-payments that vary with the cost-effectiveness of the treatment. Treatments with high value added would then feature a low co-payment to prevent people from postponing valuable care. This can also help to reduce mortality associated with cost sharing (<a href="#citeproc_bib_item_7">Chernew et al. 2008</a>).
</p>

<p>
This is not the first paper to consider the effects of demand side-cost sharing on mortality. There is a string of recent papers using innovative methods and (mostly) individual level data to identify the causal effect of health insurance on health and mortality. There are a number of issues when identifying this effect of health insurance on health and mortality using individual level data. First, mortality is a rare event at most ages. Hence, identifying the effect is difficult, especially if the changes in oop are small. Second there is the selection effect that people with low health status tend to buy (generous) health insurance (as they expect high expenditure). This can bias results in the direction that individuals with (generous) insurance tend to have adverse health outcomes (e.g. high mortality). Moreover, cost-sharing tends to be non-linear with e.g. a cap on expenditures that have to be paid oop as with a deductible. In this case, people with high care use tend to face low (marginal) treatment prices; for example, because they filled up their deductible. As low health status is likely to increase care use, people facing low marginal prices (suggesting generous insurance) are likely to have experienced adverse health outcomes.
</p>

<p>
A number of papers use the Medicaid eligibility expansion of the Affordable Care Act which was introduced in different US states at different times. This allows for a diff-in-diffs identification strategy. Using individual level data, these papers have shown that the Medicaid expansion (more generous health insurance coverage) reduced mortality (<a href="#citeproc_bib_item_4">Borgschulte and Vogler 2020</a>; <a href="#citeproc_bib_item_19">Miller, Johnson, and Wherry 2021</a>). Other papers, focusing on particular causes of death, find similar results: the Medicaid expansion was associated with lower cardiovascular mortality in middle-aged adults (<a href="#citeproc_bib_item_15">Khatana et al. 2019</a>) and lower 1-year mortality among patients with ESRD initiating dialysis (<a href="#citeproc_bib_item_26">Swaminathan et al. 2018</a>).
</p>

<p>
Others analyze Medicare part D prescription drug coverage where the end-of-year price is non-linear in expenditure. One paper uses enrollment month (related to birth month) to get exogenous variation in end-of-year expenditure for people aged 65 (<a href="#citeproc_bib_item_6">Chandra, Flack, and Obermeyer 2021</a>). The main finding is that increases in the oop costs of drugs, reduce drug use including use of high value treatments. This, in turn, raises mortality. Another approach is to show that the implementation of Medicare Part D increased the use of drug treatments for cardiovascular disease which reduced mortality (<a href="#citeproc_bib_item_13">Huh and Reif 2017</a>). By using exogenous exit of plans in the Medicare Advantage market to control for endogeneity problems, it is possible to show that more generous prescription drug coverage leads to lower mortality  (<a href="#citeproc_bib_item_1">Abaluck et al. 2020</a>).
</p>

<p>
Finally, Goldin and coauthors use an experiment where a subset of people who should buy health insurance under the Affordable Care Act were reminded that they would face a financial penalty if they did not comply. This reminder tended to induce people to buy insurance instead of remaining uninsured (<a href="#citeproc_bib_item_11">Goldin, Lurie, and McCubbin 2020</a>). Mortality turns out to be lower among the people who received the reminder compared to the control group who were not reminded in this way.
</p>

<p>
Compared to these papers on health insurance (generosity) and mortality, our paper differs along the following lines. First, we use European instead of US data. The advantage is that within a European country health insurance is more homogeneous than in the US. Within a US state or county, people may have generous employer sponsored insurance, benefit from Medicaid or Medicare or have no insurance at all. Hence, a change in Medicaid coverage may have no detectable effects at the aggregate level (while an effect can be found with individual level data). In European countries a number of health insurance features are determined nationally. Consider the first two rows of the OECD Health Systems Characteristics Survey (<a href="https://qdd.oecd.org/data/HSC">https://qdd.oecd.org/data/HSC</a>) showing the share of the population obtaining basic primary health care coverage through automatic or compulsory insurance coverage. For all European countries this is above 90% and for most 99% or 100%. For the US this is less than one third. Hence, country or region wide statistics in Europe give a better picture of the situation applying to most citizens in that region than in the US.<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>
</p>

<p>
Moreover, individual level data sets tend to be within a country not across countries. But the variation in oop across countries tends to be bigger than within a country. Hence, across country data &#x2013;although aggregated at the region level&#x2013; helps us to identify the effect of oop on health and mortality.
</p>

<p>
Second, we show that mortality is high in regions where both oop and poverty are high. This follows the literature showing that healthcare consumption is liquidity sensitive (<a href="#citeproc_bib_item_12">Gross, Layton, and Prinz 2020</a>; <a href="#citeproc_bib_item_21">Nyman 2003</a>). People on low income tend to postpone or forgo valuable treatments if these are expensive. This focus on low incomes can imply that we under-estimate the mortality effect of cost-sharing if higher incomes also forgo valuable treatments due to oop (<a href="#citeproc_bib_item_5">Brot-Goldberg et al. 2017</a>; <a href="#citeproc_bib_item_6">Chandra, Flack, and Obermeyer 2021</a>). This is then not so much caused by liquidity problems but by other forms of behavioral hazard. In this sense, the results below are a lower bound on the mortality effects of cost-sharing.
</p>

<p>
Third, we use the regional structure of the Eurostat data. We analyze the effects of our oop variable times poverty interaction on mortality per age-gender class at the NUTS 2 regional level. This helps to solve the following potential endogeneity issue. A country with a population that has low health status (across ages), decides to have, say, generous health insurance to help people improve their health. This causal effect is in the opposite direction from the one we are interested in. We avoid this problem by considering within a country how health per region varies with oop and poverty, while using NUTS 2 fixed effects to correct for other factors affecting health. By analysing health/mortality per age cohort, our results are not affected by a country's or region's age distribution. By filtering out these other effects we mitigate power issues associated with the use of mortality data at the regional level (<a href="#citeproc_bib_item_3">Black et al. 2021</a>).
</p>

<p>
Fourth, Eurostat variables based on the EU-SILC survey allow us to zoom in on the relevant causal mechanism. This survey asks people whether they had unmet medical needs in the past months and if so the reason for the unmet needs. One of the answers is that treatment was postponed or skipped because it was too expensive. This allows us to simultaneously estimate the fraction of people in a NUTS 2 region that forgo treatment because it is too expensive and the effect of unmet medical needs on mortality. In this way, we capture that in regions where the oop \(\times\) poverty interaction is high, more people postpone treatment because it is too expensive and these unmet medical needs raise mortality in the region.
</p>

<p>
Finally, our focus on the oop \(\times\) poverty interaction distinguishes our paper from the literature on the effect of income and wealth on health (<a href="#citeproc_bib_item_8">Chetty et al. 2016</a>; <a href="#citeproc_bib_item_17">Mackenbach et al. 2008</a>; <a href="#citeproc_bib_item_25">Semyonov, Lewin-Epstein, and Maskileyson 2013</a>) where papers use cross country data. This literature typically finds that lower income and wealth is associated with lower health status, although the causal mechanism is not clear (<a href="#citeproc_bib_item_9">Cutler, Lleras-Muney, and Vogl 2011</a>). Two possible mechanisms are that higher income leads to more expenditure on treatments (normal good) and therefore better health. Alternatively, healthier people are more productive and earn higher incomes. The combination of fixed effects and the use of the survey question on unmet medical needs allows us to zoom in on the mechanism where high oop \(\times\) poverty interaction leads to unmet medical needs and hence to low health status and high mortality.
</p>

<p>
In this way, our approach does not suffer from the endogeneity problem with individual level data discussed above where low health status is correlated with generous insurance (at the margin). In our data, the unit of observation is a gender/age category at the regional level. The health status of such a unit, has (almost) no effect on our country wide oop variable.
</p>

<p>
Summarizing, compared to papers using individual level data our approach is more broad brush and less precise in estimating the size of the effect of insurance generosity on mortality. To illustrate, we do not determine the mortality effect of a 1% change in a deductible. We estimate the mortality effect of a 500 euro increase in oop. We do not have data on the oop details of each country's health insurance system, like what is the coinsurance rate for different types of treatments, which treatments are exempt from oop etc. Even if we had such detailed institutional data, it is not obvious how one would summarize the different systems in a way that makes them comparable across countries. Instead we use the fraction of oop payments in total healthcare expenditure, <code>OOP</code>, as a summary measure of a health insurance system's generosity. The theory section derives that <code>OOP</code> and the fraction of people postponing treatment because it is too expensive are parametric functions of the underlying "generosity parameters" coinsurance rate and deductible level. This derivation allows us to interpret the relation between <code>OOP</code> and mortality.
</p>

<p>
Although results based on aggregate data are less precise than those based on individual level data, our approach is more robust in the sense that it applies across a number of countries instead of a particular sub-population (like 65 year old Medicare users in the US). Although we do interpret our results using the size of the effect, our main goal is to establish that an increase in <code>OOP</code> in a poor region increases mortality. In particular, we quantify how sure we are that this effect is positive.
</p>

<p>
The next section presents a model explaining the relationship between the variables mortality, poverty, <code>OOP</code> and the fraction of people forgoing treatment because it is too expensive. Then we describe the Eurostat data that we use. We explain the empirical model that we estimate. Estimation results are presented for the baseline model and we show that these are robust with respect to a number of our modeling choices. We conclude with a discussion of the policy implications. The appendix contains the proofs of our results and more details on our data and estimation results. The <a href="https://janboone.github.io/out_of_pocket_payments_and_health/index.html">online appendix</a> is the html version of this paper which includes &#x2013;per section&#x2013; the python code that is used in each section's analysis.<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup> This is a final advantage of using data at the regional level. The repository contains the python code that gets the data from Eurostat so that each step of this analysis can be replicated. Most individual level data sets cannot be freely shared.
</p>
</div>

<div id="outline-container-org8ae1d48" class="outline-3">
<h3 id="org8ae1d48"><span class="section-number-3">1.1.</span> Map&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></h3>
<div class="outline-text-3" id="text-1-1">
<p>
As we use a different python kernel here from the one used in the rest of the paper (due to conflicting supporting packages at the time of the analysis), we need to import some libraries and the data again. We use <a href="https://geopandas.org/en/stable/">geopandas</a> to plot the map of the NUTS 2 regions where the color indicates mortality per 100k population.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #89DDFF;">import</span> numpy <span style="color: #89DDFF;">as</span> np
<span style="color: #89DDFF;">import</span> geopandas <span style="color: #89DDFF;">as</span> gpd
<span style="color: #89DDFF;">import</span> matplotlib.pyplot <span style="color: #89DDFF;">as</span> plt
plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
<span style="color: #89DDFF;">import</span> pandas <span style="color: #89DDFF;">as</span> pd
<span style="color: #676E95;"># </span><span style="color: #676E95;">import altair as alt</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #676E95;"># </span><span style="color: #676E95;">read the NUTS shapefile and extract</span>
<span style="color: #676E95;"># </span><span style="color: #676E95;">the polygons for a individual countries</span>
<span style="color: #ffcb6b;">nuts</span>=gpd.read_file(<span style="color: #c3e88d;">'./SHP/NUTS_RG_60M_2021_4326_LEVL_2.shp'</span>)

<span style="color: #ffcb6b;">age_min</span> = 35
<span style="color: #ffcb6b;">age_max</span> = 85
<span style="color: #ffcb6b;">plot_age</span> = np.arange(age_min,age_max+1)
<span style="color: #ffcb6b;">first_year</span> = 2009
<span style="color: #ffcb6b;">last_year</span> = 2019
<span style="color: #ffcb6b;">df</span> = pd.read_csv(<span style="color: #c3e88d;">'./data/data_deaths_by_age_nuts_2.csv'</span>)
df.dropna(subset=[<span style="color: #c3e88d;">'deaths'</span>,<span style="color: #c3e88d;">'population'</span>, <span style="color: #c3e88d;">'TOOEXP'</span>,\
                  <span style="color: #c3e88d;">'HF3_PC_CHE'</span>,<span style="color: #c3e88d;">'lagged_mortality'</span>],
                    axis=0, how =<span style="color: #c3e88d;">'any'</span>,inplace=<span style="color: #f78c6c;">True</span>)
df = df[(df.population &gt; df.deaths) &amp; (df.age &gt;= age_min) &amp; \
        (df.age &lt;= age_max) &amp; (df.year &lt;= last_year) &amp;\
        (df.year &gt;= first_year)]
df[<span style="color: #c3e88d;">'mortality'</span>] = df.deaths/df.population*100000
df = df[(df.year==2018) &amp; (df.age==40) &amp; (df.sex==<span style="color: #c3e88d;">'F'</span>)]


nuts = nuts.to_crs(epsg=3035)
nuts[<span style="color: #c3e88d;">'centroids'</span>] = nuts.centroid
nuts = nuts.merge(df, how=<span style="color: #c3e88d;">'inner'</span>,\
                  left_on = <span style="color: #c3e88d;">'NUTS_ID'</span>, right_on = <span style="color: #c3e88d;">'nuts2'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python">nuts[nuts.sex==<span style="color: #c3e88d;">'F'</span>].plot(column=<span style="color: #c3e88d;">'mortality'</span>,
                         legend=<span style="color: #f78c6c;">True</span>,
                         figsize=(16,16),
                         <span style="color: #676E95;"># </span><span style="color: #676E95;">vmin = 71,</span>
                         vmax = 0.002*100000,
                         missing_kwds={<span style="color: #c3e88d;">'color'</span>: <span style="color: #c3e88d;">'lightgrey'</span>},
                         legend_kwds={<span style="color: #c3e88d;">'label'</span>: <span style="color: #c3e88d;">"Mortality rate"</span>,
                                      <span style="color: #c3e88d;">'orientation'</span>: <span style="color: #c3e88d;">"vertical"</span>})
<span style="color: #676E95;"># </span><span style="color: #676E95;">adjust plot domain to focus on EU region</span>
plt.xlim(0.25e7, 0.6e7)
plt.ylim(1.3e6, 5.5e6)
plt.xticks([],[])
plt.yticks([],[])
plt.title(\
  <span style="color: #c3e88d;">'Mortality 40 year old females in 2018 (per 100,000 population)'</span>);
<span style="color: #676E95;"># </span><span style="color: #676E95;">plt.tight_layout()</span>
<span style="color: #676E95;"># </span><span style="color: #676E95;">plt.legend('right');</span>
</pre>
</div>


<div id="orgefade54" class="figure">
<p><img src="./figures/Europe_mortality_40_F_2018.png" alt="Europe_mortality_40_F_2018.png" />
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-orgd4eb45d" class="outline-2">
<h2 id="orgd4eb45d"><span class="section-number-2">2.</span> Theory</h2>
<div class="outline-text-2" id="text-2">
<p>
The relevant variables in our data are mortality per region/year/age/sex category, <code>OOP</code> measuring the percentage of healthcare expenditure paid out-of-pocket (oop), the poverty rate and the fraction of people per region postponing or forgoing treatment because it is too expensive. We introduce a model to explain how these variables are related.
</p>

<p>
Consider a population (of a certain age and gender) in an EU region where a fraction \(\alpha \in \langle 0,1 \rangle\) has low income \(l\) and fraction \(1-\alpha\) high income \(h\). Let \(\pi^j\) denote the probability that someone with income \(j=l,h\) falls ill. As is well known, low income people tend to have a lower health status (<a href="#citeproc_bib_item_9">Cutler, Lleras-Muney, and Vogl 2011</a>). We capture this by assuming \(\pi^l > \pi^h\). People on low income may have a less healthy diet, exercise less etc. due to either the cost of or knowledge about healthy lifestyle choices. This makes it more likely that they fall ill.
</p>

<p>
Generally speaking, oop payments tend to take two forms that we want to capture: a coinsurance rate, which we denote \(\xi \in [0,1]\), and a maximum expenditure, which we denote \(D\) (for deductible). Some systems have a combination of the two.
</p>

<p>
Conditional on falling ill, there is a probability \(\zeta_i \in [0,1]\) that the patient is advised to get treatment \(i\) at cost \(x_i\) for \(i\) in the set of "illnesses" \(I\). We define \(I_{\xi}\) as the subset of \(I\) where \(\xi x_i < D\) and \(oop_i = \xi x_i\) and set \(I_D\) where \(\xi x_i \geq D\) and \(oop_i = D\). To keep things simple, we assume that \(\zeta_i\) is exogenous to the patient. We model the treatment decision on the extensive margin only: an agent accepts or rejects the treatment proposed by a physician.<sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup> A pure coinsurance system has \(\xi < 1\) and \(I_{\xi}=I\). A pure deductible system \(\xi=1\) and \(I_D\) non-empty. A combination of the two has \(\xi<1\) and there is a maximum on the oop payment. Health insurance systems in Europe tend to have such maximum oop expenditure.<sup><a id="fnr.4" class="footref" href="#fn.4" role="doc-backlink">4</a></sup> An increase in either \(\xi\) or \(D\) is interpreted as making health insurance less generous.
</p>

<p>
Whereas with individual level data one can determine whether an individual faces a positive treatment price at the margin (E.g. using the end-of-year price as in <a href="#citeproc_bib_item_14">Keeler, Newhouse, and Phelps 1977</a>; <a href="#citeproc_bib_item_10">Ellis 1986</a>), this is not possible with the aggregate data that we use here. Hence, we rely on an aggregate summary variable, denoted <code>OOP</code>, measured as oop payments over total healthcare expenditure. That is, the fraction of healthcare expenditure paid by patients oop. We interpret this variable as capturing the generosity of the health insurance system. To illustrate, if healthcare is free at point of service, <code>OOP</code> equals zero; if there is no health insurance at all, <code>OOP</code> equals 1. In a pure coinsurance system with rate \(\xi\) applying to all treatments, <code>OOP</code> equals \(\xi\). It is the cap on oop expenditure (like a deductible) that complicates the relation between <code>OOP</code> and healthcare use. The challenge then is to capture changes in \(\xi\) and \(D\) although we do not directly observe these variables in the data. This is what the model sets out to do.
</p>

<p>
If a patient receives treatment \(i \in I\), we denote her (expected) health \(\sigma_i\), while without treatment (expected) health equals \(\sigma_0\) with \(0 \leq \sigma_0 < \sigma_i \leq 1\).<sup><a id="fnr.5" class="footref" href="#fn.5" role="doc-backlink">5</a></sup> Health is normalized at value one for a patient who does not fall ill. The trade off between health and oop is captured by \(\sigma_0/\sigma_i <1\) and we simply assume that utility is multiplicative in health and consumption. That is, consumption yields higher utility if you are healthier. We model the patient's treatment decision as:
</p>
\begin{equation}
\label{org7138fee}
\nu \sigma_i u(y^j-oop_i) > \sigma_0 u(y^j)
\end{equation}
<p>
where utility \(u(.)\) is determined by how much money can be spent on other goods: income \(y^j\) minus oop in case of treatment and \(y^j\) if no treatment is chosen. The utility function \(u(.)\) is increasing and concave in consumption: \(u(.), u'(.) >0\) and \(u''(.) < 0\). Further, parameter \(\nu\) captures other factors than pure financial ones affecting a patient's treatment choice.<sup><a id="fnr.6" class="footref" href="#fn.6" role="doc-backlink">6</a></sup>
</p>

<p>
In our data, we have a variable "unmet medical needs" based on a number of motivations: treatment is too far away to travel to, there is a long waiting list, the patient is scared to undergo treatment etc. To make our point, it is enough to assume that such factors affect utility in a simple multiplicative way. To illustrate, if the patient has to travel far for treatment, utility is reduced by multiplying it with a value of \(\nu < 1\). Agents differ in \(\nu\) and the cumulative distribution function of \(\nu\) is given by \(G(\nu)\) and its density function by \(g(\nu)\). Other factors can include waiting time till treatment, belief that the condition will resolve itself without intervention, poor decision making e.g. with a focus on the short term thereby undervaluing the benefit of treatment. If inequality \eqref{org7138fee} holds, the agent accepts the treatment. For some proofs in the appendix it is convenient to assume that \(G\) is a Pareto distribution.
</p>

<p>
The probability that a patient with income \(y^{j}\) accepts treatment \(i\) offered by a physician equals
</p>
\begin{equation}
\label{orgdf27748}
\delta_i^j = 1-G\left( \frac{\sigma_0}{\sigma_i} \frac{u(y^{j})}{u(y^{j}-oop_i)} \right)
\end{equation}
<p>
that is, \(\nu\) is big enough that inequality \eqref{org7138fee} holds. With probability \(G\left( \frac{\sigma_0}{\sigma_i} \frac{u(y^{j})}{u(y^{j}-oop_i)} \right)\) the patient decides to postpone or forgo treatment \(i\).
</p>

<p>
The probability that a patient postpones or skips a treatment because it is too expensive is given by
</p>
\begin{equation}
\label{orgb7a8ac7}
G\left( \frac{\sigma_0}{\sigma_i} \frac{u(y^{j})}{u(y^{j}-oop_{i})} \right) - G\left( \frac{\sigma_0}{\sigma_i} \right)
\end{equation}
<p>
These are agents \(\nu\) that would have chosen treatment \(i\) if it were free (\(oop_{i}=0\) and \(u(y^j)/u(y^j-oop_i)=1\)) but who forgo treatment now that it costs \(oop_{i}>0\). The probability \(G(\sigma_{0}/\sigma_{i})\) captures factors like waiting lists or the patient hoping that the health problems resolve themselves without treatment. That is, reasons for postponing treatment not related to oop payments.
</p>

<p>
In the proof of the lemma at the end of this section, we show that the probability of accepting treatment, \(\delta_i^j\), is increasing in income \(y^j\) and decreasing in \(oop_{i}\), as one would expect.
</p>

<p>
Note that this model differs from a standard Rothschild and Stiglitz &#x2013;R&amp;S&#x2013; health insurance model (<a href="#citeproc_bib_item_23">Rothschild and Stiglitz 1976</a>) in the following way. In an R&amp;S model income plays no role and people with low health status have generous insurance coverage. Hence, they would not postpone valuable care. In our model, people with low health tend to have low income and may skip valuable treatment if the oop expense is high. This negatively affects their health.
</p>

<p>
An agent's health is affected by the probability of falling ill and then getting treatment (or not). We assume that agents' mortality is affected by health in the following way, where we define mortality \(m\) as the probability of dying in a given period.
</p>
\begin{equation}
\label{orgae11a42}
\ln(m_{agt}) = \ln({\eta}_{ag}) + \gamma \ln \left( \frac{m_{a-1,g,t-1}}{\bar m_{a-1,g}}\right) - (\alpha (1-\pi^l) + (1-\alpha) (1-\pi^{h})) \end{equation}
\begin{equation*}
 - \alpha \pi^l \sum_{i \in I} \zeta_i (\delta_i^l \sigma_i + (1-\delta_i^l)\sigma_0) - (1-\alpha) \pi^h \sum_{i \in I} \zeta_i (\delta_i^h \sigma_i + (1-\delta_i^h) \sigma_0)
\end{equation*}
<p>
where we use the following subscripts: age \(a\), gender \(g \in \{f,m\}\), calendar year \(t\). In words, log mortality in a region depends on the biology of age and gender, \(\eta_{ag}\). As people get older, they tend to become less healthy and are more likely to die. We define this effect as independent of country or year (in the period that we analyze). Then there are a number of effects that increase or decrease mortality in a region compared to \(\eta_{ag}\).
</p>

<p>
The health of the age-gender cohort in the previous period: if in a NUTS 2 region there was a shock in \(t-1\) &#x2013;when this cohort was aged \(a-1\) &#x2013; that increased mortality above the average (across years and regions) mortality for this cohort, we interpret this as a negative health shock. For the people that survived in this cohort in this region, this health shock can affect their mortality in period \(t\). This is captured by the coefficient \(\gamma\).<sup><a id="fnr.7" class="footref" href="#fn.7" role="doc-backlink">7</a></sup>
</p>

<p>
People who do not fall ill \((\alpha(1-\pi^l)+(1-\alpha)(1-\pi^h))\), have the highest health level (normalized to 1) and hence reduce mortality to the biggest extend. People who do fall ill with \(i\) and get treatment (\(\alpha \pi^l \zeta_i \delta_i^l\) and \((1-\alpha)\pi^h \zeta_i \delta_i^h\)), get health \(\sigma_i \leq 1\) and reduce mortality to a smaller extent. Finally, people falling ill but forgoing treatment lead to the smallest reduction \(\sigma_0\) in mortality.
</p>

<p>
As we show in the proof of the lemma below, we can write the expression for log mortality as:
</p>
\begin{equation}
\label{org3dd0d6e}
\ln(m_{ag2t}) =\ln ( \eta_{ag}) + \mu_2 + \gamma \ln \left( \frac{m_{a-1,2,g,t-1}}{\bar m_{a-1,g}}\right) + \beta_{poverty}\alpha_{2t} + \beta_{unmet}\text{Unmet}_{2t}
\end{equation}
<p>
where subscript \(2\) indicates that the variable varies with NUTS 2 region, \(\mu_2\) denotes NUTS 2 fixed effects, poverty \(\alpha\) varies with NUTS 2 region and calendar year and <code>Unmet</code> denotes the fraction of people indicating unmet medical needs in a region in year \(t\).
</p>

<p>
In our data, the variable <code>Unmet</code> varies with NUTS 2 region and year and not by age or gender. Hence, in terms of our model, we define this variable as follows:
</p>
\begin{equation}
\label{orgd543365}
\text{Unmet}_{2t} = \sum_{i \in I} \zeta_i (\alpha_{2t} \pi^l (1-\delta^l_{ict}) + (1-\alpha_{2t}) \pi^h (1-\delta^h_{ict}))
\end{equation}
<p>
with treatment probability \(\delta^j_i\) varying with country \(c\) and year \(t\) because oop varies with countries over time.
</p>

<p>
Further, in our data we have the variable <code>OOP</code>  defined as oop payments as a percentage of healthcare expenditure. In terms of our model, we write this as
</p>
\begin{equation}
\label{org458b67f}
\text{OOP} = \frac{\sum_{i \in I} \zeta_i oop_i (\alpha \pi^l \delta^l_i + (1-\alpha) \pi^h \delta^h_i)}{\sum_{i \in I} \zeta_i x_i (\alpha \pi^l \delta_i^l + (1-\alpha) \pi^h \delta_i^h) }
\end{equation}
<p>
where \(\zeta_i (\alpha \pi^l \delta^l_i + (1-\alpha) \pi^h \delta^h_i)\) denotes the fraction of people accepting treatment \(i\). The numerator of <code>OOP</code> contains the oop payments \(oop_{i}\) and the denominator expenditures \(x_i\). If \(I_{\xi} = I\), it is clear that \(\text{OOP} = \xi\). Because \(I_D\) is non-empty (European countries have a maximum oop payment), the expression for <code>OOP</code> is actually non-trivial. We can also write <code>OOP</code> as the ratio of average <code>oop</code> per head and average healthcare expenditure per head:
</p>
\begin{equation}
\label{orgbdcdaa6}
\text{OOP}_{ct} = \frac{\overline{oop}_{ct}}{\bar{x}_{ct}}
\end{equation}
<p>
In our data these variables vary by country and year.
</p>

<p>
Finally, using equation \eqref{orgb7a8ac7} our model allows us to formalize the fraction of people that forgo treatment because it is too expensive: fraction of poor people who need treatment, \(\alpha \pi^l\), forgoing treatment because it is too expensive plus the fraction of rich people, \((1-\alpha)\pi^h\), forgoing treatment for this reason:
</p>
\begin{equation}
\label{org040d6f1}
\text{TooExp} = \alpha \pi^l (\sum_{i \in I}\zeta_{i} \left(G\left( \frac{\sigma_0}{\sigma_i} \frac{u(y^{l})}{u(y^{l}-oop_{i})} \right) - G\left( \frac{\sigma_0}{\sigma_i} \right) \right )
\end{equation}
\begin{equation*}
 + (1-\alpha) \pi^h (\sum_{i \in I}\zeta_{i} \left(G\left( \frac{\sigma_0}{\sigma_i} \frac{u(y^{h})}{u(y^{h}-oop_{i})} \right) - G\left( \frac{\sigma_0}{\sigma_i} \right) \right )
\end{equation*}

<p>
In our data, <code>TooExp</code> varies with Nuts 2 region and year. The following lemma summarizes the main results from the model and presents the equations that we estimate below. The innovation is to view equations \eqref{orgbdcdaa6} and \eqref{org040d6f1} as being parametrized by the underlying parameters \(\xi\) and \(D\) which are not directly observed in our data. We prove that this leads to an equation where <code>TooExp</code> is a function of <code>OOP</code> and poverty.
</p>

<div class="lemma" id="orgeb785f9">
<p>
Healthcare demand \(\delta = 1-G(.)\) is increasing in income \(y^j\) and decreasing in \(oop_i\) (\(\xi\) or \(D\)). We write the expression for gender <code>g</code> mortality of age cohort <code>a</code> in Nuts 2 region <code>2</code> at time <code>t</code> as:
\[
m_{ga2t} = \frac{e^{\beta_{ag}}}{1+e^{\beta_{ag}}} e^{\left( \mu_2 + \gamma \ln \left(\frac{m_{a-1,g,2,t-1}}{\bar{m}_{a-1,g}}\right)+ \beta_{poverty}\text{Poverty}_{2t} + \beta_{unmet}\text{Unmet}_{2t}\right)}
\]
where \(\beta_{poverty}, \beta_{unmet} > 0\). The linear expansion of <code>TooExp</code> with respect to <code>OOP</code> can be written as
\[
\text{TooExp}_{2t} = b_{0,2} + b_{0,t} + \text{OOP}_{ct} \bar{x}_{ct} \left(  b_{oop,c} + b_{interaction,c} \text{Poverty}_{2t} \right)
\]
</p>

</div>

<p>
We model \({\eta}_{ag}\) as a sigmoid of age and gender fixed effects, \(\beta_{ag}\). This makes sure this part of the probability of death is between 0 and 1. We multiply this baseline probability with a multiplier capturing the other effects. In particular, NUTS 2 region fixed effects which capture regional variation in the probability of falling ill. Whether this age cohort experienced a health shock in the previous period. Poverty level and the fraction of people with unmet medical needs in the region in year \(t\). If the sum of these terms is negative, the multiplier is less than 1 and mortality for this gender/age/region/year combination is reduced compared to the baseline probability given by the sigmoid. If the sum of the terms is positive, mortality for this observation is higher than the baseline probability.
</p>

<p>
We use a linear expansion of <code>TooExp</code> in terms of <code>OOP</code>. The appendix shows how we derive this relation using the policy variables \(\xi\) and \(D\) which affect <code>OOP</code> and <code>TooExp</code> simultaneously. It turns out that there is a direct effect of <code>OOP</code> on <code>TooExp</code> and an interaction effect with the fraction of people below the poverty line in a region. We show that \(b_{oop},b_{interaction} > 0\): a region that lies in a country with high <code>OOP</code> tends to have high unmet needs and especially so if the region features a high poverty rate. As explained in the proof of the lemma, the linear expansion of <code>TooExp</code> in <code>OOP</code> and <code>OOP</code> \(\times\) Poverty interaction does not determine the intercept \(b_{0}\). Therefore, we allow \(b_0\) to vary by region and year: \(b_{0,2} + b_{0,t}\).
</p>

<p>
Figure <a href="#org80d8912">3</a> illustrates this approximation of the relation between (log-odds) <code>TooExp</code> and <code>OOP</code> for simulated values in the model above. We simulate data for a country with varying values for \(\xi\) and \(D\). Then both <code>OOP</code> and expenditure per head vary leading to the graph in the left panel of Figure <a href="#org80d8912">3</a> (see web appendix for details). For this simulated data, the approximation where the (log odds of) fraction of people forgoing treatment because it is too expensive depends linearly on <code>OOP</code> \(\times\) Poverty seems reasonable. As shown in the proof of the lemma, we need to multiply <code>OOP</code> and <code>OOP</code> \(\times\) Poverty by healthcare expenditure per head because the underlying changing variable is not the endogenous <code>OOP</code> but the parameters \(\xi\) and \(D\). As illustrated in equation \eqref{orgbdcdaa6}, the relation between changes in \(D\) and <code>OOP</code> is multiplied by expenditure per head: \(d \text{OOP}/d D \propto 1/\bar{x}_{ct}\).
</p>


<div id="org80d8912" class="figure">
<p><img src="./figures/Parametric3.png" alt="Parametric3.png" />
</p>
<p><span class="figure-number">Figure 3: </span>The simulated relation between fraction of people who forgo treatment because it is too expensive and <code>OOP</code> measure for different values of \(\xi\), \(D\) (left panel) and this relation for NUTS 2 regions and years in Romania (right panel).</p>
</div>

<p>
The right panel of Figure <a href="#org80d8912">3</a> illustrates this relation for regional data from Romania. Again a linear approximation looks reasonable. The size of the dots indicates the level of <code>OOP</code> for that observation. To identify the colors for the different Romanian regions, a color version of the pdf (or the website) is useful.
</p>
</div>


<div id="outline-container-org5ee7c77" class="outline-3">
<h3 id="org5ee7c77"><span class="section-number-3">2.1.</span> parametric function&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></h3>
<div class="outline-text-3" id="text-2-1">
<p>
This section illustrates with two figures the relation between the fraction of people with unmet medical needs due to financial constraints, <code>TooExp</code>, and our variable measuring how generous a health insurance system is, <code>OOP</code>. We illustrate this using data simulated from the model and for one country, Romania, in our data set.
</p>

<p>
As we assume that <code>TooExp</code> has a logit-normal distribution, we plot the log-odds of <code>TooExp</code> both for Romania and for our simulated data.
</p>

<p>
We plot these log-odds on the vertical axis and the interaction term <code>OOP*Poverty</code> on the vertical axis.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python">  <span style="color: #ffcb6b;">df_RO</span> = df[df.country==<span style="color: #c3e88d;">'Romania'</span>]
  df_RO[<span style="color: #c3e88d;">'OOP'</span>] = df_RO[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]/100
  df_RO[<span style="color: #c3e88d;">'interaction'</span>] = df_RO[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]*\
      df_RO[<span style="color: #c3e88d;">'deprivation'</span>]/(100*100)
  df_RO[<span style="color: #c3e88d;">'tooexp'</span>] = df_RO[<span style="color: #c3e88d;">'TOOEXP'</span>]/100
  df_RO[<span style="color: #c3e88d;">'tooexp_lo'</span>] = np.log((df_RO[<span style="color: #c3e88d;">'TOOEXP'</span>]/100)/\
                              (1-(df_RO[<span style="color: #c3e88d;">'TOOEXP'</span>]/100)))
</pre>
</div>

<p>
We use our model to simulate this parametric relation between <code>TooExp</code> and <code>OOP*Poverty</code> by varying the underlying exogenous parameters \(\xi\) and \(D\). As this is just used as illustration, we specify simple/straightforward functions for utility \(u\) and cumulative distribution function \(G\).
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python">  <span style="color: #ffcb6b;">&#945;</span> = 0.2
  <span style="color: #ffcb6b;">&#950;</span> = 0.25
  <span style="color: #ffcb6b;">x1</span> = 5000
  <span style="color: #ffcb6b;">x0</span> = 400
  <span style="color: #ffcb6b;">&#963;_x</span> = 0.8
  <span style="color: #ffcb6b;">&#963;_0</span> = 0.3
  <span style="color: #ffcb6b;">&#960;_l</span> = 0.3
  <span style="color: #ffcb6b;">&#960;_h</span> = 0.1
  <span style="color: #ffcb6b;">y_h</span> = 20000
  <span style="color: #ffcb6b;">y_l</span> = 3000

  <span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">u</span>(y):
      <span style="color: #89DDFF;">return</span> np.sqrt(y)
  <span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">G</span>(y,oop):
      <span style="color: #89DDFF;">return</span> 1-np.exp(-1*(&#963;_0/&#963;_x * u(y)/u(y-oop)))
  <span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">oop</span>(&#958;,D,y):
      <span style="color: #89DDFF;">return</span> (&#950;*&#958;*(1-G(y,&#958;*x0))*x0+(1-&#950;)*(1-G(y,D))*D)
  <span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">expend</span>(&#958;,D,y):
      <span style="color: #89DDFF;">return</span> (&#950;*(1-G(y,&#958;*x0))*x0+(1-&#950;)*(1-G(y,D))*x1)
  <span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">Expend</span>(&#958;,D,&#945;,&#960;_l):
      <span style="color: #89DDFF;">return</span> &#945;*&#960;_l*expend(&#958;,D,y_l)+(1-&#945;)*&#960;_h*expend(&#958;,D,y_h)
  <span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">OOP</span>(&#958;,D,&#945;,&#960;_l):
      <span style="color: #89DDFF;">return</span> (&#945;*&#960;_l*oop(&#958;,D,y_l)+(1-&#945;)*&#960;_h*oop(&#958;,D,y_h))/\
          Expend(&#958;,D,&#945;,&#960;_l)
  <span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">TooExp</span>(&#958;,D,&#945;,&#960;_l):
      <span style="color: #89DDFF;">return</span> &#945;*&#960;_l*(&#950;*(G(y_l,&#958;*x0)-G(y_l,0))+\
                    (1-&#950;)*(G(y_l,D)-G(y_l,0)))+\
                    (1-&#945;)*&#960;_h*(&#950;*(G(y_h,&#958;*x0)-G(y_h,0))+\
                               (1-&#950;)*(G(y_h,D)-G(y_h,0)))

  <span style="color: #ffcb6b;">range_D</span> = np.arange(500, 2500,75)[:,<span style="color: #f78c6c;">None</span>]
  <span style="color: #ffcb6b;">range_&#958;</span> = (np.arange(0.4,1.00,0.1))[<span style="color: #f78c6c;">None</span>,:]

  <span style="color: #ffcb6b;">Y1</span> = TooExp(range_&#958;,range_D,&#945;,&#960;_l).flatten()+\
      np.random.normal(0,0.0015,size=range_D.shape[0]*range_&#958;.shape[1])
  Y1_lo = np.clip(np.log(Y1*10/(1-Y1*10)),-5.0,1)
  oop_1 = OOP(range_&#958;,range_D,&#945;,&#960;_l).flatten()
  X1 = oop_1*&#945;
  Z1 = Expend(range_&#958;,range_D,&#945;,&#960;_l).flatten()*X1

  plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
  fig, (<span style="color: #ffcb6b;">ax1</span>,<span style="color: #ffcb6b;">ax2</span>) = plt.subplots(1, 2, sharex=<span style="color: #f78c6c;">True</span>,\
                                sharey=<span style="color: #f78c6c;">True</span>,dpi=140,figsize=(14,6))

  fig.suptitle(<span style="color: #c3e88d;">'Relation between OOP $\\times$ Poverty and TooExp'</span>)
  ax1.scatter(X1,Y1_lo,s=oop_1*90)
  ax1.set_xlabel(<span style="color: #c3e88d;">'OOP $\\times$ Poverty'</span>)
  ax1.set_ylabel(<span style="color: #c3e88d;">'log odds TooExp'</span>)
  ax1.set_title(<span style="color: #c3e88d;">'Simulated data'</span>)
  ax1.set_ylim(-4.5,-1.5)
  fig2 = sns.scatterplot(ax=ax2,data = df_RO, \
                         x = <span style="color: #c3e88d;">'interaction'</span>,y=<span style="color: #c3e88d;">'tooexp_lo'</span>,\
                         hue=<span style="color: #c3e88d;">'nuts2'</span>,size=<span style="color: #c3e88d;">'OOP'</span>)
  fig2.<span style="color: #82aaff;">set</span>(xlabel = <span style="color: #c3e88d;">'OOP $\\times$ Poverty'</span>, \
           ylabel = <span style="color: #c3e88d;">'TooExp'</span>, title = <span style="color: #c3e88d;">'Romania'</span>);
</pre>
</div>

<pre class="example">
/tmp/ipykernel_136527/144876270.py:36: RuntimeWarning: invalid value encountered in log
  Y1_lo = np.clip(np.log(Y1*10/(1-Y1*10)),-5.0,1)
</pre>


<div id="org2170186" class="figure">
<p><img src="./figures/Parametric3.png" alt="Parametric3.png" />
</p>
</div>
</div>
</div>
</div>



<div id="outline-container-org3d22ffe" class="outline-2">
<h2 id="org3d22ffe"><span class="section-number-2">3.</span> Data</h2>
<div class="outline-text-2" id="text-3">
<p>
The data that we use is from <a href="https://ec.europa.eu/eurostat/web/regions/data/database">Eurostat's regional database</a> and provides for NUTS 2 regions population size and number of deaths per age-gender category. In principle, we have data on 14 countries and 78 NUTS 2 regions for the years 2009-2019, ages 35-85 for women and men. The years 2009-2019 were chosen  because, at the time of the analysis, data on poverty was available from 2009 onward and data on the <a href="https://ec.europa.eu/eurostat/databrowser/view/demo_r_magec/default/table?lang=en">number of deaths</a> ran till 2019. We start at age 35 because at ages below 35, mortality is so low that there is hardly a difference between mortality in regions with different poverty levels (see Figure <a href="#orgc210112">4</a> below). For ages above 85 population numbers per region get rather low. We drop NUTS 2 region-year combinations where for an age-gender category &#x2013;due to reporting issues or people moving&#x2013; the number of deaths in a year exceeds the population size at the start of the year. For the baseline analysis, we focus on observations where we have complete records on mortality, the fraction of people indicating they postponed treatment because it was too expensive and oop expenditure. We come back to this in the robustness analysis where we estimate the model including observations with missing values.
</p>

<p>
Table <a href="#org4542675">1</a> shows the summary statistics for our variables. We have more than 50k observations.<sup><a id="fnr.8" class="footref" href="#fn.8" role="doc-backlink">8</a></sup> The average population size per region-age-gender category is about 7500 and the average number of deaths 100. Median population size per category equals 6500 and median number of deaths 56. In our data, the percentage of people dying in a NUTS 2/year/age/gender category (<code>mortality</code>) equals 2% on average with a maximum of 20% for some region and age combination.
</p>

<table id="org4542675" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 1:</span> Summary statistics main variables</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">count</th>
<th scope="col" class="org-right">mean</th>
<th scope="col" class="org-right">std</th>
<th scope="col" class="org-right">min</th>
<th scope="col" class="org-right">median</th>
<th scope="col" class="org-right">max</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">population</td>
<td class="org-right">52612.00</td>
<td class="org-right">7491.28</td>
<td class="org-right">4805.28</td>
<td class="org-right">440.00</td>
<td class="org-right">6477.00</td>
<td class="org-right">36117.00</td>
</tr>

<tr>
<td class="org-left">deaths</td>
<td class="org-right">52612.00</td>
<td class="org-right">103.19</td>
<td class="org-right">126.49</td>
<td class="org-right">0.00</td>
<td class="org-right">56.00</td>
<td class="org-right">1033.00</td>
</tr>

<tr>
<td class="org-left">mortality</td>
<td class="org-right">52612.00</td>
<td class="org-right">2.12</td>
<td class="org-right">2.94</td>
<td class="org-right">0.00</td>
<td class="org-right">0.81</td>
<td class="org-right">20.72</td>
</tr>

<tr>
<td class="org-left">poverty</td>
<td class="org-right">50878.00</td>
<td class="org-right">16.54</td>
<td class="org-right">6.58</td>
<td class="org-right">2.60</td>
<td class="org-right">15.30</td>
<td class="org-right">36.10</td>
</tr>

<tr>
<td class="org-left">deprivation</td>
<td class="org-right">52612.00</td>
<td class="org-right">11.23</td>
<td class="org-right">12.78</td>
<td class="org-right">0.00</td>
<td class="org-right">3.40</td>
<td class="org-right">52.30</td>
</tr>

<tr>
<td class="org-left">too exp.</td>
<td class="org-right">52612.00</td>
<td class="org-right">2.00</td>
<td class="org-right">3.09</td>
<td class="org-right">0.00</td>
<td class="org-right">0.60</td>
<td class="org-right">16.00</td>
</tr>

<tr>
<td class="org-left">unmet</td>
<td class="org-right">52612.00</td>
<td class="org-right">5.81</td>
<td class="org-right">4.08</td>
<td class="org-right">0.00</td>
<td class="org-right">4.80</td>
<td class="org-right">20.90</td>
</tr>

<tr>
<td class="org-left">out-of-pocket</td>
<td class="org-right">52612.00</td>
<td class="org-right">21.99</td>
<td class="org-right">8.88</td>
<td class="org-right">8.83</td>
<td class="org-right">19.46</td>
<td class="org-right">47.74</td>
</tr>

<tr>
<td class="org-left">voluntary</td>
<td class="org-right">52612.00</td>
<td class="org-right">3.13</td>
<td class="org-right">3.07</td>
<td class="org-right">0.33</td>
<td class="org-right">1.59</td>
<td class="org-right">15.20</td>
</tr>

<tr>
<td class="org-left">expend. per head</td>
<td class="org-right">52612.00</td>
<td class="org-right">3386.59</td>
<td class="org-right">2691.25</td>
<td class="org-right">307.69</td>
<td class="org-right">3559.49</td>
<td class="org-right">8484.88</td>
</tr>
</tbody>
</table>

<p>
We use two measures for poverty; each of these measures comes from the EU statistics on income and living conditions (<a href="https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:EU_statistics_on_income_and_living_conditions_(EU-SILC)">EU-SILC</a>) survey. The first is "at-risk-of-poverty rate" that we refer to as <code>poverty</code>. This is a relative poverty measure: the share of people with disposable income after social transfers below a threshold based on the national median disposable income. The material deprivation measure (denoted <code>deprivation</code>) refers to the enforced inability to pay unexpected expenses, afford adequate heating of the home, durable goods like a washing machine etc. See the appendix for details.
</p>

<p>
In our data, the (unweighted) average (across regions and years) percentage of people at risk of poverty equals 16% with a maximum of 36%. For material deprivation the numbers are 11% and 52%. These measures vary by NUTS 2 region and year but not by age or gender. We use <code>deprivation</code> in our baseline analysis because it captures more closely the idea of postponing treatment due to financial constraints. The <code>poverty</code> variable is used in a robustness check.
</p>

<p>
Also from the EU-SILC survey, we use the variable capturing unmet medical needs because the forgone treatment was too expensive (<code>too exp</code>). The variable <code>unmet</code> measures percentage of people in need of healthcare that postpone or forgo treatment because it is either too expensive, the hospital is too far away, there is a waiting list for the treatment, the patient hopes that symptoms will disappear without treatment, the patient is afraid of treatment or has no time to visit a physician. As explained in the model above, our analysis uses both <code>too exp</code>  and <code>unmet</code> (which includes <code>too exp</code> as reason for unmet medical needs) as variables.
</p>

<p>
The measure <code>OOP</code> that we use in the baseline model, is based on household oop payments (<code>out-of-pocket</code>). In particular, this measures the percentage of healthcare expenditures paid oop. This varies by country and year. The higher <code>OOP</code>, the less generous the healthcare system is (in terms of higher coinsurance \(\xi\) or deductible \(D\) in the model above). We expect that high <code>OOP</code> is especially problematic in regions with a high percentage of people with low income.
</p>

<p>
In a robustness analysis we consider the sum of oop and payments to voluntary health insurance (<code>voluntary</code>) as a percentage of health expenditures as our <code>OOP</code> measure. The reason why we also consider voluntary insurance is that basic or mandatory insurance packages can differ between countries. If people are willing to spend money on voluntary insurance, it can be the case that this voluntary insurance covers treatments that people deem to be important. Put differently, a country that finances all expenditure ("free at point of service") for a very narrow set of treatments would appear generous if we only used oop payments. The narrowness of this insurance would then be signalled by people buying voluntary insurance to cover other treatments.
</p>

<p>
As can be seen in Table <a href="#org4542675">1</a>, <code>out-of-pocket</code> is the most important component of the two <code>OOP</code> inputs. Percentage of healthcare expenditure paid oop is a multiple of the percentage financed via voluntary insurance (both in terms of the mean and of the minimum, median and maximum reported in the table). Therefore, the baseline model works with oop payments (only).
</p>

<p>
Finally, as shown in Lemma <a href="#orgeb785f9">1</a>, healthcare expenditure per head (<code>expend per head</code>) affects how <code>OOP</code> influences the fraction of people forgoing treatment because it is too expensive. Expenditure per head is on average 3300 euro for the countries in our data. But the variation is big with a standard deviation of almost 2700 euro.
</p>

<p>
Figure <a href="#orgc210112">4</a> (left panel) shows average mortality as a function of age for women and men. This is the pattern that one would expect: clearly increasing with age from age 40 onward and higher for men than for women (as women tend to live longer than men). Figure <a href="#orgc210112">4</a> (middle panel) shows the effect we are interested in: mortality is higher in regions where the interaction <code>OOP</code> \(\times\) Poverty is high than where it is low and this difference increases with age. Both for women and for men, we plot per age category the difference between average mortality in regions that are at least 0.5 standard deviation above the mean for <code>OOP</code> \(\times\) Poverty and regions that are 0.5 standard deviation below the mean. Around age 82, this mortality difference equals approximately 4 percentage points. In the raw data, for 100 women aged 82, there are 4 additional deaths in regions with high <code>OOP</code> \(\times\) Poverty compared to regions with low interaction. Note that this plot of the raw data does not correct for other factors, like the poverty level itself, and thus over-estimates the size of the effect of <code>OOP</code> \(\times\) Poverty on mortality. The right panel in this figure does a similar exercise with the fraction of people reporting unmet medical needs. Mortality is higher in regions where unmet needs are at least 0.5 standard deviation above the mean compared to regions where it is 0.5 standard deviation below the mean.
</p>

<p>
The observation from the figure that the difference between the two sets of regions is approximately zero for people below 35, is our motivation to include ages above 35 only in our data. Further, the difference in mortality between the regions increases with the mortality level in the left panel. This is in line with our specification in Lemma <a href="#orgeb785f9">1</a> where unmet needs has a multiplicative effect on the underlying mortality rate modeled by \(e^{\beta_{ag}}/(1+e^{\beta_{ag}})\).
</p>



<div id="orgc210112" class="figure">
<p><img src="./figures/IncreaseMortalityInteractionData.png" alt="IncreaseMortalityInteractionData.png" />
</p>
<p><span class="figure-number">Figure 4: </span>Mortality and difference in mortality between regions with high and low interaction <code>OOP</code> \(\times\) Poverty and high and low unmet medical needs.</p>
</div>
</div>



<div id="outline-container-org8fa56dd" class="outline-3">
<h3 id="org8fa56dd"><span class="section-number-3">3.1.</span> data&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></h3>
<div class="outline-text-3" id="text-3-1">
<p>
The following python code generates Table <a href="#org4542675">1</a> with summary statistics.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">headers</span> = [<span style="color: #c3e88d;">'count'</span>,<span style="color: #c3e88d;">'mean'</span>,<span style="color: #c3e88d;">'std'</span>,<span style="color: #c3e88d;">'min'</span>,<span style="color: #c3e88d;">'median'</span>,<span style="color: #c3e88d;">'max'</span>]
<span style="color: #ffcb6b;">variables</span> = df[[<span style="color: #c3e88d;">'population'</span>,<span style="color: #c3e88d;">'deaths'</span>,<span style="color: #c3e88d;">'mortality'</span>,\
                <span style="color: #c3e88d;">'at risk of poverty'</span>,\
                <span style="color: #c3e88d;">'percentage_material_deprivation'</span>,\
                <span style="color: #c3e88d;">'TOOEXP'</span>,<span style="color: #c3e88d;">'unmet'</span>,\
                <span style="color: #c3e88d;">'HF3_PC_CHE'</span>,<span style="color: #c3e88d;">'HF2_PC_CHE'</span>,\
           <span style="color: #c3e88d;">'health expenditure per capita'</span>]]\
           .describe().T[[<span style="color: #c3e88d;">'count'</span>,<span style="color: #c3e88d;">'mean'</span>,<span style="color: #c3e88d;">'std'</span>,<span style="color: #c3e88d;">'min'</span>,<span style="color: #c3e88d;">'50%'</span>,<span style="color: #c3e88d;">'max'</span>]]
variables.rename({<span style="color: #c3e88d;">'at risk of poverty'</span>:<span style="color: #c3e88d;">'poverty'</span>,\
                  <span style="color: #c3e88d;">'percentage_material_deprivation'</span>:\
                  <span style="color: #c3e88d;">'deprivation'</span>, <span style="color: #c3e88d;">'HF2_PC_CHE'</span>:<span style="color: #c3e88d;">'voluntary'</span>,\
                  <span style="color: #c3e88d;">'HF3_PC_CHE'</span>:<span style="color: #c3e88d;">'out-of-pocket'</span>,\
                  <span style="color: #c3e88d;">'TOOEXP'</span>:<span style="color: #c3e88d;">'too exp.'</span>,\
                  <span style="color: #c3e88d;">'health expenditure per capita'</span>:\
                  <span style="color: #c3e88d;">'expend. per head'</span>},inplace=<span style="color: #f78c6c;">True</span>)
<span style="color: #82aaff;">print</span>(tabulate(variables,headers,tablefmt=<span style="color: #c3e88d;">"orgtbl"</span>,\
               floatfmt=<span style="color: #c3e88d;">".2f"</span>))
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">count</th>
<th scope="col" class="org-right">mean</th>
<th scope="col" class="org-right">std</th>
<th scope="col" class="org-right">min</th>
<th scope="col" class="org-right">median</th>
<th scope="col" class="org-right">max</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">population</td>
<td class="org-right">52612.00</td>
<td class="org-right">7491.28</td>
<td class="org-right">4805.28</td>
<td class="org-right">440.00</td>
<td class="org-right">6477.00</td>
<td class="org-right">36117.00</td>
</tr>

<tr>
<td class="org-left">deaths</td>
<td class="org-right">52612.00</td>
<td class="org-right">103.19</td>
<td class="org-right">126.49</td>
<td class="org-right">0.00</td>
<td class="org-right">56.00</td>
<td class="org-right">1033.00</td>
</tr>

<tr>
<td class="org-left">mortality</td>
<td class="org-right">52612.00</td>
<td class="org-right">2.12</td>
<td class="org-right">2.94</td>
<td class="org-right">0.00</td>
<td class="org-right">0.81</td>
<td class="org-right">20.72</td>
</tr>

<tr>
<td class="org-left">poverty</td>
<td class="org-right">50878.00</td>
<td class="org-right">16.54</td>
<td class="org-right">6.58</td>
<td class="org-right">2.60</td>
<td class="org-right">15.30</td>
<td class="org-right">36.10</td>
</tr>

<tr>
<td class="org-left">deprivation</td>
<td class="org-right">52612.00</td>
<td class="org-right">11.23</td>
<td class="org-right">12.78</td>
<td class="org-right">0.00</td>
<td class="org-right">3.40</td>
<td class="org-right">52.30</td>
</tr>

<tr>
<td class="org-left">too exp.</td>
<td class="org-right">52612.00</td>
<td class="org-right">2.00</td>
<td class="org-right">3.09</td>
<td class="org-right">0.00</td>
<td class="org-right">0.60</td>
<td class="org-right">16.00</td>
</tr>

<tr>
<td class="org-left">unmet</td>
<td class="org-right">52612.00</td>
<td class="org-right">5.81</td>
<td class="org-right">4.08</td>
<td class="org-right">0.00</td>
<td class="org-right">4.80</td>
<td class="org-right">20.90</td>
</tr>

<tr>
<td class="org-left">out-of-pocket</td>
<td class="org-right">52612.00</td>
<td class="org-right">21.99</td>
<td class="org-right">8.88</td>
<td class="org-right">8.83</td>
<td class="org-right">19.46</td>
<td class="org-right">47.74</td>
</tr>

<tr>
<td class="org-left">voluntary</td>
<td class="org-right">52612.00</td>
<td class="org-right">3.13</td>
<td class="org-right">3.07</td>
<td class="org-right">0.33</td>
<td class="org-right">1.59</td>
<td class="org-right">15.20</td>
</tr>

<tr>
<td class="org-left">expend. per head</td>
<td class="org-right">52612.00</td>
<td class="org-right">3386.59</td>
<td class="org-right">2691.25</td>
<td class="org-right">307.69</td>
<td class="org-right">3559.49</td>
<td class="org-right">8484.88</td>
</tr>
</tbody>
</table>
</div>




<div id="outline-container-org269e9aa" class="outline-4">
<h4 id="org269e9aa"><span class="section-number-4">3.1.1.</span> standardizing data</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
In our Bayesian estimation we work with standardized variables. To deal with (potential) missing values in the estimation with pymc, we use numpy's <a href="https://numpy.org/doc/stable/reference/maskedarray.html">masked arrays</a>. To use fixed effects, we index variables by country and NUTS 2 indices, gender, year and age. These indices are generated with pandas' <code>factorize</code> function.
</p>

<p>
All variables representing fractions (between 0 and 1) are not (further) standardized. Population size and number of deaths are not standardized either. Health care expenditure is standardized by dividing by its standard deviation using the function <code>standardize_s</code> defined below.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">country_index</span>, <span style="color: #ffcb6b;">country_list</span> = pd.factorize(df.country,sort=<span style="color: #f78c6c;">True</span>)
country_code_index, country_code_list = \
  pd.factorize(df.country_code, sort=<span style="color: #f78c6c;">True</span>)
nuts2_index, nuts2_list = pd.factorize(df.nuts2,sort=<span style="color: #f78c6c;">True</span>)
nuts1_index, nuts1_list = pd.factorize(df.nuts1,sort=<span style="color: #f78c6c;">True</span>)
gender, gender_list =\
  np.array(pd.factorize(df.sex,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)
year, year_list =\
  np.array(pd.factorize(df.year,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)
age_index, age_list = \
  np.array(pd.factorize(df.age,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)

N_countries = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(country_index))
N_nuts1 = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(nuts1_index))
N_nuts2 = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(nuts2_index))
N_age = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(age_index))

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">standardize_s</span>(x):
  x_ma = np.ma.masked_invalid(x)
  <span style="color: #89DDFF;">return</span> x_ma/x_ma.std()
</pre>
</div>

<p>
The following cell standardizes variables as percentage in our data into fractions and transforms lagged mortality into logs, <code>lagged_log_mortality</code>, and fraction too expensive into log-odds, <code>too_exp_lo</code>. As mortality and <code>TooExp</code> can be zero for some observations, we clip these variables from below. The lower bounds imply probabilities of less than 1%. Neither of these variables is close to one in our data; hence the upper-bound is not relevant.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #676E95;"># </span><span style="color: #676E95;">dependent variable</span>
<span style="color: #ffcb6b;">mortality</span> = df.deaths.values
<span style="color: #ffcb6b;">population</span> = df.population.values
<span style="color: #ffcb6b;">lagged_log_mortality</span> = np.clip(\
    np.ma.masked_invalid(np.log(df[<span style="color: #c3e88d;">'lagged_mortality_s'</span>])),\
                         np.log(0.0001),np.log(10))

<span style="color: #676E95;"># </span><span style="color: #676E95;">nuts 2 measures</span>
<span style="color: #ffcb6b;">poverty_s</span>  = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'poverty'</span>]/100.0)
<span style="color: #ffcb6b;">deprivation_s</span> = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'deprivation'</span>]/100.0)

<span style="color: #ffcb6b;">oop_s</span> = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>])/100.0 <span style="color: #676E95;"># </span><span style="color: #676E95;">only oop</span>
<span style="color: #ffcb6b;">oop_e</span> = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]+df[<span style="color: #c3e88d;">'HF2_PC_CHE'</span>])/100.0
      <span style="color: #676E95;"># </span><span style="color: #676E95;">oop and voluntary insurance</span>

<span style="color: #ffcb6b;">too_exp</span> = (df[<span style="color: #c3e88d;">'TOOEXP'</span>])/100.0
<span style="color: #ffcb6b;">too_exp_lo</span> = np.clip(np.log(too_exp/(1-too_exp)),np.log(0.0001),np.log(10))
<span style="color: #ffcb6b;">unmet</span> = (df[<span style="color: #c3e88d;">'UNMET'</span>])/100.0



<span style="color: #676E95;"># </span><span style="color: #676E95;">country measures</span>
<span style="color: #ffcb6b;">expenditure_s</span> = standardize_s(df[<span style="color: #c3e88d;">'health expenditure per capita'</span>])
<span style="color: #ffcb6b;">std_expenditure</span> = np.std(df[<span style="color: #c3e88d;">'health expenditure per capita'</span>])

<span style="color: #676E95;"># </span><span style="color: #676E95;">female = (df.sex == 'F').astype('uint8').values</span>

N = <span style="color: #82aaff;">len</span>(mortality) <span style="color: #676E95;"># </span><span style="color: #676E95;">total sample size</span>
N_years = <span style="color: #82aaff;">len</span>(year_list)

<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"total sample size: {}"</span>.<span style="color: #82aaff;">format</span>(N))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of countries:       {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(country_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of NUTS 1 regions:  {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(nuts1_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of NUTS 2 regions:  {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(nuts2_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of ages:            {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(age_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of years:           {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(year_list)))
</pre>
</div>

<pre class="example">
total sample size: 52612
number of countries:       14
number of NUTS 1 regions:  25
number of NUTS 2 regions:  78
number of ages:            51
number of years:           10
/home/janboone/anaconda3/envs/env_pymc/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)
</pre>


<p>
We print our total sample size, number of countries, NUTS 1 and NUTS 2 regions, number of calendar years and ages.
</p>
</div>
</div>

<div id="outline-container-orgbca2873" class="outline-4">
<h4 id="orgbca2873"><span class="section-number-4">3.1.2.</span> figure with extended age range</h4>
<div class="outline-text-4" id="text-3-1-2">
<p>
Next, we use a <code>groupby</code> to plot average mortality by age and gender. Further, we compare regions where the interaction <code>OOP</code> \(\times\) Poverty is at least 0.5 standard deviation above the mean with regions where it is at least this distance below the mean. For low (young) ages, there is hardly a difference, mortality is close to 0 for both sets of regions. But from age 40 onward, there is a clear difference which increases with age.
</p>

<p>
We can generate a similar figure with the (standardized) variable <code>unmet</code>: taking the difference in mortality between regions with unmet 0.5 standard deviation above the mean and 0.5 standard deviation below the mean.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">first_year</span> = 2009
<span style="color: #ffcb6b;">last_year</span> = 2019
<span style="color: #ffcb6b;">age_min_fig</span> = 20

<span style="color: #ffcb6b;">df_fig</span> = pd.read_csv(<span style="color: #c3e88d;">'./data/data_deaths_by_age_nuts_2.csv'</span>)
<span style="color: #ffcb6b;">df_fig</span>[<span style="color: #c3e88d;">'poverty'</span>] = df_fig[<span style="color: #c3e88d;">'at risk of poverty'</span>]
<span style="color: #ffcb6b;">df_fig</span>[<span style="color: #c3e88d;">'deprivation'</span>] = df_fig[<span style="color: #c3e88d;">'percentage_material_deprivation'</span>]

df_fig.dropna(subset=[<span style="color: #c3e88d;">'deaths'</span>,<span style="color: #c3e88d;">'population'</span>, <span style="color: #c3e88d;">'TOOEXP'</span>,\
                  <span style="color: #c3e88d;">'HF3_PC_CHE'</span>,<span style="color: #c3e88d;">'lagged_mortality'</span>],
                    axis=0, how =<span style="color: #c3e88d;">'any'</span>,inplace=<span style="color: #f78c6c;">True</span>)
df_fig = df_fig[(df_fig.population &gt; df_fig.deaths) &amp; (df_fig.age &gt;= age_min_fig) &amp; \
        (df_fig.age &lt;= age_max) &amp; (df_fig.year &lt;= last_year) &amp;\
        (df_fig.year &gt;= first_year)]
df_fig[<span style="color: #c3e88d;">'mortality'</span>] = df_fig.deaths/df_fig.population*100<span style="background-color: #ff5370;"> </span>
df_groupby = df_fig[[<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>,<span style="color: #c3e88d;">'mortality'</span>]].\
    groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>]).mean().reset_index()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python">plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
fig, (<span style="color: #ffcb6b;">ax1</span>, <span style="color: #ffcb6b;">ax2</span>, <span style="color: #ffcb6b;">ax3</span>) = plt.subplots(1, 3,\
                        sharex=<span style="color: #f78c6c;">True</span>,dpi=140,figsize=(16,6))
fig.suptitle(<span style="color: #c3e88d;">'Mortality across age'</span>)
ax1.plot(np.arange(age_min_fig,age_max+1),\
         df_groupby[df_groupby.sex==<span style="color: #c3e88d;">'F'</span>].mortality,\
         label=<span style="color: #c3e88d;">'female mortality'</span>)
ax1.plot(np.arange(age_min_fig,age_max+1),\
         df_groupby[df_groupby.sex==<span style="color: #c3e88d;">'M'</span>].mortality,
         label=<span style="color: #c3e88d;">'male mortality'</span>)
ax1.legend()
ax1.axhline(0,c=<span style="color: #c3e88d;">'k'</span>,linestyle=<span style="color: #c3e88d;">'dashed'</span>)
ax1.set_xlabel(<span style="color: #c3e88d;">'age'</span>)
ax1.set_ylabel(<span style="color: #c3e88d;">'mortality (in %)'</span>)
ax1.set_title(\
  <span style="color: #c3e88d;">'Average mortality percentage by age\naveraged across years and countries'</span>);

oop_poverty = df_fig[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>] * df_fig[<span style="color: #c3e88d;">'deprivation'</span>]/(100*100)
k = 0.5

mask_high_interaction = (oop_poverty &gt; np.mean(oop_poverty) + k * np.std(oop_poverty))
mask_low_interaction  = (oop_poverty &lt; np.mean(oop_poverty) - k * np.std(oop_poverty))

groupby_high = df_fig[mask_high_interaction].\
    groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>])[<span style="color: #c3e88d;">'mortality'</span>].mean().reset_index()
groupby_low = df_fig[mask_low_interaction].\
    groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>])[<span style="color: #c3e88d;">'mortality'</span>].mean().reset_index()

mortality_difference_0_F = (groupby_high[groupby_high[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'F'</span>].\
              mortality-groupby_low[groupby_low[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'F'</span>].mortality)
ax2.plot(groupby_high[groupby_high[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'F'</span>].\
         age,mortality_difference_0_F,label=<span style="color: #c3e88d;">'female'</span>)
mortality_difference_0_M = (groupby_high[groupby_high[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'M'</span>].\
         mortality-groupby_low[groupby_low[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'M'</span>].mortality)
ax2.plot(groupby_high[groupby_high[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'M'</span>].\
         age,mortality_difference_0_M,label=<span style="color: #c3e88d;">'male'</span>)
ax2.axhline(0,c=<span style="color: #c3e88d;">'k'</span>,linestyle=<span style="color: #c3e88d;">'dashed'</span>)
ax2.set_xlabel(<span style="color: #c3e88d;">'age'</span>)
ax2.set_ylabel(\
  <span style="color: #c3e88d;">'mortality difference in percentage points'</span>)
ax2.set_title(\
  <span style="color: #c3e88d;">'Increase in mortality due to an\nincrease in the interaction OOP $\\times$ Poverty'</span>)

unmet_fig = (df_fig[<span style="color: #c3e88d;">'UNMET'</span>])/100.0

mask_high_interaction = (unmet_fig &gt; unmet_fig.mean() + k*unmet_fig.std())
mask_low_interaction = (unmet_fig &lt; unmet_fig.mean() - k*unmet_fig.std())

groupby_high = df_fig[mask_high_interaction].\
    groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>])[<span style="color: #c3e88d;">'mortality'</span>].mean().reset_index()
groupby_low = df_fig[mask_low_interaction].\
    groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>])[<span style="color: #c3e88d;">'mortality'</span>].mean().reset_index()

mortality_difference_0_F = (groupby_high[groupby_high[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'F'</span>].\
    mortality-groupby_low[groupby_low[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'F'</span>].mortality)
ax3.plot(groupby_high[groupby_high[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'F'</span>].age,\
    mortality_difference_0_F,label=<span style="color: #c3e88d;">'female'</span>)
mortality_difference_0_M = (groupby_high[groupby_high[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'M'</span>].\
    mortality-groupby_low[groupby_low[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'M'</span>].mortality)
ax3.plot(groupby_high[groupby_high[<span style="color: #c3e88d;">'sex'</span>]==<span style="color: #c3e88d;">'M'</span>].age,\
         mortality_difference_0_M,label=<span style="color: #c3e88d;">'male'</span>)
ax3.axhline(0,c=<span style="color: #c3e88d;">'k'</span>,linestyle=<span style="color: #c3e88d;">'dashed'</span>)
ax3.set_xlabel(<span style="color: #c3e88d;">'age'</span>)
ax3.set_ylabel(\
   <span style="color: #c3e88d;">'mortality difference in percentage points'</span>)
ax3.set_title(\
   <span style="color: #c3e88d;">'Increase in mortality due to an increase\nin fraction of people with unmet medical needs'</span>)
fig.tight_layout();
</pre>
</div>


<div id="orga0bef1a" class="figure">
<p><img src="./figures/IncreaseMortalityInteractionData.png" alt="IncreaseMortalityInteractionData.png" />
</p>
</div>
</div>
</div>
</div>
</div>



<div id="outline-container-org2f9546c" class="outline-2">
<h2 id="org2f9546c"><span class="section-number-2">4.</span> Estimation</h2>
<div class="outline-text-2" id="text-4">
<p>

</p>

<p>
In this section, we explain how we estimate the equations in Lemma <a href="#orgeb785f9">1</a>.
</p>
</div>

<div id="outline-container-org182ae52" class="outline-3">
<h3 id="org182ae52"><span class="section-number-3">4.1.</span> Empirical model</h3>
<div class="outline-text-3" id="text-4-1">
<p>
First, we estimate a binomial model with population size as the number of draws and deaths as the number of events. We do this for every combination of NUTS 2 region, calendar year, age and gender in our data. The probability of \(k \leq n\) deaths out of a population \(n\) is then given by
</p>
\begin{equation}
\label{orgc7208ff}
\binom{n}{k} m^{k}(1-m)^{n-k}
\end{equation}
<p>
where \(m\) denotes mortality, the probability of death. The advantage of modeling \(k\) as a binomial distribution is that it automatically captures that the variance in the proportion of deaths will be bigger if population size \(n\) is smaller. The equation that we estimate for \(m_{2atg}\) is given in the lemma. The coefficient we are especially interested in is \(\beta_{unmet}\). This is the coefficient through which an increase in unmet medical needs because of financial problems affects mortality.
</p>

<p>
Figure <a href="#orgc210112">4</a> illustrates that without the multiplicative specification for \(m_{ga2t}\) in the lemma, the coefficients for \(\beta_{unmet}, \beta_{poverty}\) would have to vary with age. Indeed, for the young mortality is low even in regions with high poverty or high unmet needs. This would have considerably increased the number of parameters that we need to estimate.
</p>

<p>
The second equation captures how an increase in <code>OOP</code> affects the fraction of people in a region that postpone or skip treatment because it is too expensive. In our estimation we want to ensure that <code>TooExp</code> is between 0 and 1. For this we assume that <code>TooExp</code> has a logit-normal distribution. That is, the log-odds of <code>TooExp</code> is normally distributed.
</p>

<p>
We use the variables in Table <a href="#org4542675">1</a> to capture their theoretical counterparts. As mentioned, in the baseline specification we use deprivation as (absolute) poverty measure and out-of-pocket as the measure for <code>OOP</code>. In robustness checks, we use at-risk-of-poverty as (relative) poverty measure and include voluntary health insurance expenditure as part of <code>OOP</code>.
</p>
</div>
</div>

<div id="outline-container-org4cd41d9" class="outline-3">
<h3 id="org4cd41d9"><span class="section-number-3">4.2.</span> Bayesian estimation</h3>
<div class="outline-text-3" id="text-4-2">
<p>
We use Markov Chain Monte Carlo (MCMC), in particular the NUTS sampler to explore the posterior distributions of our parameters. For this sampler, we have the guarantee that the whole posterior distribution is captured as long as we have enough samples. Although this is an asymptotic result, we are confident that drawing four chains of 2000 samples (1000 samples of which are used for tuning) is enough to cover the posterior distribution. In the appendix we discuss a number of checks on this convergence.
</p>

<p>
It is not straightforward to put priors on the coefficients of the two equations in Lemma <a href="#orgeb785f9">1</a>. To illustrate, how strong is the reaction of mortality to a \(0.1\) increase in the fraction of people reporting unmet medical needs? We are not aware of previous studies looking into this and have no a priori information on the strength of this effect. Therefore, we use a hierarchical model to determine the parameters of the prior distributions. Details on the priors can be found in the online appendix.
</p>

<p>
In the robustness section, we have two checks on our model with missing observations. First, when we use at-risk-of-poverty instead of deprivation as measure for low income. As can be seen in Table <a href="#org4542675">1</a>, poverty is reported less frequently by the countries in our sample than the other variables. Second, when we allow for missing observations in deprivation and unmet medical needs due to financial constraints. We explain below how Bayesian estimation deals with missing observations without imputing missing values.
</p>
</div>
</div>

<div id="outline-container-org7889438" class="outline-3">
<h3 id="org7889438"><span class="section-number-3">4.3.</span> baseline model&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></h3>
<div class="outline-text-3" id="text-4-3">
</div>
<div id="outline-container-org1ff6026" class="outline-4">
<h4 id="org1ff6026"><span class="section-number-4">4.3.1.</span> model</h4>
<div class="outline-text-4" id="text-4-3-1">
<p>
The function <code>build_model</code> specifies our Bayesian model where the function has poverty and oop as arguments. These vary over deprivation in the baseline specification and at-risk-of-poverty in a robustness check; oop in the narrow sense of out-of-pocket payments (baseline) and the sum of oop payments and money spent on voluntary insurance for a robustness check.
</p>

<p>
Setting priors for the fixed effects <code>mu_2_too, mu_t_too, mu_2_m, beta_age</code> is not so sensitive in the sense that we are not particularly interested in the values of these effects. They need to be broad enough to cover relevant values. Most fixed effects are centered at 0 with the exception of <code>mu_2_too</code> and <code>beta_age</code> which are centered to roughly capture the average values of <code>TooExp</code> and mortality. To illustrate, the mean of <code>too_exp_lo</code> equals \(-5.17\); hence, we choose <code>mu</code> for the region fixed effects <code>mu_2_too</code> equal to \(-5.0\).
</p>

<p>
For the coefficients <code>b_oop, b_interaction</code> and <code>beta_lagged_log_mortality</code>, <code>beta_unmet</code>, <code>beta_poverty</code> where we are interested in the size of the effects, choosing a prior is more subtle. As mentioned, we have no clear idea to which extent <code>TooExp</code> or the number of deaths are determined by factors outside of our model (captured by fixed effects) or by the variables that we do model. But we do believe that these effects will be comparable for different variables and across countries (for the <code>TooExp</code> equation).
</p>

<p>
Hence, we introduce the hyper-parameters <code>sd_prior_b, sd_prior_beta</code> to capture this. These parameters then feed into the priors for the <code>b_</code> and <code>beta_</code> parameters.
</p>

<p>
The <code>beta_</code> coefficients enter the mortality equation in the multiplier term as \(e^{...}\) which can get big "very fast". To avoid this term getting too big in sampling the posterior, we introduce an upper-bound on this term. The idea of <code>at.switch(at.lt(x, 0.7),at.exp(x),at.exp(0.7*(x/0.7)**0.1))</code> is that when sampling, high draws of <code>x</code> do not cause \(m>1\) which would cause an error. Note that \(e^{0.7}= 2.0\) which is not a factor which we expect: twice as high mortality (for a given age/sex category) in one region compared to another. Hence over the relevant range we expect \(\lambda = e^x\) but when sampling we avoid high values for \(\lambda\) while avoiding a zero derivative which <code>clip()</code> would give us. It turns out that in the posterior of <code>x</code> there are indeed very few values above 0.7 and we work with this term as if it is \(e^x\).
</p>

<p>
For parameters where the model clearly implies that they are positive, like \(b_{oop},b_{intercation}\), we use a <code>HalfNormal</code> distribution to specify the prior distribution.
</p>

<p>
Finally, we specify \(m\) as in Lemma <a href="#orgeb785f9">1</a>. Then \(m\) is the probability in our Binomial distribution explaining the number of people that die out of population size <code>population</code>. As explained in the lemma, we start from a baseline age profile \(h = e^{\beta_{ag}}/(1+e^{\beta_{ag}})\) and then multiply this with a factor that varies around 1.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">lagged_log_mortality</span> = np.asarray(lagged_log_mortality)
<span style="color: #ffcb6b;">unmet</span> = np.asarray(unmet)

<span style="color: #ffcb6b;">coords</span> = {<span style="color: #c3e88d;">"country"</span>:country_list, <span style="color: #c3e88d;">"nuts2"</span>:nuts2_list,\
          <span style="color: #c3e88d;">"gender"</span>:gender_list, <span style="color: #c3e88d;">"age"</span>:age_list,\
          <span style="color: #c3e88d;">"year"</span>:year_list}

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">build_model</span>(poverty,oop):
  <span style="color: #89DDFF;">with</span> pm.Model(coords=coords) <span style="color: #89DDFF;">as</span> baseline_model:
    sd_fixed_effects = 0.3
    <span style="color: #676E95;"># </span><span style="color: #676E95;">hierarchical priors</span>
    sd_prior_b = pm.HalfNormal(<span style="color: #c3e88d;">'sd_prior_b'</span>, sigma = 0.1)
    sd_prior_beta = pm.HalfNormal(<span style="color: #c3e88d;">'sd_prior_beta'</span>, sigma = 0.1)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">Too Expensive equation</span>
    <span style="color: #676E95;">## </span><span style="color: #676E95;">NUTS 2 regional fixed effect:</span>
    mu_2_too      = pm.Normal(<span style="color: #c3e88d;">'mu_2_too'</span>, mu = -5.0,\
                              sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"nuts2"</span>)
    <span style="color: #676E95;">## </span><span style="color: #676E95;">time fixed effect:</span>
    mu_t_too = pm.Normal(<span style="color: #c3e88d;">'mu_t'</span>, mu = 0.0,\
                     sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"year"</span>)
    <span style="color: #676E95;">## </span><span style="color: #676E95;">coefficients of the TooExp equation:</span>
    b_oop         = pm.HalfNormal(<span style="color: #c3e88d;">'b_oop'</span>, sigma = sd_prior_b,\
                                  dims=<span style="color: #c3e88d;">"country"</span>)
    b_interaction = pm.HalfNormal(<span style="color: #c3e88d;">'b_interaction'</span>,\
                                  sigma = sd_prior_b, dims=<span style="color: #c3e88d;">"country"</span>)
    mu_too_exp_lo = pm.Deterministic(<span style="color: #c3e88d;">'mu_too_exp_lo'</span>, \
                      mu_2_too[nuts2_index] + mu_t_too[year] +\
                      expenditure_s * oop *\
                      (b_oop[country_index] +\
                       b_interaction[country_index] * poverty))
    <span style="color: #676E95;">## </span><span style="color: #676E95;">equation for the log odds of TooExp</span>
    Too_exp_lo    = pm.Normal(<span style="color: #c3e88d;">'Too_exp_lo'</span>, mu = mu_too_exp_lo,\
                              sigma = 1, observed = too_exp_lo)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">Mortality equation</span>
    <span style="color: #676E95;">## </span><span style="color: #676E95;">age/gender fixed effect:</span>
    beta_age = pm.Normal(<span style="color: #c3e88d;">'beta_age'</span>, mu = -3.0,\
                         sigma = sd_fixed_effects,\
                         dims=(<span style="color: #c3e88d;">"age"</span>,<span style="color: #c3e88d;">"gender"</span>),\
                         initval=-3*np.ones((N_age,2)))
    h = pm.Deterministic(<span style="color: #c3e88d;">'h'</span>,at.sigmoid(\
                              beta_age[age_index,gender]))

    <span style="color: #676E95;">## </span><span style="color: #676E95;">multiplier effect: x</span>
    <span style="color: #676E95;">### </span><span style="color: #676E95;">NUTS 2 fixed effect:</span>
    mu_2_m   = pm.Normal(<span style="color: #c3e88d;">'mu_2_m'</span>, mu = 0.0,\
                         sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"nuts2"</span>)
    <span style="color: #676E95;">### </span><span style="color: #676E95;">coefficients of the mortality equation:</span>
    beta_lagged_log_mortality = pm.Normal(<span style="color: #c3e88d;">'beta_lagged_log_mortality'</span>,\
                                          mu = 0, sigma = sd_prior_beta)
    beta_unmet = pm.HalfNormal(<span style="color: #c3e88d;">'beta_unmet'</span>, sigma = sd_prior_beta)
    beta_poverty = pm.HalfNormal(<span style="color: #c3e88d;">'beta_poverty'</span>, sigma = sd_prior_beta)
    x = pm.Deterministic(<span style="color: #c3e88d;">'x'</span>,mu_2_m[nuts2_index] +\
                             beta_unmet*unmet +\
                             beta_poverty*poverty+\
                             beta_lagged_log_mortality*\
                             lagged_log_mortality
                         )

  <span style="color: #676E95;">##  </span><span style="color: #676E95;">combining h and x</span>
  flat_exp = at.switch(
    at.lt(x, 0.7), <span style="color: #676E95;"># </span><span style="color: #676E95;">if</span>
    at.exp(x), <span style="color: #676E95;"># </span><span style="color: #676E95;">then</span>
    at.exp(0.7*(x/0.7)**0.1) <span style="color: #676E95;"># </span><span style="color: #676E95;">else</span>
  )
  mortality_function = h*flat_exp

  <span style="color: #89DDFF;">with</span> baseline_model:
    <span style="color: #676E95;">## </span><span style="color: #676E95;">equation binomial distribution number of deaths:</span>
    m = pm.Deterministic(<span style="color: #c3e88d;">'m'</span>, mortality_function)
    obs = pm.Binomial(<span style="color: #c3e88d;">"obs"</span>, p = m,\
                      observed=mortality, n = population)
  <span style="color: #89DDFF;">return</span> baseline_model

baseline_model = build_model(deprivation_s,oop_s)
</pre>
</div>
</div>
</div>


<div id="outline-container-org1841c09" class="outline-4">
<h4 id="org1841c09"><span class="section-number-4">4.3.2.</span> run model and save trace</h4>
<div class="outline-text-4" id="text-4-3-2">
<p>
The following code samples from the posterior and then saves the trace to a file.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #89DDFF;">with</span> <span style="color: #ffcb6b;">baseline_model</span>:
    idata_baseline = pm.sample(target_accept=0.85)
    pm.sample_posterior_predictive(idata_baseline, \
                                   extend_inferencedata=<span style="color: #f78c6c;">True</span>)
</pre>
</div>

<p>
Output of the NUTS sampler:
</p>

<pre class="example">
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sd_prior_b, sd_prior_beta, mu_2_too, mu_t, b_oop, b_interaction, beta_age, mu_2_m, beta_lagged_log_mortality, beta_unmet, beta_poverty]

100.00% [8000/8000 1:18:29&lt;00:00 Sampling 4 chains, 57 divergences]

Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4711 seconds.
There were 49 divergences after tuning. Increase `target_accept` or reparameterize.
There was 1 divergence after tuning. Increase `target_accept` or reparameterize.
There were 7 divergences after tuning. Increase `target_accept` or reparameterize.

100.00% [4000/4000 00:26&lt;00:00]
</pre>

<p>
Out of 8000 samples, we have about 50 divergences. This is low enough not to tune the algorithm further.
</p>

<p>
We save the samples to file:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python">idata_baseline.to_netcdf(<span style="color: #c3e88d;">"./traces/baseline_model.nc"</span>)
</pre>
</div>

<pre class="example">
./traces/baseline_model.nc
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org5836620" class="outline-2">
<h2 id="org5836620"><span class="section-number-2">5.</span> Results</h2>
<div class="outline-text-2" id="text-5">
<p>
In this section we present the results of the estimation of the baseline model. Before presenting the outcome of our estimation, we present graphically two checks of our model.
</p>
</div>

<div id="outline-container-org6af2583" class="outline-3">
<h3 id="org6af2583"><span class="section-number-3">5.1.</span> model fit</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Figure <a href="#orge66aa9e">5</a> gives an idea of the fit of the model in terms of predicting deaths per gender/age/region/year category and the fraction of people postponing treatment because it is too expensive.
</p>

<p>
The left panel shows observed number of deaths per category on the horizontal axis and the posterior predictive for this on the vertical axis. For each row in our data, we have observed number of deaths and a prediction of this number. In the figure, we show the average prediction of deaths across the posterior samples. The predictions are not perfect but do follow the 45-degree line closely.
</p>

<p>
The right panel shows the (log odds of the) fraction of people per region/year indicating they went without treatment (for a while) because it was too expensive. Two things are different in this panel compared to the left. First, this fraction does not vary by gender and age. Hence, we do not have a prediction for each row in our data. Second, this fraction <code>TooExp</code> is based on (EU-SILC) survey data where we do not know the number of people interviewed. Hence, we cannot model this as a binomial distribution where we predict the number of people indicating unmet medical needs because of financial constraints.
</p>

<p>
Therefore, the right panel shows the observed and predicted fraction for <code>TooExp</code> per region/year. The dots indicate the average posterior prediction of this log-odds ratio. For small observed values of the <code>TooExp</code> (log-odds below \(-5\) in the figure) there is a range of predicted values. Although this range seems wide in log-odds space, both the observed and predicted values are basically equal to zero.
</p>

<p>
A final observation is that <code>TooExp</code> equals 0 for a number of region/year combinations. To handle this numerically, we use a lower bound for the log-odds. This corresponds to a probability of 0.0001 which is close enough to zero for our purposes. The right panel shows this bunching for a number of observations slightly below \(-9\).
</p>

<p>
Compared to the observed number of deaths, the predictions for <code>TooExp</code> seem less accurate. This is to be expected as there are a lot fewer observations for this variable compared to mortality. But all in all the fit does not seem unreasonable as the points cluster around the 45-degree line.
</p>



<div id="orge66aa9e" class="figure">
<p><img src="./figures/fit_baseline_model.png" alt="fit_baseline_model.png" />
</p>
<p><span class="figure-number">Figure 5: </span>Fit of estimated and observed mortality across all observations and observed and predicted fraction of people indicating <code>TooExp</code> across NUTS 2 regions.</p>
</div>

<p>
Another way to check how well the model fits, is to see how well it captures the age profile of mortality. This we present in Figure <a href="#org7ab8a9d">6</a>. The left panel shows the age profile \(\eta_{ag} = e^{\beta_{ag}}/(1+e^{\beta_{ag}})\). If the other terms in equation \eqref{org3dd0d6e} equal 0, \(\eta_{ag}\) gives the probability of death for category \(ag\). The right panel includes for every region and calendar year the correction on \(\eta_{ag}\) to yield mortality for that combination of gender/age/region/year. On average, the model captures the age profile perfectly.
</p>



<div id="org7ab8a9d" class="figure">
<p><img src="./figures/age_profile_baseline.png" alt="age_profile_baseline.png" />
</p>
<p><span class="figure-number">Figure 6: </span>Fit of average mortality by age</p>
</div>


<p>
The appendix presents two further checks of the model. Figure <a href="#orgd05479e">9</a> shows the trace plots for the parameters of interest. The figures in the left panel show the posterior distribution of the parameters in the figure. The coefficients <code>b_oop, b_interaction</code> vary by country and hence we have different colors for the distributions in these graphs. The <code>beta</code> parameters do not vary with country (or another index) and hence there is one color only. In the <code>beta</code> figures it is easy to see that there are four distributions per parameter. These correspond to the four chains that are sampled by the NUTS algorithm.
</p>

<p>
The right panels show the same samples but now ordered across the horizontal axis as they were drawn. We check these plots for the following three features. First, the plot should be stationary; that is, not trending upward or downward. This implies that the posterior mean of the coefficient is (more or less) constant as we sample. Second, there should be good mixing which translates in condensed zig-zagging. In other words, the algorithm manages to draw values across the whole domain of the posterior quickly after each other. Finally, the four chains cover the same regions. All three features are satisfied for all coefficients in the right panel of the figure.
</p>

<p>
Another check on the convergence of the algorithm are the r-hat values in Table <a href="#orgfaa2c26">6</a>. This table summarizes the posterior distribution for the slopes that we are interested in. It provides the mean and standard deviation for each of these parameters, the 95% probability/credibility intervals and the number of effective samples for each parameter. As the number of these samples is above 500 for all and above 1000 for most parameters, this looks fine. The final column presents the values for r-hat for each parameter. Since these are all equal (close) to one, we can be confident that the NUTS algorithm converged for these parameters.
</p>
</div>
</div>

<div id="outline-container-org526ef29" class="outline-3">
<h3 id="org526ef29"><span class="section-number-3">5.2.</span> size of effects</h3>
<div class="outline-text-3" id="text-5-2">
<p>
Table <a href="#orgfaa2c26">6</a> presents the values for each of the parameters. Here we focus on the effect we are interested in: what is the increase in mortality due to an increase in oop? As we show in the appendix, a 500 euro increase in oop leads to the following increase in mortality:
</p>
\begin{equation}
\label{org28669b2}
\frac{dm_{ga2t}}{m_{ga2t}} = \beta_{unmet} \text{TooExp}_{2t}(1-\text{TooExp}_{2t}) 500 (b_{oop,c}+b_{interaction,c} Poverty_{2t})
\end{equation}
<p>
Note that this increase in the number of deaths \(dm_{ga2t}\) per the number of deaths \(m_{ga2t}\) is independent of age. This is due to our formulation of mortality in equation \eqref{org3dd0d6e} where we have a baseline mortality \(\eta_{ag}\) and a deviation from this baseline based on poverty and unmet medical needs etc. Figure <a href="#orgeff8d5d">2</a> reports the expression in the equation above multiplied by 1000. That is, we report the increase in deaths due to the oop increase per 1000 deaths.
</p>

<p>
Note that the 500 euro change in <code>OOP</code> enters multiplicatively. In other words, dividing the effect in Figure <a href="#orgeff8d5d">2</a> by ten gives the effect of a 50 euro increase in <code>OOP</code> for each country. In this sense, the choice of 500 euro is a matter of presentation.<sup><a id="fnr.9" class="footref" href="#fn.9" role="doc-backlink">9</a></sup>
</p>

<p>
As the expression for \(dm/m\) varies with country, year and NUTS 2 region, Figure <a href="#orgeff8d5d">2</a> summarizes our main findings in the following way. For each country we focus on the region where deprivation is highest. This is the region where we expect the mortality effect of an oop increase to be highest as many people could have problems paying medical bills. Table <a href="#orgd77a371">2</a> presents this region for each country in our data together with the value of deprivation, the fraction of people with unmet medical needs due to financial constraints and the country's value for <code>OOP</code>. As the table illustrates, the fraction of people indicating that treatment was too expensive tends to be high when both deprivation and <code>OOP</code> are high.
</p>


<table id="orgd77a371" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 2:</span> Region per country with highest fraction of material deprivation.</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">region</th>
<th scope="col" class="org-left">country</th>
<th scope="col" class="org-right">deprivation</th>
<th scope="col" class="org-right">too expensive</th>
<th scope="col" class="org-right">OOP</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">BG33</td>
<td class="org-left">Bulgaria</td>
<td class="org-right">0.40</td>
<td class="org-right">0.08</td>
<td class="org-right">0.43</td>
</tr>

<tr>
<td class="org-left">HR04</td>
<td class="org-left">Croatia</td>
<td class="org-right">0.13</td>
<td class="org-right">0.01</td>
<td class="org-right">0.11</td>
</tr>

<tr>
<td class="org-left">DK02</td>
<td class="org-left">Denmark</td>
<td class="org-right">0.04</td>
<td class="org-right">0.00</td>
<td class="org-right">0.14</td>
</tr>

<tr>
<td class="org-left">FI1C</td>
<td class="org-left">Finland</td>
<td class="org-right">0.03</td>
<td class="org-right">0.00</td>
<td class="org-right">0.18</td>
</tr>

<tr>
<td class="org-left">EL63</td>
<td class="org-left">Greece</td>
<td class="org-right">0.28</td>
<td class="org-right">0.07</td>
<td class="org-right">0.37</td>
</tr>

<tr>
<td class="org-left">HU31</td>
<td class="org-left">Hungary</td>
<td class="org-right">0.32</td>
<td class="org-right">0.02</td>
<td class="org-right">0.28</td>
</tr>

<tr>
<td class="org-left">IE06</td>
<td class="org-left">Ireland</td>
<td class="org-right">0.07</td>
<td class="org-right">0.02</td>
<td class="org-right">0.12</td>
</tr>

<tr>
<td class="org-left">LT02</td>
<td class="org-left">Lithuania</td>
<td class="org-right">0.12</td>
<td class="org-right">0.01</td>
<td class="org-right">0.32</td>
</tr>

<tr>
<td class="org-left">NO01</td>
<td class="org-left">Norway</td>
<td class="org-right">0.02</td>
<td class="org-right">0.00</td>
<td class="org-right">0.14</td>
</tr>

<tr>
<td class="org-left">RO22</td>
<td class="org-left">Romania</td>
<td class="org-right">0.32</td>
<td class="org-right">0.11</td>
<td class="org-right">0.21</td>
</tr>

<tr>
<td class="org-left">SK04</td>
<td class="org-left">Slovakia</td>
<td class="org-right">0.11</td>
<td class="org-right">0.01</td>
<td class="org-right">0.20</td>
</tr>

<tr>
<td class="org-left">SI03</td>
<td class="org-left">Slovenia</td>
<td class="org-right">0.05</td>
<td class="org-right">0.00</td>
<td class="org-right">0.12</td>
</tr>

<tr>
<td class="org-left">SE22</td>
<td class="org-left">Sweden</td>
<td class="org-right">0.02</td>
<td class="org-right">0.00</td>
<td class="org-right">0.15</td>
</tr>

<tr>
<td class="org-left">CH01</td>
<td class="org-left">Switzerland</td>
<td class="org-right">0.02</td>
<td class="org-right">0.02</td>
<td class="org-right">0.26</td>
</tr>
</tbody>
</table>

<p>
Substituting these values from the table into the expression for \(dm/m\) we get the numbers in Figure <a href="#orgeff8d5d">2</a>. As mentioned, the blue bars give the average effect of the 500 euro increase in oop on mortality. As we have the posterior distributions for each of the parameters, we also have the posterior distribution for the mortality effects per country. The black horizontal lines present the 95% intervals around the mean effect.
</p>

<p>
The first observation is that for Bulgaria, Greece, Hungary and Romania the 95% probability interval is bounded away from zero. For these countries we can clearly see that an increase in oop negatively affects health and increases mortality.
</p>

<p>
Why are the effects smaller for the other countries? The effects are basically zero for the Scandinavian countries, Slovenia and Switzerland. As shown in Table <a href="#orgd77a371">2</a>, for these countries both deprivation and the fraction of people indicating unmet medical needs because treatment is too expensive are small. For the Scandinavian countries in the region with highest deprivation, <code>TooExp</code> is basically zero. It then follows from equation \eqref{org28669b2} that the effect on mortality is (close to) zero.
</p>

<p>
The equation also features the following positive second derivative effect. As <code>OOP</code> increases, <code>TooExp</code> increases (especially in regions with high deprivation). This increases the mortality effect of a further increase in <code>OOP</code>.<sup><a id="fnr.10" class="footref" href="#fn.10" role="doc-backlink">10</a></sup> Hence, the effect of an increase in <code>OOP</code> is bigger, the higher the starting point of <code>OOP</code>. Countries where <code>OOP</code> is already high, should be careful increasing it further because the detrimental health effects are stronger. In contrast, low initial values for <code>OOP</code> and <code>TooExp</code> imply that an increase in oop expenditure hardly affects health and mortality.
</p>

<p>
Another reason why the effects are small for some countries is that the underlying parameters <code>b_oop, b_interaction</code> are small for these countries. This can be seen in Table <a href="#orgfaa2c26">6</a> in the appendix. If countries have policies to subsidize healthcare for poor families, the effect of country wide <code>OOP</code> on these families' unmet medical needs is small as they actually pay a lower fraction of their treatments' costs oop.
</p>

<p>
Summarizing, we can identify in our data the effect that an oop increase, raises the number of people with unmet medical needs due to financial constraints and hence increases mortality. This is especially the case in regions with high poverty and high initial <code>OOP</code>. Confirming this effect was the main objective of the paper.
</p>

<p>
A follow up question is: how big is this effect? In order to interpret the size of the oop effect, Table <a href="#org7fba337">3</a> presents the number of people dying from a particular cause per 1000 dead.<sup><a id="fnr.11" class="footref" href="#fn.11" role="doc-backlink">11</a></sup> If we would consider all causes and add them up, the sum of the second column in Table <a href="#org7fba337">3</a> would equal 1000. The table focuses on causes of death with an order of magnitude comparable to the effects in Figure <a href="#orgeff8d5d">2</a>. The table is based on EU wide data in 2017 for ages 35-85.
</p>

<p>
Note that the comparison of the numbers in the figure with the numbers in the table is just to get an idea of the order of magnitude. But &#x2013;strictly speaking&#x2013; the causes are not comparable. Nobody dies of an increase in oop in the way people die from pneumonia. Due to an increase in oop, people may have gone without treatment which can then lead to death from, say, lung cancer. Hence, one should be careful in interpreting the simulation results with the numbers in Table <a href="#org7fba337">3</a>. But the table does provide some context in interpreting the size of the simulated effects.
</p>

<table id="org7fba337" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 3:</span> Number of people dying by cause (per 1000 dead) for ages 35-85 (EU average).</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">icd10</th>
<th scope="col" class="org-right">per 1000</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Malignant neoplasm of breast</td>
<td class="org-right">23.66</td>
</tr>

<tr>
<td class="org-left">Malignant neoplasm of prostate</td>
<td class="org-right">16.16</td>
</tr>

<tr>
<td class="org-left">Malignant neoplasm of bladder</td>
<td class="org-right">9.72</td>
</tr>

<tr>
<td class="org-left">Diabetes mellitus</td>
<td class="org-right">22.59</td>
</tr>

<tr>
<td class="org-left">Mental and behavioural disorders</td>
<td class="org-right">26.85</td>
</tr>

<tr>
<td class="org-left">Parkinson disease</td>
<td class="org-right">9.17</td>
</tr>

<tr>
<td class="org-left">Alzheimer disease</td>
<td class="org-right">13.08</td>
</tr>

<tr>
<td class="org-left">Pneumonia</td>
<td class="org-right">19.74</td>
</tr>

<tr>
<td class="org-left">Transport accidents</td>
<td class="org-right">5.90</td>
</tr>
</tbody>
</table>

<p>
The average mortality effect due to a 500 euro increase in oop in Romania is approximately 33 (per 1000 dead). This exceeds deaths due to each of the causes in the table. The average effects in Bulgaria and Greece are around 15 and 22 resp. which places them between deaths due to Alzheimer disease and diabetes. In Hungary the order of magnitude is comparable to deaths due to transport accidents.
</p>

<p>
However, these are effects aggregated at the regional level (of the regions with highest poverty levels). Suppose we are willing to assume that the incidence of the increase in mortality due to the 500 euro increase in oop falls mainly in the group of people who live in material deprivation. Table <a href="#orgd77a371">2</a> shows this is around 30% for the relevant regions in Greece, Hungary and Romania. To get these effects at the region level, the effects among this specific group is an order of magnitude bigger.
</p>

<p>
Finally, there is also the following dynamic effect. As oop increases, 35 year olds postpone treatments thereby lowering their health status. Part of this reduced health leads to higher mortality among 35 year olds but some of these people survive this year. Next year, they start with lower than average health which can then raise mortality among 36 year olds. These dynamic feedback effects are captured by the parameter \(\gamma\) in Lemma <a href="#orgeb785f9">1</a>. As shown in Table <a href="#orgfaa2c26">6</a> in the appendix, the estimated value for \(\gamma\) is approximately 0.5 (coefficient <code>beta_lagged_log_mortality</code>). As effects accumulate across age and time, the effect for 85 year olds almost doubles (\(1+\gamma+...+\gamma^{50} \approx 2\)). To illustrate, the long run effect of a 500 euro increase in <code>OOP</code> leads to 66 deaths per 1000 dead for 85 year old Romanians in its poorest region.
</p>

<p>
One of the advantages of doing a Bayesian analysis is that we can easily show the uncertainty surrounding our estimated effects. This is illustrated in Figure <a href="#org9b136f4">7</a> where we show for eight Romanian regions the probability that the mortality effect exceeds a certain value. Region RO22 tends to have the biggest effect (reported in Figure <a href="#orgeff8d5d">2</a>), while the effect per 1000 dead is smallest in NUTS 2 region RO42. We are pretty sure (probability close to 1) that in RO22 the effect is at least 15 per 1000 dead. While in RO42 this probability is less than 40%. In RO42 we are 80% sure that the effect exceeds 10 per 1000 dead. This is due to the fact that both <code>deprivation</code> and <code>too expensive</code> are substantially lower in RO42 compared to RO22.
</p>


<div id="org9b136f4" class="figure">
<p><img src="./figures/Effect_RO.png" alt="Effect_RO.png" />
</p>
<p><span class="figure-number">Figure 7: </span>Uncertainty of the mortality effects in eight NUTS 2 regions in Romania.</p>
</div>

<p>
Summarizing the discussion on the size of the effect, we find the following. In countries where poverty and <code>OOP</code> are high, a 500 euro further increase in oop leads to an increase in mortality (per 1000 dead) that is comparable to causes varying from Alzheimer disease to diabetes or breast cancer.
</p>
</div>
</div>

<div id="outline-container-org1b851f8" class="outline-3">
<h3 id="org1b851f8"><span class="section-number-3">5.3.</span> model fit and size of the effects&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></h3>
<div class="outline-text-3" id="text-5-3">
<p>
Here we provide the code that generates the results on model fit and size of the effects discussed in this section.
</p>
</div>


<div id="outline-container-orgd134383" class="outline-4">
<h4 id="orgd134383"><span class="section-number-4">5.3.1.</span> reading in existing trace</h4>
<div class="outline-text-4" id="text-5-3-1">
<p>
Read in the trace if the model was run before:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">idata_baseline</span> = az.from_netcdf(<span style="color: #c3e88d;">"./traces/baseline_model.nc"</span>)
</pre>
</div>
</div>
</div>


<div id="outline-container-org3d971ae" class="outline-4">
<h4 id="org3d971ae"><span class="section-number-4">5.3.2.</span> model fit</h4>
<div class="outline-text-4" id="text-5-3-2">
<p>
This section presents the code generating the figures that we use as a check on the fit of the model. As explained in the main text: for the mortality equation we check the fit using the posterior predictive. For <code>TooExp</code> we only have predictions for each NUTS 2/calendar year combination (not for every row in our dataframe). Hence, for the latter we plot the parameter <code>mu_too_exp_lo</code> and the 95% probability interval.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">my_predictions_mort</span> = np.mean(idata_baseline.posterior_predictive.\
                              obs,axis=(0,1))
my_predictions_too  = np.mean((idata_baseline.posterior.\
                          mu_too_exp_lo.values),axis=(0,1))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python">plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
fig, (<span style="color: #ffcb6b;">ax1</span>,<span style="color: #ffcb6b;">ax2</span>) = plt.subplots(1,2, dpi=280,figsize=(12,6))
ax1.scatter(mortality,my_predictions_mort)
ax1.plot([0,1000],[0,1000],<span style="color: #c3e88d;">'k'</span>)
ax1.set_xlabel(<span style="color: #c3e88d;">'observed number of deaths'</span>)
ax1.set_ylabel(<span style="color: #c3e88d;">'predicted number of deaths'</span>)
ax1.set_title(\
  <span style="color: #c3e88d;">'Number of deaths across\nNUTS 2 region, year, age, gender'</span>)
ax2.plot([-9,-1.5],[-9,-1.5],<span style="color: #c3e88d;">'k'</span>)
ax2.scatter((too_exp_lo),(my_predictions_too))
<span style="color: #676E95;"># </span><span style="color: #676E95;">ax2.vlines(too_exp_lo,my_predictions_too_25,my_predictions_too_975,</span>
<span style="color: #676E95;">#            </span><span style="color: #676E95;">colors='k',linewidth=1)</span>
ax2.set_xlabel(<span style="color: #c3e88d;">'observed too expensive (log odds)'</span>)
ax2.set_ylabel(<span style="color: #c3e88d;">'predicted too expensive (log odds)'</span>)
ax2.set_title(\
  <span style="color: #c3e88d;">'Fraction indicating TooExp across\nNUTS 2 region and year'</span>);
</pre>
</div>




<div id="org3a4c3fe" class="figure">
<p><img src="./figures/fit_baseline_model.png" alt="fit_baseline_model.png" />
</p>
</div>

<p>
The following code presents the baseline age profile <code>h</code> and the average mortality rate predicted by the model and the average in our data.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">beta_age</span> = idata_baseline.posterior.beta_age.values
<span style="color: #ffcb6b;">h</span> = at.sigmoid(beta_age).<span style="color: #82aaff;">eval</span>()
plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
fig, (<span style="color: #ffcb6b;">ax1</span>,<span style="color: #ffcb6b;">ax2</span>) = plt.subplots(1,2, dpi=280,figsize=(12,6))
ax1.plot(plot_age,np.mean(h[:,:,:,0],axis=(0,1))*100000,\
         label=<span style="color: #c3e88d;">'female'</span>)
ax1.plot(plot_age,np.mean(h[:,:,:,1],axis=(0,1))*100000,\
         label=<span style="color: #c3e88d;">'male'</span>)
ax1.set_title(<span style="color: #c3e88d;">'sigmoid($\\beta_{age,gender}$)*100k'</span>)
ax1.set_xlabel(<span style="color: #c3e88d;">'age'</span>)
ax1.set_ylabel(<span style="color: #c3e88d;">'mortality per 100k'</span>)
<span style="color: #676E95;"># </span><span style="color: #676E95;">ax1.legend();</span>

df_groupby = df[[<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>,<span style="color: #c3e88d;">'mortality'</span>]].\
    groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>]).mean().reset_index()

df[<span style="color: #c3e88d;">'mean_predicted_m'</span>] = np.mean(idata_baseline.posterior.m.values,\
                                 axis=(0,1))
df[<span style="color: #c3e88d;">'lambda'</span>] = np.mean(np.exp(idata_baseline.posterior.x.values),\
                       axis=(0,1))
groupby_mortality = df[[<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>,<span style="color: #c3e88d;">'mean_predicted_m'</span>,<span style="color: #c3e88d;">'lambda'</span>]].\
    groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>]).mean().reset_index()
s = groupby_mortality.agg(<span style="color: #c3e88d;">'nunique'</span>)
predicted_mortality_array = groupby_mortality.mean_predicted_m.\
    values.reshape(s[<span style="color: #c3e88d;">'age'</span>],s[<span style="color: #c3e88d;">'sex'</span>])
age_pattern_female = predicted_mortality_array[:,0]
age_pattern_male = predicted_mortality_array[:,1]
ax2.plot(plot_age,100000*age_pattern_female,label=<span style="color: #c3e88d;">'female'</span>)
ax2.plot(plot_age,100000*age_pattern_male,label=<span style="color: #c3e88d;">'male'</span>)
ax2.plot(np.arange(35,86),1000*df_groupby[df_groupby.sex==<span style="color: #c3e88d;">'F'</span>].\
         mortality,<span style="color: #c3e88d;">'k.'</span>,label=<span style="color: #c3e88d;">'observed'</span>)
ax2.plot(np.arange(35,86),1000*df_groupby[df_groupby.sex==<span style="color: #c3e88d;">'M'</span>].\
         mortality,<span style="color: #c3e88d;">'k.'</span>)
ax2.set_title(\
  <span style="color: #c3e88d;">'Predicted and observed mortality per 100k population'</span>)
ax2.set_xlabel(<span style="color: #c3e88d;">'age'</span>)
ax2.legend();
</pre>
</div>


<div id="org17378be" class="figure">
<p><img src="./figures/age_profile_baseline.png" alt="age_profile_baseline.png" />
</p>
</div>
</div>
</div>


<div id="outline-container-org40dcbe4" class="outline-4">
<h4 id="org40dcbe4"><span class="section-number-4">5.3.3.</span> size of the effects</h4>
<div class="outline-text-4" id="text-5-3-3">
<p>
This section provides the python code that illustrates the size of the effect of a 500 euro increase in oop on mortality. For this we need to know the posterior distribution for the parameters of interest that allow us to calculate this effect:
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">variables</span> = [<span style="color: #c3e88d;">'beta_unmet'</span>,<span style="color: #c3e88d;">'beta_lagged_log_mortality'</span>,\
             <span style="color: #c3e88d;">'beta_poverty'</span>,<span style="color: #c3e88d;">'b_oop'</span>, <span style="color: #c3e88d;">'b_interaction'</span>,\
             <span style="color: #c3e88d;">'sd_prior_b'</span>,<span style="color: #c3e88d;">'sd_prior_beta'</span>]
</pre>
</div>

<p>
For these parameters we present the trace plot and the table with the mean parameter values, 94% highest density interval and the value for <code>r_hat</code>.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python">az.plot_trace(idata_baseline,var_names=variables,\
              divergences=<span style="color: #f78c6c;">None</span>,figsize=(20,18),compact=<span style="color: #f78c6c;">True</span>);
</pre>
</div>


<div id="org70ca19c" class="figure">
<p><img src="./figures/trace_plot_baseline.png" alt="trace_plot_baseline.png" />
</p>
</div>





<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">headers</span> = [<span style="color: #c3e88d;">'mean'</span>, <span style="color: #c3e88d;">'sd'</span>, <span style="color: #c3e88d;">'hdi_3%'</span>, <span style="color: #c3e88d;">'hdi_97%'</span>,\
           <span style="color: #c3e88d;">'ess_bulk'</span>, <span style="color: #c3e88d;">'r_hat'</span>]

<span style="color: #ffcb6b;">df_summary</span> = az.summary(idata_baseline,var_names=variables)[headers]
<span style="color: #82aaff;">print</span>(tabulate(df_summary,\
               headers,tablefmt=<span style="color: #c3e88d;">'orgtbl'</span>,floatfmt=<span style="color: #c3e88d;">".2f"</span>))
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">mean</th>
<th scope="col" class="org-right">sd</th>
<th scope="col" class="org-right">hdi_3%</th>
<th scope="col" class="org-right">hdi_97%</th>
<th scope="col" class="org-right">ess_bulk</th>
<th scope="col" class="org-right">r_hat</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">beta_unmet</td>
<td class="org-right">0.09</td>
<td class="org-right">0.02</td>
<td class="org-right">0.06</td>
<td class="org-right">0.13</td>
<td class="org-right">2507.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">beta_lagged_log_mortality</td>
<td class="org-right">0.54</td>
<td class="org-right">0.00</td>
<td class="org-right">0.53</td>
<td class="org-right">0.54</td>
<td class="org-right">2535.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">beta_poverty</td>
<td class="org-right">0.01</td>
<td class="org-right">0.01</td>
<td class="org-right">0.00</td>
<td class="org-right">0.01</td>
<td class="org-right">2840.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Bulgaria]</td>
<td class="org-right">0.83</td>
<td class="org-right">0.64</td>
<td class="org-right">0.00</td>
<td class="org-right">2.00</td>
<td class="org-right">1230.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Croatia]</td>
<td class="org-right">1.91</td>
<td class="org-right">1.50</td>
<td class="org-right">0.00</td>
<td class="org-right">4.60</td>
<td class="org-right">1245.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Denmark]</td>
<td class="org-right">2.54</td>
<td class="org-right">0.52</td>
<td class="org-right">1.57</td>
<td class="org-right">3.54</td>
<td class="org-right">855.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Finland]</td>
<td class="org-right">0.04</td>
<td class="org-right">0.04</td>
<td class="org-right">0.00</td>
<td class="org-right">0.11</td>
<td class="org-right">3337.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Greece]</td>
<td class="org-right">20.01</td>
<td class="org-right">0.64</td>
<td class="org-right">18.77</td>
<td class="org-right">21.14</td>
<td class="org-right">928.00</td>
<td class="org-right">1.01</td>
</tr>

<tr>
<td class="org-left">b_oop[Hungary]</td>
<td class="org-right">0.12</td>
<td class="org-right">0.12</td>
<td class="org-right">0.00</td>
<td class="org-right">0.34</td>
<td class="org-right">2260.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Ireland]</td>
<td class="org-right">6.64</td>
<td class="org-right">0.85</td>
<td class="org-right">4.90</td>
<td class="org-right">8.11</td>
<td class="org-right">1264.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Lithuania]</td>
<td class="org-right">3.44</td>
<td class="org-right">1.49</td>
<td class="org-right">0.62</td>
<td class="org-right">6.07</td>
<td class="org-right">1811.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Norway]</td>
<td class="org-right">0.03</td>
<td class="org-right">0.03</td>
<td class="org-right">0.00</td>
<td class="org-right">0.07</td>
<td class="org-right">3025.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Romania]</td>
<td class="org-right">13.61</td>
<td class="org-right">1.70</td>
<td class="org-right">10.36</td>
<td class="org-right">16.65</td>
<td class="org-right">1041.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Slovakia]</td>
<td class="org-right">1.90</td>
<td class="org-right">1.10</td>
<td class="org-right">0.00</td>
<td class="org-right">3.75</td>
<td class="org-right">757.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Slovenia]</td>
<td class="org-right">0.33</td>
<td class="org-right">0.31</td>
<td class="org-right">0.00</td>
<td class="org-right">0.91</td>
<td class="org-right">2474.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Sweden]</td>
<td class="org-right">0.48</td>
<td class="org-right">0.27</td>
<td class="org-right">0.00</td>
<td class="org-right">0.94</td>
<td class="org-right">539.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Switzerland]</td>
<td class="org-right">0.02</td>
<td class="org-right">0.02</td>
<td class="org-right">0.00</td>
<td class="org-right">0.06</td>
<td class="org-right">2059.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Bulgaria]</td>
<td class="org-right">27.49</td>
<td class="org-right">2.05</td>
<td class="org-right">23.74</td>
<td class="org-right">31.33</td>
<td class="org-right">1695.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Croatia]</td>
<td class="org-right">2.45</td>
<td class="org-right">1.88</td>
<td class="org-right">0.00</td>
<td class="org-right">5.88</td>
<td class="org-right">1535.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Denmark]</td>
<td class="org-right">36.41</td>
<td class="org-right">3.16</td>
<td class="org-right">30.67</td>
<td class="org-right">42.50</td>
<td class="org-right">2411.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Finland]</td>
<td class="org-right">0.71</td>
<td class="org-right">0.68</td>
<td class="org-right">0.00</td>
<td class="org-right">1.93</td>
<td class="org-right">2556.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Greece]</td>
<td class="org-right">3.80</td>
<td class="org-right">2.32</td>
<td class="org-right">0.01</td>
<td class="org-right">7.75</td>
<td class="org-right">1226.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Hungary]</td>
<td class="org-right">56.73</td>
<td class="org-right">2.68</td>
<td class="org-right">51.98</td>
<td class="org-right">61.99</td>
<td class="org-right">1006.00</td>
<td class="org-right">1.01</td>
</tr>

<tr>
<td class="org-left">b_interaction[Ireland]</td>
<td class="org-right">3.08</td>
<td class="org-right">2.17</td>
<td class="org-right">0.00</td>
<td class="org-right">6.93</td>
<td class="org-right">2799.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Lithuania]</td>
<td class="org-right">2.70</td>
<td class="org-right">1.96</td>
<td class="org-right">0.00</td>
<td class="org-right">6.11</td>
<td class="org-right">1987.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Norway]</td>
<td class="org-right">25.39</td>
<td class="org-right">2.90</td>
<td class="org-right">20.18</td>
<td class="org-right">30.88</td>
<td class="org-right">1989.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Romania]</td>
<td class="org-right">18.73</td>
<td class="org-right">2.95</td>
<td class="org-right">13.12</td>
<td class="org-right">24.03</td>
<td class="org-right">2239.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Slovakia]</td>
<td class="org-right">1.23</td>
<td class="org-right">1.08</td>
<td class="org-right">0.00</td>
<td class="org-right">3.24</td>
<td class="org-right">2618.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Slovenia]</td>
<td class="org-right">2.08</td>
<td class="org-right">1.62</td>
<td class="org-right">0.01</td>
<td class="org-right">5.05</td>
<td class="org-right">2362.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Sweden]</td>
<td class="org-right">10.35</td>
<td class="org-right">2.81</td>
<td class="org-right">5.01</td>
<td class="org-right">15.45</td>
<td class="org-right">1722.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Switzerland]</td>
<td class="org-right">22.36</td>
<td class="org-right">1.70</td>
<td class="org-right">19.20</td>
<td class="org-right">25.55</td>
<td class="org-right">1927.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">sd_prior_b</td>
<td class="org-right">2.94</td>
<td class="org-right">0.08</td>
<td class="org-right">2.79</td>
<td class="org-right">3.08</td>
<td class="org-right">1391.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">sd_prior_beta</td>
<td class="org-right">0.22</td>
<td class="org-right">0.04</td>
<td class="org-right">0.14</td>
<td class="org-right">0.31</td>
<td class="org-right">3505.00</td>
<td class="org-right">1.00</td>
</tr>
</tbody>
</table>


<p>
The function <code>Delta_log_mortality</code> is the python code for equation \eqref{org28669b2}. To use this function at the NUTS 2 level where <code>deprivation</code> is highest per country, we define a new dataframe at the NUTS 2 level using <code>groupby</code>. To be able to multiply the coefficients and the data using broadcasting, we introduce 5 dimensions for each variable. The order of the dimensions is: chain, samples, countries, nuts2, observations.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">df_nuts2</span> = df[[<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'poverty'</span>,<span style="color: #c3e88d;">'deprivation'</span>,\
            <span style="color: #c3e88d;">'unmet'</span>,<span style="color: #c3e88d;">'TOOEXP'</span>,<span style="color: #c3e88d;">'health expenditure per capita'</span>,<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]].\
            groupby([<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>]).mean().reset_index()
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'poverty_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'poverty'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'deprivation_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'deprivation'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'unmet_s'</span>] = (df_nuts2.unmet)/100.0
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'too_exp_s'</span>] = df_nuts2.TOOEXP/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'oop_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]/100

<span style="color: #ffcb6b;">poverty_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'poverty_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">deprivation_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">unmet_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'unmet_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">too_exp_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'too_exp_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]

<span style="color: #ffcb6b;">beta_unmet</span> = idata_baseline.posterior.beta_unmet.\
    values[:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_oop</span> = idata_baseline.posterior.b_oop.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_interaction</span> = idata_baseline.posterior.b_interaction.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">Delta_log_mortality</span>(p_too_exp,Delta_OOP,alpha):
    <span style="color: #89DDFF;">return</span> beta_unmet * p_too_exp*(1-p_too_exp) * \
        Delta_OOP * (b_oop + b_interaction * alpha)
</pre>
</div>

<p>
The groupby <code>df_nuts2</code> takes the average across time (and age/sex) for each NUTS 2 region. To aggregate this to the country level, we focus on the Nuts 2 region with highest deprivation fraction. For this region (with highest deprivation per country), we calculate \(\Delta \ln(m)\) due to a 500 euro increase in oop.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">idx</span> = df_nuts2.groupby([<span style="color: #c3e88d;">'country'</span>])[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    transform(<span style="color: #82aaff;">max</span>) == df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>]
<span style="color: #ffcb6b;">df_country</span> = df_nuts2[idx].sort_values([<span style="color: #c3e88d;">'country'</span>]).\
    drop_duplicates(subset=<span style="color: #c3e88d;">'country'</span>,keep=<span style="color: #c3e88d;">'last'</span>)
depr_country = df_country.deprivation_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
too_exp_country = df_country.too_exp_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
delta_oop = 500
Delta_log_m = Delta_log_mortality(too_exp_country,\
  delta_oop/std_expenditure,depr_country).mean(axis=(0,1))
</pre>
</div>

<p>
The regions per country that have the highest rate of deprivation are given in the following table.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #89DDFF;">from</span> tabulate <span style="color: #89DDFF;">import</span> tabulate
<span style="color: #82aaff;">print</span>(tabulate(df_country[[<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'deprivation_s'</span>,\
    <span style="color: #c3e88d;">'too_exp_s'</span>,<span style="color: #c3e88d;">'oop_s'</span>]],headers=[<span style="color: #c3e88d;">'region'</span>,<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'deprivation'</span>,\
                           <span style="color: #c3e88d;">'too expensive'</span>,<span style="color: #c3e88d;">'OOP'</span>],
               tablefmt=<span style="color: #c3e88d;">"orgtbl"</span>,floatfmt=<span style="color: #c3e88d;">".2f"</span>))
</pre>
</div>



<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">region</th>
<th scope="col" class="org-left">country</th>
<th scope="col" class="org-right">deprivation</th>
<th scope="col" class="org-right">too expensive</th>
<th scope="col" class="org-right">OOP</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">BG33</td>
<td class="org-left">Bulgaria</td>
<td class="org-right">0.40</td>
<td class="org-right">0.08</td>
<td class="org-right">0.43</td>
</tr>

<tr>
<td class="org-left">HR04</td>
<td class="org-left">Croatia</td>
<td class="org-right">0.13</td>
<td class="org-right">0.01</td>
<td class="org-right">0.11</td>
</tr>

<tr>
<td class="org-left">DK02</td>
<td class="org-left">Denmark</td>
<td class="org-right">0.04</td>
<td class="org-right">0.00</td>
<td class="org-right">0.14</td>
</tr>

<tr>
<td class="org-left">FI1C</td>
<td class="org-left">Finland</td>
<td class="org-right">0.03</td>
<td class="org-right">0.00</td>
<td class="org-right">0.18</td>
</tr>

<tr>
<td class="org-left">EL63</td>
<td class="org-left">Greece</td>
<td class="org-right">0.28</td>
<td class="org-right">0.07</td>
<td class="org-right">0.37</td>
</tr>

<tr>
<td class="org-left">HU31</td>
<td class="org-left">Hungary</td>
<td class="org-right">0.32</td>
<td class="org-right">0.02</td>
<td class="org-right">0.28</td>
</tr>

<tr>
<td class="org-left">IE06</td>
<td class="org-left">Ireland</td>
<td class="org-right">0.07</td>
<td class="org-right">0.02</td>
<td class="org-right">0.12</td>
</tr>

<tr>
<td class="org-left">LT02</td>
<td class="org-left">Lithuania</td>
<td class="org-right">0.12</td>
<td class="org-right">0.01</td>
<td class="org-right">0.32</td>
</tr>

<tr>
<td class="org-left">NO01</td>
<td class="org-left">Norway</td>
<td class="org-right">0.02</td>
<td class="org-right">0.00</td>
<td class="org-right">0.14</td>
</tr>

<tr>
<td class="org-left">RO22</td>
<td class="org-left">Romania</td>
<td class="org-right">0.32</td>
<td class="org-right">0.11</td>
<td class="org-right">0.21</td>
</tr>

<tr>
<td class="org-left">SK04</td>
<td class="org-left">Slovakia</td>
<td class="org-right">0.11</td>
<td class="org-right">0.01</td>
<td class="org-right">0.20</td>
</tr>

<tr>
<td class="org-left">SI03</td>
<td class="org-left">Slovenia</td>
<td class="org-right">0.05</td>
<td class="org-right">0.00</td>
<td class="org-right">0.12</td>
</tr>

<tr>
<td class="org-left">SE22</td>
<td class="org-left">Sweden</td>
<td class="org-right">0.02</td>
<td class="org-right">0.00</td>
<td class="org-right">0.15</td>
</tr>

<tr>
<td class="org-left">CH01</td>
<td class="org-left">Switzerland</td>
<td class="org-right">0.02</td>
<td class="org-right">0.02</td>
<td class="org-right">0.26</td>
</tr>
</tbody>
</table>




<p>
We plot the average mortality increase per 1000 dead due to the 500 euro oop increase for each of the countries and the 95% probability interval. For the countries where there is indeed a substantial effect, the 95% probability interval does not include 0.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python">plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
fig, (<span style="color: #ffcb6b;">ax1</span>) = plt.subplots(1,1,dpi=280,figsize=(6,6))
y_pos = np.arange(N_countries)
xerr = np.percentile(Delta_log_mortality(too_exp_country,\
        delta_oop/std_expenditure,depr_country),\
        [2.5,97.5],axis=(0,1)).squeeze(axis=(2,3)) -\
        Delta_log_m.flatten()

fig.suptitle(<span style="color: #c3e88d;">'Effect of {} Euro oop increase on mortality'</span>.\
             <span style="color: #82aaff;">format</span>(delta_oop),fontsize=14)
ax1.barh(y_pos,Delta_log_m.flatten()*1000,\
         xerr = np.<span style="color: #82aaff;">abs</span>(xerr)*1000, \
         align=<span style="color: #c3e88d;">'center'</span>,label=<span style="color: #c3e88d;">'average effect'</span>)
ax1.set_yticks(y_pos, labels=country_list)
ax1.invert_yaxis()  <span style="color: #676E95;"># </span><span style="color: #676E95;">labels read top-to-bottom</span>
ax1.legend(loc = <span style="color: #c3e88d;">'lower right'</span>)
ax1.set_xlabel(<span style="color: #c3e88d;">'$\Delta$ mortality per 1000 dead'</span>);
</pre>
</div>


<div id="orgb23fd35" class="figure">
<p><img src="./figures/change_mortality_countries_baseline.png" alt="change_mortality_countries_baseline.png" />
</p>
</div>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">Delta_log_mortality_RO</span>(p_too_exp,Delta_OOP,alpha):
    <span style="color: #89DDFF;">return</span> beta_unmet * p_too_exp*(1-p_too_exp) * \
        Delta_OOP * (b_oop[:,:,9,:,:][:,:,<span style="color: #f78c6c;">None</span>,:,:] + b_interaction[:,:,9,:,:][:,:,<span style="color: #f78c6c;">None</span>,:,:] * alpha)
<span style="color: #ffcb6b;">df_RO</span> = df_nuts2[df_nuts2.country==<span style="color: #c3e88d;">'Romania'</span>]
depr_RO = df_RO.deprivation_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
too_exp_RO = df_RO.too_exp_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
delta_oop = 500
Delta_log_m_RO = Delta_log_mortality_RO(too_exp_RO,\
  delta_oop/std_expenditure,depr_RO)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">range_d</span> = np.linspace(0,0.06,50)
<span style="color: #ffcb6b;">N_samples</span> = beta_unmet.shape[0]*beta_unmet.shape[1]
<span style="color: #ffcb6b;">fraction_greater_than</span> = (Delta_log_m_RO &gt; range_d).<span style="color: #82aaff;">sum</span>(axis=(0,1))/N_samples
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python">plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
fig, (<span style="color: #ffcb6b;">ax1</span>) = plt.subplots(1,1,dpi=280,figsize=(6,6))
<span style="color: #89DDFF;">for</span> i <span style="color: #89DDFF;">in</span> <span style="color: #82aaff;">range</span>(fraction_greater_than.shape[0]):
    ax1.plot(range_d*1000,fraction_greater_than[i,0,:],label=df_RO.nuts2.iloc[i])

plt.title(<span style="color: #c3e88d;">'Probability that in Romania 500 euro increase\nin OOP exceeds number of deaths per 1000'</span>)
ax1.set_xlabel(<span style="color: #c3e88d;">'$\Delta$ mortality per 1000 dead'</span>)
ax1.set_ylabel(<span style="color: #c3e88d;">'Probability'</span>)
ax1.legend();
</pre>
</div>


<div id="orgf199ed7" class="figure">
<p><img src="./figures/Effect_RO.png" alt="Effect_RO.png" />
</p>
</div>
</div>
</div>




<div id="outline-container-org1ca7642" class="outline-4">
<h4 id="org1ca7642"><span class="section-number-4">5.3.4.</span> comparing to other causes of death</h4>
<div class="outline-text-4" id="text-5-3-4">
<p>
To get an idea of the magnitude of the mortality effect of the increase of oop, we compare it to the number of deaths (per 1000 dead) due to other causes that have a similar order of magnitude. For this we use EU data on causes of death for different age-classes. We focus on the class from age 35 till 85 and take the average across the EU for the calendar year 2017.
The <a href="https://ec.europa.eu/eurostat/databrowser/view/hlth_cd_aro/default/table?lang=en">Eurostat</a> website contains the names for the icd-10 codes that we use. We focus on causes with less than 30 deaths per 1000 dead. In the main text we use the table below for a subset of causes.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #89DDFF;">from</span> country_codes <span style="color: #89DDFF;">import</span> eurostat_dictionary
<span style="color: #89DDFF;">import</span> eurostat
<span style="color: #ffcb6b;">df</span> = eurostat.get_data_df(<span style="color: #c3e88d;">'hlth_cd_aro'</span>)
df.rename({<span style="color: #c3e88d;">'geo\\time'</span>:<span style="color: #c3e88d;">'geo'</span>},inplace=<span style="color: #f78c6c;">True</span>,axis=1)
df[<span style="color: #c3e88d;">'country'</span>] = df[<span style="color: #c3e88d;">'geo'</span>].replace(eurostat_dictionary)
df = df[(df.age.isin([<span style="color: #c3e88d;">'Y35-39'</span>, <span style="color: #c3e88d;">'Y40-44'</span>, <span style="color: #c3e88d;">'Y45-49'</span>, <span style="color: #c3e88d;">'Y50-54'</span>,\
                      <span style="color: #c3e88d;">'Y55-59'</span>,<span style="color: #c3e88d;">'Y60-64'</span>, <span style="color: #c3e88d;">'Y65-69'</span>, <span style="color: #c3e88d;">'Y70-74'</span>,\
                      <span style="color: #c3e88d;">'Y75-79'</span>,<span style="color: #c3e88d;">'Y80-84'</span>])) &amp; \
        (df.unit.isin([<span style="color: #c3e88d;">'NR'</span>])) &amp; (df[<span style="color: #c3e88d;">'resid'</span>].\
                                  isin([<span style="color: #c3e88d;">'TOT_IN'</span>])) &amp; \
        (df.sex.isin([<span style="color: #c3e88d;">'T'</span>]))]
df_eu = df[(df.geo==<span style="color: #c3e88d;">'EU28'</span>)][[<span style="color: #c3e88d;">'icd10'</span>,<span style="color: #c3e88d;">'age'</span>,2017]]

groupby_eu = df_eu.groupby([<span style="color: #c3e88d;">'icd10'</span>]).<span style="color: #82aaff;">sum</span>().reset_index()
total_mortality = groupby_eu[(groupby_eu.icd10==<span style="color: #c3e88d;">'A-R_V-Y'</span>)][2017].\
    values
groupby_eu[<span style="color: #c3e88d;">'per 1000'</span>] = groupby_eu[2017]/total_mortality*1000
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">rename_dict</span> = {
 <span style="color: #c3e88d;">"C50"</span> : <span style="color: #c3e88d;">"Malignant neoplasm of breast"</span>,
 <span style="color: #c3e88d;">"C61"</span> : <span style="color: #c3e88d;">"Malignant neoplasm of prostate"</span>,
 <span style="color: #c3e88d;">"C67"</span> : <span style="color: #c3e88d;">"Malignant neoplasm of bladder"</span>,
 <span style="color: #c3e88d;">"E10-E14"</span> : <span style="color: #c3e88d;">"Diabetes mellitus"</span>,
 <span style="color: #c3e88d;">"F"</span> : <span style="color: #c3e88d;">"Mental and behavioural disorders"</span>,
 <span style="color: #c3e88d;">"G20"</span> : <span style="color: #c3e88d;">"Parkinson disease"</span>,
 <span style="color: #c3e88d;">"G30"</span> : <span style="color: #c3e88d;">"Alzheimer disease"</span>,
 <span style="color: #c3e88d;">"J12-J18"</span> : <span style="color: #c3e88d;">"Pneumonia"</span>,
 <span style="color: #c3e88d;">"V_Y85"</span> : <span style="color: #c3e88d;">"Transport accidents"</span>}
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #89DDFF;">from</span> tabulate <span style="color: #89DDFF;">import</span> tabulate
<span style="color: #82aaff;">print</span>(tabulate(groupby_eu[(groupby_eu[<span style="color: #c3e88d;">'per 1000'</span>] &lt; 90.0) &amp;\
                          (groupby_eu[<span style="color: #c3e88d;">'per 1000'</span>] &gt; 5) &amp;\
                          (groupby_eu[<span style="color: #c3e88d;">'icd10'</span>].isin(<span style="color: #82aaff;">list</span>(rename_dict.keys())))]\
               .replace(rename_dict)\
        [[<span style="color: #c3e88d;">'icd10'</span>,<span style="color: #c3e88d;">'per 1000'</span>]],tablefmt=<span style="color: #c3e88d;">"orgtbl"</span>,\
        headers=[<span style="color: #c3e88d;">'icd10'</span>,<span style="color: #c3e88d;">'per 1000'</span>],floatfmt=<span style="color: #c3e88d;">".2f"</span>))
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-left">icd10</th>
<th scope="col" class="org-right">per 1000</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">20</td>
<td class="org-left">Malignant neoplasm of breast</td>
<td class="org-right">23.66</td>
</tr>

<tr>
<td class="org-right">24</td>
<td class="org-left">Malignant neoplasm of prostate</td>
<td class="org-right">16.16</td>
</tr>

<tr>
<td class="org-right">26</td>
<td class="org-left">Malignant neoplasm of bladder</td>
<td class="org-right">9.72</td>
</tr>

<tr>
<td class="org-right">36</td>
<td class="org-left">Diabetes mellitus</td>
<td class="org-right">22.59</td>
</tr>

<tr>
<td class="org-right">38</td>
<td class="org-left">Mental and behavioural disorders</td>
<td class="org-right">26.85</td>
</tr>

<tr>
<td class="org-right">42</td>
<td class="org-left">Parkinson disease</td>
<td class="org-right">9.17</td>
</tr>

<tr>
<td class="org-right">43</td>
<td class="org-left">Alzheimer disease</td>
<td class="org-right">13.08</td>
</tr>

<tr>
<td class="org-right">55</td>
<td class="org-left">Pneumonia</td>
<td class="org-right">19.74</td>
</tr>

<tr>
<td class="org-right">82</td>
<td class="org-left">Transport accidents</td>
<td class="org-right">5.90</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>



<div id="outline-container-org67aa40e" class="outline-2">
<h2 id="org67aa40e"><span class="section-number-2">6.</span> Robustness checks</h2>
<div class="outline-text-2" id="text-6">
<p>
In this section we discuss four different robustness checks. We explain each robustness check and discuss the results. The details of these checks can be found in <a href="https://janboone.github.io/out_of_pocket_payments_and_health/index.html#org5ed5f60">the online appendix</a>.
</p>

<p>
First, we use the at-risk-of-poverty variable, instead of deprivation as our variable capturing the fraction of people on low income. Second, we extend our definition of oop costs with expenditures on voluntary health insurance. Third, instead of focusing on the coefficient \(\beta_{unmet}\) in the mortality equation, we work with <code>TooExp</code> in this equation. The idea here is that other reasons for unmet needs (than too expensive) may have bigger effects on mortality. If this would be the case, the baseline model overestimates the effect of too expensive (and hence of oop) on mortality. Finally, we allow for missing observations in our data for the variables <code>deprivation</code> and <code>TooExp</code>. This means that we have almost 70k observations for the other variables, as shown in Table <a href="#org994393c">4</a>.
</p>

<table id="org994393c" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 4:</span> Summary statistics extended sample</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">count</th>
<th scope="col" class="org-right">mean</th>
<th scope="col" class="org-right">std</th>
<th scope="col" class="org-right">min</th>
<th scope="col" class="org-right">median</th>
<th scope="col" class="org-right">max</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">population</td>
<td class="org-right">69442.00</td>
<td class="org-right">7079.73</td>
<td class="org-right">5115.71</td>
<td class="org-right">383.00</td>
<td class="org-right">5835.00</td>
<td class="org-right">36117.00</td>
</tr>

<tr>
<td class="org-left">deaths</td>
<td class="org-right">69442.00</td>
<td class="org-right">96.61</td>
<td class="org-right">124.32</td>
<td class="org-right">0.00</td>
<td class="org-right">48.00</td>
<td class="org-right">1033.00</td>
</tr>

<tr>
<td class="org-left">mortality</td>
<td class="org-right">69442.00</td>
<td class="org-right">2.07</td>
<td class="org-right">2.88</td>
<td class="org-right">0.00</td>
<td class="org-right">0.79</td>
<td class="org-right">20.72</td>
</tr>

<tr>
<td class="org-left">deprivation</td>
<td class="org-right">52612.00</td>
<td class="org-right">11.23</td>
<td class="org-right">12.78</td>
<td class="org-right">0.00</td>
<td class="org-right">3.40</td>
<td class="org-right">52.30</td>
</tr>

<tr>
<td class="org-left">too exp.</td>
<td class="org-right">52612.00</td>
<td class="org-right">2.00</td>
<td class="org-right">3.09</td>
<td class="org-right">0.00</td>
<td class="org-right">0.60</td>
<td class="org-right">16.00</td>
</tr>

<tr>
<td class="org-left">unmet</td>
<td class="org-right">69442.00</td>
<td class="org-right">4.41</td>
<td class="org-right">4.34</td>
<td class="org-right">0.00</td>
<td class="org-right">3.20</td>
<td class="org-right">20.90</td>
</tr>

<tr>
<td class="org-left">out-of-pocket</td>
<td class="org-right">69442.00</td>
<td class="org-right">24.02</td>
<td class="org-right">9.04</td>
<td class="org-right">8.83</td>
<td class="org-right">25.16</td>
<td class="org-right">47.74</td>
</tr>

<tr>
<td class="org-left">expend. per head</td>
<td class="org-right">69442.00</td>
<td class="org-right">2922.90</td>
<td class="org-right">2501.32</td>
<td class="org-right">307.69</td>
<td class="org-right">1522.08</td>
<td class="org-right">8484.88</td>
</tr>
</tbody>
</table>

<p>
Comparing the numbers in this table (for the variables used in the robustness analysis) with Table <a href="#org4542675">1</a>, we see the following. Population and number of deaths are slightly smaller in the extended data, suggesting that smaller regions have missing data on deprivation and fraction of people who postpone treatment because it is too expensive. <code>Deprivation</code> and <code>too expensive</code> are the same in both samples. <code>Unmet</code> is slightly lower in the extended data. Out-of-pocket expenditure is two percentage points higher and expenditure per head 400 euro lower in the extended data. This suggests that we have missing observations mainly in regions of poorer countries.
</p>

<p>
In two robustness checks we need to estimate our model taking missing observations into account. As shown in Table <a href="#org4542675">1</a>, we need to do this when using poverty as our measure on low income instead of deprivation and not shrink our sample size. And we do this in the last robustness check with many missing observations for deprivation and too expensive.
</p>

<p>
In Bayesian analysis there is a natural way to deal with missing variables which is an improvement on two standard ways of dealing with this: (i) dropping observations (rows) with missing values (sometimes called complete case analysis) and (ii) interpolating the missing values. The former would change our sample when comparing the results with poverty and with deprivation. And it would not increase our sample size to almost 70k in our last robustness check. Interpolating data, say by replacing a missing value with the mean value of the variable makes the estimation method "too confident" about this value, thereby negatively affecting the quality of the inference.
</p>

<p>
We use the following method to deal with missing values (As desribed in <a href="#citeproc_bib_item_18">McElreath 2020</a>). The uncertainty surrounding the value of a missing observation is taken into account in the posterior distributions of our parameters. When sampling the posterior, if we encounter a missing value in a variable, this value is drawn from its distribution. We work with 4000 samples for the posterior and hence we draw 4000 different values for each missing observation. In this way, the uncertainty about the (missing) value translates into posterior uncertainty of the parameters and predictions.
</p>



<div id="orgf4a0352" class="figure">
<p><img src="./figures/robustness_summary.png" alt="robustness_summary.png" />
</p>
<p><span class="figure-number">Figure 8: </span>Summary of four robustness checks</p>
</div>

<p>
We summarize the robustness checks in Figure <a href="#orgf4a0352">8</a>. The figure has the baseline average effects of Figure <a href="#orgeff8d5d">2</a> on the horizontal axis. For a number of countries these effects are smaller than 5 (per 1000 dead). In all of the robustness checks, these effects remain small.
</p>

<p>
The four countries with baseline effects exceeding five are explicitly named in the figure. For a given baseline effect, there are four (vertically aligned per country) robustness effects. Ideally, all four points would lie on the 45-degree line. But, obviously, there is some variation in the effect size for different specifications.
</p>

<p>
Including voluntary health insurance payments in our oop measure has the smallest effect on outcomes. The points are very close to the 45-degree line: the effects are basically the same as with the baseline specification.
</p>

<p>
Using <code>too expensive</code> in the mortality equation yields smaller effects for Hungary and Bulgaria, but the differences with the baseline are relatively small. The ranking of the effect size across the four countries (with significant effects) remains the same.
</p>

<p>
The differences are bigger if we use the at-risk-of-poverty rate instead of deprivation. Especially in Bulgaria and Romania, the effects are substantially smaller. As at-risk-of-poverty is relative measure, one would expect the effect of this variable on <code>too expensive</code> and hence on unmet needs to be smaller than with deprivation. This also reduces the overall effect of oop on mortality.
</p>

<p>
The biggest difference can be seen when we extend our data by almost 20k observations which include a substantial number of missing observations. The effect of this change in sample for Romania is basically zero and it is relatively small for Bulgaria. But the deviations from the baseline results are big for Hungary and Greece. In fact, for Greece the effect in this robustness check is smaller than for Bulgaria thereby changing the order among countries in effect size. Quite frankly, we have no clear intuition why the differences are so big by extending the sample.
</p>

<p>
Overall the picture is that the baseline results are fairly robust to the use of different variables and different specifications. Extending the data by 20k observations, allowing for missing values for deprivation and too expensive leads to the biggest deviation compared to the baseline results. But also in this case we find that the extra deaths (per 1000 dead) due to a 500 euro oop increase lie above the deaths due to Alzheimer disease and breast cancer for the countries with the most sizable effects.
</p>
</div>

<div id="outline-container-org9f1dddb" class="outline-3">
<h3 id="org9f1dddb"><span class="section-number-3">6.1.</span> code of the robustness checks&#xa0;&#xa0;&#xa0;<span class="tag"><span class="code">code</span></span></h3>
<div class="outline-text-3" id="text-6-1">
<p>
First we generate the posterior samples for each robustness check. Then we use these samples to create Figure <a href="#orgf4a0352">8</a>.
</p>
</div>


<div id="outline-container-orgb08cee5" class="outline-4">
<h4 id="orgb08cee5"><span class="section-number-4">6.1.1.</span> Generating the samples</h4>
<div class="outline-text-4" id="text-6-1-1">
<p>
In this section we explain how we generate the posterior samples for each of the robustness checks.
</p>
</div>

<ol class="org-ol">
<li><a id="org522c438"></a>poverty instead of deprivation<br />
<div class="outline-text-5" id="text-6-1-1-1">
<p>
For this robustness check, the main change is in how we call the model <code>model_poverty = build_model(poverty_s,oop_s)</code> where we use <code>poverty</code> instead of <code>deprivation</code> as variable capturing low income. A second change is needed to accommodate that poverty has missing values compared to deprivation. As we want to keep the sample unchanged, we add <code>Poverty</code> as a variable that we need to predict when there is missing value for some observations. We know that poverty is positive and hence we choose a half-normal distribution with a small value of sigma (to avoid drawing values exceeding one).
</p>

<p>
Apart from these two adjustments, sampling the posterior is the same as in the baseline specification of the model.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">lagged_log_mortality</span> = np.asarray(lagged_log_mortality)
<span style="color: #ffcb6b;">unmet</span> = np.asarray(unmet)

<span style="color: #ffcb6b;">coords</span> = {<span style="color: #c3e88d;">"country"</span>:country_list, <span style="color: #c3e88d;">"nuts2"</span>:nuts2_list,\
          <span style="color: #c3e88d;">"gender"</span>:gender_list, <span style="color: #c3e88d;">"age"</span>:age_list,\
          <span style="color: #c3e88d;">"year"</span>:year_list}

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">build_model</span>(poverty,oop):
  <span style="color: #89DDFF;">with</span> pm.Model(coords=coords) <span style="color: #89DDFF;">as</span> baseline_model:
    sd_fixed_effects = 0.3
    <span style="color: #676E95;"># </span><span style="color: #676E95;">hierarchical priors</span>
    sd_prior_b = pm.HalfNormal(<span style="color: #c3e88d;">'sd_prior_b'</span>, sigma = 0.1)
    sd_prior_beta = pm.HalfNormal(<span style="color: #c3e88d;">'sd_prior_beta'</span>, sigma = 0.1)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">missing values poverty</span>
    Poverty = pm.HalfNormal(<span style="color: #c3e88d;">'Poverty'</span>, sigma = 0.06, observed=poverty)
    <span style="color: #676E95;"># </span><span style="color: #676E95;">Too Expensive equation</span>
    <span style="color: #676E95;">## </span><span style="color: #676E95;">NUTS 2 regional fixed effect:</span>
    mu_2_too      = pm.Normal(<span style="color: #c3e88d;">'mu_2_too'</span>, mu = -5.0,\
                              sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"nuts2"</span>)
    <span style="color: #676E95;">## </span><span style="color: #676E95;">time fixed effect:</span>
    mu_t_too = pm.Normal(<span style="color: #c3e88d;">'mu_t'</span>, mu = 0.0,\
                     sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"year"</span>)
    <span style="color: #676E95;">## </span><span style="color: #676E95;">coefficients of the TooExp equation:</span>
    b_oop         = pm.HalfNormal(<span style="color: #c3e88d;">'b_oop'</span>, sigma = sd_prior_b,\
                                  dims=<span style="color: #c3e88d;">"country"</span>)
    b_interaction = pm.HalfNormal(<span style="color: #c3e88d;">'b_interaction'</span>,\
                                  sigma = sd_prior_b, dims=<span style="color: #c3e88d;">"country"</span>)
    mu_too_exp_lo = pm.Deterministic(<span style="color: #c3e88d;">'mu_too_exp_lo'</span>, \
                      mu_2_too[nuts2_index] + mu_t_too[year] +\
                      expenditure_s * oop *\
                      (b_oop[country_index] +\
                       b_interaction[country_index] * Poverty))
    <span style="color: #676E95;">## </span><span style="color: #676E95;">equation for the log odds of TooExp</span>
    Too_exp_lo    = pm.Normal(<span style="color: #c3e88d;">'Too_exp_lo'</span>, mu = mu_too_exp_lo,\
                              sigma = 1, observed = too_exp_lo)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">Mortality equation</span>
    <span style="color: #676E95;">## </span><span style="color: #676E95;">age/gender fixed effect:</span>
    beta_age = pm.Normal(<span style="color: #c3e88d;">'beta_age'</span>, mu = -3.0,\
                         sigma = sd_fixed_effects,\
                         dims=(<span style="color: #c3e88d;">"age"</span>,<span style="color: #c3e88d;">"gender"</span>),\
                         initval=-3*np.ones((N_age,2)))
    h = pm.Deterministic(<span style="color: #c3e88d;">'h'</span>,at.sigmoid(\
                              beta_age[age_index,gender]))

    <span style="color: #676E95;">## </span><span style="color: #676E95;">multiplier effect: x</span>
    <span style="color: #676E95;">### </span><span style="color: #676E95;">NUTS 2 fixed effect:</span>
    mu_2_m   = pm.Normal(<span style="color: #c3e88d;">'mu_2_m'</span>, mu = 0.0,\
                         sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"nuts2"</span>)
    <span style="color: #676E95;">### </span><span style="color: #676E95;">coefficients of the mortality equation:</span>
    beta_lagged_log_mortality = pm.Normal(<span style="color: #c3e88d;">'beta_lagged_log_mortality'</span>,\
                                          mu = 0, sigma = sd_prior_beta)
    beta_unmet = pm.HalfNormal(<span style="color: #c3e88d;">'beta_unmet'</span>, sigma = sd_prior_beta)
    beta_poverty = pm.HalfNormal(<span style="color: #c3e88d;">'beta_poverty'</span>, sigma = sd_prior_beta)
    x = pm.Deterministic(<span style="color: #c3e88d;">'x'</span>,mu_2_m[nuts2_index] +\
                             beta_unmet*unmet +\
                             beta_poverty*Poverty+\
                             beta_lagged_log_mortality*\
                             lagged_log_mortality
                         )

  <span style="color: #676E95;">##  </span><span style="color: #676E95;">combining h and x</span>
  flat_exp = at.switch(
    at.lt(x, 0.7), <span style="color: #676E95;"># </span><span style="color: #676E95;">if</span>
    at.exp(x), <span style="color: #676E95;"># </span><span style="color: #676E95;">then</span>
    at.exp(0.7*(x/0.7)**0.1) <span style="color: #676E95;"># </span><span style="color: #676E95;">else</span>
  )
  mortality_function = h*flat_exp

  <span style="color: #89DDFF;">with</span> baseline_model:
    <span style="color: #676E95;">## </span><span style="color: #676E95;">equation binomial distribution number of deaths:</span>
    m = pm.Deterministic(<span style="color: #c3e88d;">'m'</span>, mortality_function)
    obs = pm.Binomial(<span style="color: #c3e88d;">"obs"</span>, p = m,\
                      observed=mortality, n = population)
  <span style="color: #89DDFF;">return</span> baseline_model
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">model_poverty</span> = build_model(poverty_s,oop_s)
<span style="color: #89DDFF;">with</span> <span style="color: #ffcb6b;">model_poverty</span>:
    idata_poverty = pm.sample(target_accept=0.85)
    pm.sample_posterior_predictive(idata_poverty, \
                                   extend_inferencedata=<span style="color: #f78c6c;">True</span>)
</pre>
</div>

<p>
Output of the NUTS sampler:
</p>

<pre class="example">

/home/janboone/anaconda3/envs/env_pymc/lib/python3.10/site-packages/pymc/model.py:1431: ImputationWarning: Data in Poverty contains missing values and will be automatically imputed from the sampling distribution.
  warnings.warn(impute_message, ImputationWarning)
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sd_prior_b, sd_prior_beta, Poverty_missing, mu_2_too, mu_t, b_oop, b_interaction, beta_age, mu_2_m, beta_lagged_log_mortality, beta_unmet, beta_poverty]

100.00% [8000/8000 1:05:06&lt;00:00 Sampling 4 chains, 237 divergences]

Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3908 seconds.
There were 13 divergences after tuning. Increase `target_accept` or reparameterize.
There were 37 divergences after tuning. Increase `target_accept` or reparameterize.
There were 187 divergences after tuning. Increase `target_accept` or reparameterize.
The acceptance probability does not match the target. It is 0.5954, but should be close to 0.85. Try to increase the number of tuning steps.

100.00% [4000/4000 00:47&lt;00:00]
</pre>


<div class="org-src-container">
<pre class="src src-jupyter-python">idata_poverty.to_netcdf(<span style="color: #c3e88d;">"./traces/model_poverty.nc"</span>)
</pre>
</div>
</div>
</li>


<li><a id="orgde069ec"></a>include voluntary insurance expenditure in <code>OOP</code><br />
<div class="outline-text-5" id="text-6-1-1-2">
<p>
For this robustness check we call the function <code>build_model()</code> with the extended oop measure, <code>oop_e</code>, which includes expenditures on voluntary health insurance. Apart from this, the sampling is the same as in the baseline.
</p>


<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">model_voluntary</span> = build_model(deprivation_s,oop_e)
<span style="color: #89DDFF;">with</span> <span style="color: #ffcb6b;">model_voluntary</span>:
    idata_voluntary = pm.sample(target_accept=0.85)
    pm.sample_posterior_predictive(idata_voluntary, \
                                   extend_inferencedata=<span style="color: #f78c6c;">True</span>)
</pre>
</div>

<p>
Output of the NUTS sampler:
</p>

<pre class="example">


Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sd_prior_b, sd_prior_beta, mu_2_too, mu_t, b_oop, b_interaction, beta_age, mu_2_m, beta_lagged_log_mortality, beta_unmet, beta_poverty]

100.00% [8000/8000 1:22:56&lt;00:00 Sampling 4 chains, 10 divergences]

Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4978 seconds.
There were 4 divergences after tuning. Increase `target_accept` or reparameterize.
There were 4 divergences after tuning. Increase `target_accept` or reparameterize.
There were 2 divergences after tuning. Increase `target_accept` or reparameterize.

100.00% [4000/4000 00:28&lt;00:00]
</pre>


<div class="org-src-container">
<pre class="src src-jupyter-python">idata_voluntary.to_netcdf(<span style="color: #c3e88d;">"./traces/model_voluntary.nc"</span>)
</pre>
</div>

<pre class="example">
./traces/model_voluntary.nc
</pre>
</div>
</li>





<li><a id="org7624448"></a><code>TooExp</code> effect in mortality equation<br />
<div class="outline-text-5" id="text-6-1-1-3">
<p>
Instead of using all reasons for unmet medical needs in the mortality equation, we just use <code>TooExp</code> in the mortality effect. Hence, the main change in the code is the line <code>beta_too_exp*too_exp</code> in the expression for <code>x</code>.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">lagged_log_mortality</span> = np.asarray(lagged_log_mortality)
<span style="color: #ffcb6b;">too_exp</span> = np.asarray(too_exp)

<span style="color: #ffcb6b;">coords</span> = {<span style="color: #c3e88d;">"country"</span>:country_list, <span style="color: #c3e88d;">"nuts2"</span>:nuts2_list,\
          <span style="color: #c3e88d;">"gender"</span>:gender_list, <span style="color: #c3e88d;">"age"</span>:age_list,\
          <span style="color: #c3e88d;">"year"</span>:year_list}

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">build_model</span>(poverty,oop):
  <span style="color: #89DDFF;">with</span> pm.Model(coords=coords) <span style="color: #89DDFF;">as</span> baseline_model:
    sd_fixed_effects = 0.3
    <span style="color: #676E95;"># </span><span style="color: #676E95;">hierarchical priors</span>
    sd_prior_b = pm.HalfNormal(<span style="color: #c3e88d;">'sd_prior_b'</span>, sigma = 0.1)
    sd_prior_beta = pm.HalfNormal(<span style="color: #c3e88d;">'sd_prior_beta'</span>, sigma = 0.1)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">Too Expensive equation</span>
    <span style="color: #676E95;">## </span><span style="color: #676E95;">NUTS 2 regional fixed effect:</span>
    mu_2_too      = pm.Normal(<span style="color: #c3e88d;">'mu_2_too'</span>, mu = -5.0,\
                              sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"nuts2"</span>)
    <span style="color: #676E95;">## </span><span style="color: #676E95;">time fixed effect:</span>
    mu_t_too = pm.Normal(<span style="color: #c3e88d;">'mu_t'</span>, mu = 0.0,\
                     sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"year"</span>)
    <span style="color: #676E95;">## </span><span style="color: #676E95;">coefficients of the TooExp equation:</span>
    b_oop         = pm.HalfNormal(<span style="color: #c3e88d;">'b_oop'</span>, sigma = sd_prior_b,\
                                  dims=<span style="color: #c3e88d;">"country"</span>)
    b_interaction = pm.HalfNormal(<span style="color: #c3e88d;">'b_interaction'</span>,\
                                  sigma = sd_prior_b, dims=<span style="color: #c3e88d;">"country"</span>)
    mu_too_exp_lo = pm.Deterministic(<span style="color: #c3e88d;">'mu_too_exp_lo'</span>, \
                      mu_2_too[nuts2_index] + mu_t_too[year] +\
                      expenditure_s * oop *\
                      (b_oop[country_index] +\
                       b_interaction[country_index] * poverty))
    <span style="color: #676E95;">## </span><span style="color: #676E95;">equation for the log odds of TooExp</span>
    Too_exp_lo    = pm.Normal(<span style="color: #c3e88d;">'Too_exp_lo'</span>, mu = mu_too_exp_lo,\
                              sigma = 1, observed = too_exp_lo)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">Mortality equation</span>
    <span style="color: #676E95;">## </span><span style="color: #676E95;">age/gender fixed effect:</span>
    beta_age = pm.Normal(<span style="color: #c3e88d;">'beta_age'</span>, mu = -3.0,\
                         sigma = sd_fixed_effects,\
                         dims=(<span style="color: #c3e88d;">"age"</span>,<span style="color: #c3e88d;">"gender"</span>),\
                         initval=-3*np.ones((N_age,2)))
    h = pm.Deterministic(<span style="color: #c3e88d;">'h'</span>,at.sigmoid(\
                              beta_age[age_index,gender]))

    <span style="color: #676E95;">## </span><span style="color: #676E95;">multiplier effect: x</span>
    <span style="color: #676E95;">### </span><span style="color: #676E95;">NUTS 2 fixed effect:</span>
    mu_2_m   = pm.Normal(<span style="color: #c3e88d;">'mu_2_m'</span>, mu = 0.0,\
                         sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"nuts2"</span>)
    <span style="color: #676E95;">### </span><span style="color: #676E95;">coefficients of the mortality equation:</span>
    beta_lagged_log_mortality = pm.Normal(<span style="color: #c3e88d;">'beta_lagged_log_mortality'</span>,\
                                          mu = 0, sigma = sd_prior_beta)
    beta_too_exp = pm.HalfNormal(<span style="color: #c3e88d;">'beta_too_exp'</span>, sigma = sd_prior_beta)
    beta_poverty = pm.HalfNormal(<span style="color: #c3e88d;">'beta_poverty'</span>, sigma = sd_prior_beta)
    x = pm.Deterministic(<span style="color: #c3e88d;">'x'</span>,mu_2_m[nuts2_index] +\
                             beta_too_exp*too_exp +\
                             beta_poverty*poverty+\
                             beta_lagged_log_mortality*\
                             lagged_log_mortality
                         )

  <span style="color: #676E95;">##  </span><span style="color: #676E95;">combining h and x</span>
  flat_exp = at.switch(
    at.lt(x, 0.7), <span style="color: #676E95;"># </span><span style="color: #676E95;">if</span>
    at.exp(x), <span style="color: #676E95;"># </span><span style="color: #676E95;">then</span>
    at.exp(0.7*(x/0.7)**0.1) <span style="color: #676E95;"># </span><span style="color: #676E95;">else</span>
  )
  mortality_function = h*flat_exp

  <span style="color: #89DDFF;">with</span> baseline_model:
    <span style="color: #676E95;">## </span><span style="color: #676E95;">equation binomial distribution number of deaths:</span>
    m = pm.Deterministic(<span style="color: #c3e88d;">'m'</span>, mortality_function)
    obs = pm.Binomial(<span style="color: #c3e88d;">"obs"</span>, p = m,\
                      observed=mortality, n = population)
  <span style="color: #89DDFF;">return</span> baseline_model
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">model_separate</span> = build_model(deprivation_s,oop_s)
<span style="color: #89DDFF;">with</span> <span style="color: #ffcb6b;">model_separate</span>:
    idata_separate = pm.sample(target_accept=0.85)
    pm.sample_posterior_predictive(idata_separate, \
                                   extend_inferencedata=<span style="color: #f78c6c;">True</span>)
</pre>
</div>

<p>
Output of the NUTS sampler:
</p>

<pre class="example">
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sd_prior_b, sd_prior_beta, mu_2_too, mu_t, b_oop, b_interaction, beta_age, mu_2_m, beta_lagged_log_mortality, beta_too_exp, beta_poverty]

100.00% [8000/8000 1:25:25&lt;00:00 Sampling 4 chains, 63 divergences]

Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 5126 seconds.
There were 22 divergences after tuning. Increase `target_accept` or reparameterize.
There were 2 divergences after tuning. Increase `target_accept` or reparameterize.
There were 31 divergences after tuning. Increase `target_accept` or reparameterize.
The acceptance probability does not match the target. It is 0.7788, but should be close to 0.85. Try to increase the number of tuning steps.
There were 8 divergences after tuning. Increase `target_accept` or reparameterize.

100.00% [4000/4000 00:36&lt;00:00]
</pre>


<div class="org-src-container">
<pre class="src src-jupyter-python">idata_separate.to_netcdf(<span style="color: #c3e88d;">"./traces/model_separate.nc"</span>)
</pre>
</div>

<pre class="example">
./traces/model_separate.nc
</pre>
</div>
</li>





<li><a id="orgdb9c07a"></a>include observations with missing values<br />
<div class="outline-text-5" id="text-6-1-1-4">
<p>
The biggest change in code compared to the baseline model is the extension of our data with 20k new observations. This first means that we need to read in the data again with a different selection criterion for the <code>dropna</code> method. In particular, the baseline model drops observations where there are missing values for <code>TOOEXP</code> which is the most stringent criterion. We drop this criterion in the code below.
</p>

<p>
But we do want to make sure that all observations have values for the mortality variables (as before) and for expenditure per head, unmet medical needs and oop. As these variables are important for identifying the causal mechanism that we have in mind, we prefer to keep complete cases for these variables in our dataframe.
</p>

<p>
Using this selection criterion allows Poland into the dataset, although there are not observations at all for some of these variables for Poland. Hence, we exclude Poland explicitly in the code below.
</p>

<p>
In this way, we have the same sample of countries as in the baseline analysis, but now for some region-year combinations we have missing values for deprivation and too expensive. As we show below, we draw from distributions for these missing observations where the distributions are estimated using observations of different years for these regions.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">age_min</span> = 35
<span style="color: #ffcb6b;">age_max</span> = 85
<span style="color: #ffcb6b;">age_range</span> = np.arange(age_max-age_min+1)[:,np.newaxis]
<span style="color: #ffcb6b;">plot_age</span> = np.arange(age_min,age_max+1)
<span style="color: #ffcb6b;">first_year</span> = 2009
<span style="color: #ffcb6b;">last_year</span> = 2019

<span style="color: #ffcb6b;">df</span> = pd.read_csv(<span style="color: #c3e88d;">'./data/data_deaths_by_age_nuts_2.csv'</span>)
<span style="color: #ffcb6b;">df</span>[<span style="color: #c3e88d;">'poverty'</span>] = df[<span style="color: #c3e88d;">'at risk of poverty'</span>]
<span style="color: #ffcb6b;">df</span>[<span style="color: #c3e88d;">'deprivation'</span>] = df[<span style="color: #c3e88d;">'percentage_material_deprivation'</span>]

df.dropna(subset=[<span style="color: #c3e88d;">'deaths'</span>,<span style="color: #c3e88d;">'population'</span>,<span style="color: #c3e88d;">'lagged_mortality'</span>,\
                  <span style="color: #c3e88d;">'health expenditure per capita'</span>,<span style="color: #c3e88d;">'UNMET'</span>,<span style="color: #c3e88d;">'HF3_PC_CHE'</span>],
                    axis=0, how =<span style="color: #c3e88d;">'any'</span>,inplace=<span style="color: #f78c6c;">True</span>)
df = df[(df.population &gt; df.deaths) &amp; (df.age &gt;= age_min) &amp; \
        (df.age &lt;= age_max) &amp; (df.year &lt;= last_year) &amp;\
        (df.year &gt;= first_year) &amp;(df.country != <span style="color: #c3e88d;">'Poland'</span>)]
df[<span style="color: #c3e88d;">'mortality'</span>] = df.deaths/df.population*100 \
    <span style="color: #676E95;"># </span><span style="color: #676E95;">mortality as a percentage</span>

<span style="color: #676E95;"># </span><span style="color: #676E95;">lagged mortality as fraction of mean lagged mortality</span>
<span style="color: #676E95;"># </span><span style="color: #676E95;">per age/gender group</span>
df[<span style="color: #c3e88d;">'lagged_mortality_s'</span>] = (df[<span style="color: #c3e88d;">'lagged_mortality'</span>])/\
    df.groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>])[<span style="color: #c3e88d;">'lagged_mortality'</span>].\
    transform(<span style="color: #c3e88d;">'mean'</span>)

df[<span style="color: #c3e88d;">'unmet'</span>] = df[<span style="color: #c3e88d;">'UNMET'</span>]
<span style="color: #82aaff;">len</span>(df)
</pre>
</div>

<pre class="example">
69442
</pre>



<p>
We perform the same data-steps that we do in the baseline analysis.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">country_index</span>, <span style="color: #ffcb6b;">country_list</span> = pd.factorize(df.country,sort=<span style="color: #f78c6c;">True</span>)
country_code_index, country_code_list = \
  pd.factorize(df.country_code, sort=<span style="color: #f78c6c;">True</span>)
nuts2_index, nuts2_list = pd.factorize(df.nuts2,sort=<span style="color: #f78c6c;">True</span>)
nuts1_index, nuts1_list = pd.factorize(df.nuts1,sort=<span style="color: #f78c6c;">True</span>)
gender, gender_list =\
  np.array(pd.factorize(df.sex,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)
year, year_list =\
  np.array(pd.factorize(df.year,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)
age_index, age_list = \
  np.array(pd.factorize(df.age,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)

N_countries = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(country_index))
N_nuts1 = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(nuts1_index))
N_nuts2 = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(nuts2_index))
N_age = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(age_index))

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">standardize_s</span>(x):
  x_ma = np.ma.masked_invalid(x)
  <span style="color: #89DDFF;">return</span> x_ma/x_ma.std()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #676E95;"># </span><span style="color: #676E95;">dependent variable</span>
<span style="color: #ffcb6b;">mortality</span> = df.deaths.values
<span style="color: #ffcb6b;">population</span> = df.population.values
<span style="color: #ffcb6b;">lagged_log_mortality</span> = np.clip(\
    np.ma.masked_invalid(np.log(df[<span style="color: #c3e88d;">'lagged_mortality_s'</span>])),\
                         np.log(0.0001),np.log(10))

<span style="color: #676E95;"># </span><span style="color: #676E95;">nuts 2 measures</span>
<span style="color: #ffcb6b;">poverty_s</span>  = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'poverty'</span>]/100.0)
<span style="color: #ffcb6b;">deprivation_s</span> = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'deprivation'</span>]/100.0)

<span style="color: #ffcb6b;">oop_s</span> = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>])/100.0 <span style="color: #676E95;"># </span><span style="color: #676E95;">only oop</span>

<span style="color: #ffcb6b;">too_exp</span> = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'TOOEXP'</span>])/100.0
<span style="color: #ffcb6b;">too_exp_lo</span> = np.clip(np.log(too_exp/(1-too_exp)),np.log(0.0001),np.log(10))
<span style="color: #ffcb6b;">unmet</span> = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'UNMET'</span>])/100.0



<span style="color: #676E95;"># </span><span style="color: #676E95;">country measures</span>
<span style="color: #ffcb6b;">expenditure_s</span> = standardize_s(df[<span style="color: #c3e88d;">'health expenditure per capita'</span>])
<span style="color: #ffcb6b;">std_expenditure</span> = np.std(df[<span style="color: #c3e88d;">'health expenditure per capita'</span>])

<span style="color: #676E95;"># </span><span style="color: #676E95;">female = (df.sex == 'F').astype('uint8').values</span>

N = <span style="color: #82aaff;">len</span>(mortality) <span style="color: #676E95;"># </span><span style="color: #676E95;">total sample size</span>
N_years = <span style="color: #82aaff;">len</span>(year_list)

<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"total sample size: {}"</span>.<span style="color: #82aaff;">format</span>(N))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of countries:       {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(country_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of NUTS 1 regions:  {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(nuts1_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of NUTS 2 regions:  {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(nuts2_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of ages:            {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(age_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of years:           {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(year_list)))
</pre>
</div>

<pre class="example" id="org2f44f87">
total sample size: 69442
number of countries:       14
number of NUTS 1 regions:  25
number of NUTS 2 regions:  78
number of ages:            51
number of years:           10
/home/janboone/anaconda3/envs/env_pymc/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)
/tmp/ipykernel_8955/3235566128.py:15: RuntimeWarning: divide by zero encountered in log
  too_exp_lo = np.clip(np.log(too_exp/(1-too_exp)),np.log(0.0001),np.log(10))
</pre>

<p>
The number of countries, regions, ages and years is the same as in the baseline specification. We have more observations now as we do no longer drop rows where we have a missing value for either deprivation or too expensive.
</p>



<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">headers</span> = [<span style="color: #c3e88d;">'count'</span>,<span style="color: #c3e88d;">'mean'</span>,<span style="color: #c3e88d;">'std'</span>,<span style="color: #c3e88d;">'min'</span>,<span style="color: #c3e88d;">'median'</span>,<span style="color: #c3e88d;">'max'</span>]
<span style="color: #ffcb6b;">variables</span> = df[[<span style="color: #c3e88d;">'population'</span>,<span style="color: #c3e88d;">'deaths'</span>,<span style="color: #c3e88d;">'mortality'</span>,\
                <span style="color: #c3e88d;">'at risk of poverty'</span>,\
                <span style="color: #c3e88d;">'percentage_material_deprivation'</span>,\
                <span style="color: #c3e88d;">'TOOEXP'</span>,<span style="color: #c3e88d;">'unmet'</span>,\
                <span style="color: #c3e88d;">'HF3_PC_CHE'</span>,<span style="color: #c3e88d;">'HF2_PC_CHE'</span>,\
           <span style="color: #c3e88d;">'health expenditure per capita'</span>]]\
           .describe().T[[<span style="color: #c3e88d;">'count'</span>,<span style="color: #c3e88d;">'mean'</span>,<span style="color: #c3e88d;">'std'</span>,<span style="color: #c3e88d;">'min'</span>,<span style="color: #c3e88d;">'50%'</span>,<span style="color: #c3e88d;">'max'</span>]]
variables.rename({<span style="color: #c3e88d;">'at risk of poverty'</span>:<span style="color: #c3e88d;">'poverty'</span>,\
                  <span style="color: #c3e88d;">'percentage_material_deprivation'</span>:\
                  <span style="color: #c3e88d;">'deprivation'</span>, <span style="color: #c3e88d;">'HF2_PC_CHE'</span>:<span style="color: #c3e88d;">'voluntary'</span>,\
                  <span style="color: #c3e88d;">'HF3_PC_CHE'</span>:<span style="color: #c3e88d;">'out-of-pocket'</span>,\
                  <span style="color: #c3e88d;">'TOOEXP'</span>:<span style="color: #c3e88d;">'too exp.'</span>,\
                  <span style="color: #c3e88d;">'health expenditure per capita'</span>:\
                  <span style="color: #c3e88d;">'expend. per head'</span>},inplace=<span style="color: #f78c6c;">True</span>)
<span style="color: #82aaff;">print</span>(tabulate(variables,headers,tablefmt=<span style="color: #c3e88d;">"orgtbl"</span>,\
               floatfmt=<span style="color: #c3e88d;">".2f"</span>))
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">count</th>
<th scope="col" class="org-right">mean</th>
<th scope="col" class="org-right">std</th>
<th scope="col" class="org-right">min</th>
<th scope="col" class="org-right">median</th>
<th scope="col" class="org-right">max</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">population</td>
<td class="org-right">69442.00</td>
<td class="org-right">7079.73</td>
<td class="org-right">5115.71</td>
<td class="org-right">383.00</td>
<td class="org-right">5835.00</td>
<td class="org-right">36117.00</td>
</tr>

<tr>
<td class="org-left">deaths</td>
<td class="org-right">69442.00</td>
<td class="org-right">96.61</td>
<td class="org-right">124.32</td>
<td class="org-right">0.00</td>
<td class="org-right">48.00</td>
<td class="org-right">1033.00</td>
</tr>

<tr>
<td class="org-left">mortality</td>
<td class="org-right">69442.00</td>
<td class="org-right">2.07</td>
<td class="org-right">2.88</td>
<td class="org-right">0.00</td>
<td class="org-right">0.79</td>
<td class="org-right">20.72</td>
</tr>

<tr>
<td class="org-left">poverty</td>
<td class="org-right">50878.00</td>
<td class="org-right">16.54</td>
<td class="org-right">6.58</td>
<td class="org-right">2.60</td>
<td class="org-right">15.30</td>
<td class="org-right">36.10</td>
</tr>

<tr>
<td class="org-left">deprivation</td>
<td class="org-right">52612.00</td>
<td class="org-right">11.23</td>
<td class="org-right">12.78</td>
<td class="org-right">0.00</td>
<td class="org-right">3.40</td>
<td class="org-right">52.30</td>
</tr>

<tr>
<td class="org-left">too exp.</td>
<td class="org-right">52612.00</td>
<td class="org-right">2.00</td>
<td class="org-right">3.09</td>
<td class="org-right">0.00</td>
<td class="org-right">0.60</td>
<td class="org-right">16.00</td>
</tr>

<tr>
<td class="org-left">unmet</td>
<td class="org-right">69442.00</td>
<td class="org-right">4.41</td>
<td class="org-right">4.34</td>
<td class="org-right">0.00</td>
<td class="org-right">3.20</td>
<td class="org-right">20.90</td>
</tr>

<tr>
<td class="org-left">out-of-pocket</td>
<td class="org-right">69442.00</td>
<td class="org-right">24.02</td>
<td class="org-right">9.04</td>
<td class="org-right">8.83</td>
<td class="org-right">25.16</td>
<td class="org-right">47.74</td>
</tr>

<tr>
<td class="org-left">voluntary</td>
<td class="org-right">69442.00</td>
<td class="org-right">3.42</td>
<td class="org-right">3.22</td>
<td class="org-right">0.33</td>
<td class="org-right">2.35</td>
<td class="org-right">15.90</td>
</tr>

<tr>
<td class="org-left">expend. per head</td>
<td class="org-right">69442.00</td>
<td class="org-right">2922.90</td>
<td class="org-right">2501.32</td>
<td class="org-right">307.69</td>
<td class="org-right">1522.08</td>
<td class="org-right">8484.88</td>
</tr>
</tbody>
</table>


<p>
We specify the model in the same way as in the baseline. As there are missing values for deprivation, we specify a distribution for this variable. In case of a missing value, the value is drawn from this distribution. With 4000 samples, we draw 4000 different values for this missing value. We allow the parameter for this distribution of <code>Deprivation</code> to vary by NUTS 2 region. Hence information from other years is used for this region to estimate its parameter <code>sigma_deprivation</code>. In this way, regions that tend to feature low deprivation in other years will draw a value from the half-normal distribution with a low value for <code>sigma_deprivation</code>. So each of the 4000 draws for this missing value will be relatively low. In contrast, for regions that feature high deprivation in other years, we will tend to draw 4000 relatively high values for the missing observations.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">lagged_log_mortality</span> = np.asarray(lagged_log_mortality)
<span style="color: #ffcb6b;">unmet</span> = np.asarray(unmet)

<span style="color: #ffcb6b;">coords</span> = {<span style="color: #c3e88d;">"country"</span>:country_list, <span style="color: #c3e88d;">"nuts2"</span>:nuts2_list,\
          <span style="color: #c3e88d;">"gender"</span>:gender_list, <span style="color: #c3e88d;">"age"</span>:age_list,\
          <span style="color: #c3e88d;">"year"</span>:year_list}

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">build_model</span>():
  <span style="color: #89DDFF;">with</span> pm.Model(coords=coords) <span style="color: #89DDFF;">as</span> baseline_model:
    sd_fixed_effects = 0.3
    <span style="color: #676E95;"># </span><span style="color: #676E95;">hierarchical priors</span>
    sd_prior_b = pm.HalfNormal(<span style="color: #c3e88d;">'sd_prior_b'</span>, sigma = 1.0)
    sd_prior_beta = pm.HalfNormal(<span style="color: #c3e88d;">'sd_prior_beta'</span>, sigma = 1.0)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">missing values</span>
    sigma_deprivation = pm.HalfNormal(<span style="color: #c3e88d;">'sigma_deprivation'</span>, sigma = 0.05, dims=<span style="color: #c3e88d;">'nuts2'</span>)
    Deprivation = pm.HalfNormal(<span style="color: #c3e88d;">'Deprivation'</span>, sigma = sigma_deprivation[nuts2_index],\
                                observed = deprivation_s)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">Too Expensive equation</span>
    <span style="color: #676E95;">## </span><span style="color: #676E95;">NUTS 2 regional fixed effect:</span>
    mu_2_too      = pm.Normal(<span style="color: #c3e88d;">'mu_2_too'</span>, mu = -5.0,\
                              sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"nuts2"</span>)
    <span style="color: #676E95;">## </span><span style="color: #676E95;">time fixed effect:</span>
    mu_t_too = pm.Normal(<span style="color: #c3e88d;">'mu_t'</span>, mu = 0.0,\
                     sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"year"</span>)
    <span style="color: #676E95;">## </span><span style="color: #676E95;">coefficients of the TooExp equation:</span>
    b_oop         = pm.HalfNormal(<span style="color: #c3e88d;">'b_oop'</span>, sigma = sd_prior_b,\
                                  dims=<span style="color: #c3e88d;">"country"</span>)
    b_interaction = pm.HalfNormal(<span style="color: #c3e88d;">'b_interaction'</span>,\
                                  sigma = sd_prior_b, dims=<span style="color: #c3e88d;">"country"</span>)
    mu_too_exp_lo = pm.Deterministic(<span style="color: #c3e88d;">'mu_too_exp_lo'</span>, \
                      mu_2_too[nuts2_index] + mu_t_too[year] +\
                      expenditure_s * oop_s *\
                      (b_oop[country_index] +\
                       b_interaction[country_index] * Deprivation))
    <span style="color: #676E95;">## </span><span style="color: #676E95;">equation for the log odds of TooExp</span>
    Too_exp_lo    = pm.Normal(<span style="color: #c3e88d;">'Too_exp_lo'</span>, mu = mu_too_exp_lo,\
                              sigma = 1, observed = too_exp_lo)

    <span style="color: #676E95;"># </span><span style="color: #676E95;">Mortality equation</span>
    <span style="color: #676E95;">## </span><span style="color: #676E95;">age/gender fixed effect:</span>
    beta_age = pm.Normal(<span style="color: #c3e88d;">'beta_age'</span>, mu = -3.0,\
                         sigma = sd_fixed_effects,\
                         dims=(<span style="color: #c3e88d;">"age"</span>,<span style="color: #c3e88d;">"gender"</span>),\
                         initval=-3*np.ones((N_age,2)))
    h = pm.Deterministic(<span style="color: #c3e88d;">'h'</span>,at.sigmoid(\
                              beta_age[age_index,gender]))

    <span style="color: #676E95;">## </span><span style="color: #676E95;">multiplier effect: x</span>
    <span style="color: #676E95;">### </span><span style="color: #676E95;">NUTS 2 fixed effect:</span>
    mu_2_m   = pm.Normal(<span style="color: #c3e88d;">'mu_2_m'</span>, mu = 0.0,\
                         sigma = sd_fixed_effects, dims=<span style="color: #c3e88d;">"nuts2"</span>)
    <span style="color: #676E95;">### </span><span style="color: #676E95;">coefficients of the mortality equation:</span>
    beta_lagged_log_mortality = pm.Normal(<span style="color: #c3e88d;">'beta_lagged_log_mortality'</span>,\
                                          mu = 0, sigma = sd_prior_beta)
    beta_unmet = pm.HalfNormal(<span style="color: #c3e88d;">'beta_unmet'</span>, sigma = sd_prior_beta)
    beta_poverty = pm.HalfNormal(<span style="color: #c3e88d;">'beta_poverty'</span>, sigma = sd_prior_beta)
    x = pm.Deterministic(<span style="color: #c3e88d;">'x'</span>,mu_2_m[nuts2_index] +\
                             beta_unmet*unmet +\
                             beta_poverty*Deprivation+\
                             beta_lagged_log_mortality*\
                             lagged_log_mortality
                         )

  <span style="color: #676E95;">##  </span><span style="color: #676E95;">combining h and x</span>
  flat_exp = at.switch(
    at.lt(x, 0.7), <span style="color: #676E95;"># </span><span style="color: #676E95;">if</span>
    at.exp(x), <span style="color: #676E95;"># </span><span style="color: #676E95;">then</span>
    at.exp(0.7*(x/0.7)**0.1) <span style="color: #676E95;"># </span><span style="color: #676E95;">else</span>
  )
  mortality_function = h*flat_exp

  <span style="color: #89DDFF;">with</span> baseline_model:
    <span style="color: #676E95;">## </span><span style="color: #676E95;">equation binomial distribution number of deaths:</span>
    m = pm.Deterministic(<span style="color: #c3e88d;">'m'</span>, mortality_function)
    obs = pm.Binomial(<span style="color: #c3e88d;">"obs"</span>, p = m,\
                      observed=mortality, n = population)
  <span style="color: #89DDFF;">return</span> baseline_model
</pre>
</div>


<p>
Because we have more observations here than in the baseline specification and need to predict missing values for two variables, the NUTS algorithm becomes too slow. We use Automatic Differentiation Variational Inference (ADVI) instead (<a href="#citeproc_bib_item_16">Kucukelbir et al. 2016</a>). The idea of ADVI is to approximate the posterior distribution with a number of well known distributions. This first approximation step is an optimization problem. Once we have found the optimized fit to the posterior distribution, we will sample from this approximate posterior.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">model_missing</span> = build_model()
<span style="color: #89DDFF;">with</span> <span style="color: #ffcb6b;">model_missing</span>:
    approx = pm.fit(method=<span style="color: #c3e88d;">"advi"</span>)
</pre>
</div>

<p>
To check convergence of the ADVI algorithm we use the Evidence Lower Bound (ELBO) plot.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python">plt.plot(approx.hist);
</pre>
</div>


<div id="org2e9b159" class="figure">
<p><img src="./figures/ELBO_missing.png" alt="ELBO_missing.png" />
</p>
</div>

<p>
This figure has the expected inverse J shape suggesting that the ADVI algorithm converged.
</p>

<p>
Then we draw 4000 samples for our posterior distribution.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">idata_missing</span> = approx.sample(4000)
</pre>
</div>



<div class="org-src-container">
<pre class="src src-jupyter-python">idata_missing.to_netcdf(<span style="color: #c3e88d;">"./traces/model_missing.nc"</span>)
</pre>
</div>

<pre class="example">
./traces/model_missing.nc
</pre>
</div>
</li>
</ol>
</div>


<div id="outline-container-orgf841cca" class="outline-4">
<h4 id="orgf841cca"><span class="section-number-4">6.1.2.</span> creating Figure <a href="#orgf4a0352">8</a></h4>
<div class="outline-text-4" id="text-6-1-2">
<p>
In this section we read in the samples for the robustness checks that were generated above. For each robustness check we then generate the mean mortality effect (per 1000 dead) of a 500 euro increase in <code>OOP</code>. We then save these effects into a dataframe.
</p>
</div>

<ol class="org-ol">
<li><a id="org4100443"></a>baseline<br />
<div class="outline-text-5" id="text-6-1-2-1">
<p>
We read in the posterior samples and calculate the effects in the same way we did above for the baseline model.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">idata_baseline</span> = az.from_netcdf(<span style="color: #c3e88d;">"./traces/baseline_model.nc"</span>)
<span style="color: #ffcb6b;">df_nuts2</span> = df[[<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'poverty'</span>,<span style="color: #c3e88d;">'deprivation'</span>,\
            <span style="color: #c3e88d;">'unmet'</span>,<span style="color: #c3e88d;">'TOOEXP'</span>,<span style="color: #c3e88d;">'health expenditure per capita'</span>,<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]].\
            groupby([<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>]).mean().reset_index()
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'poverty_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'poverty'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'deprivation_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'deprivation'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'unmet_s'</span>] = (df_nuts2.unmet)/100.0
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'too_exp_s'</span>] = df_nuts2.TOOEXP/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'oop_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]/100

<span style="color: #ffcb6b;">poverty_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'poverty_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">deprivation_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">unmet_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'unmet_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">too_exp_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'too_exp_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]

<span style="color: #ffcb6b;">beta_unmet</span> = idata_baseline.posterior.beta_unmet.\
    values[:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_oop</span> = idata_baseline.posterior.b_oop.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_interaction</span> = idata_baseline.posterior.b_interaction.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">Delta_log_mortality</span>(p_too_exp,Delta_OOP,alpha):
    <span style="color: #89DDFF;">return</span> beta_unmet * p_too_exp*(1-p_too_exp) * \
        Delta_OOP * (b_oop + b_interaction * alpha)

<span style="color: #ffcb6b;">idx</span> = df_nuts2.groupby([<span style="color: #c3e88d;">'country'</span>])[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    transform(<span style="color: #82aaff;">max</span>) == df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>]
<span style="color: #ffcb6b;">df_country</span> = df_nuts2[idx].sort_values([<span style="color: #c3e88d;">'country'</span>]).\
    drop_duplicates(subset=<span style="color: #c3e88d;">'country'</span>,keep=<span style="color: #c3e88d;">'last'</span>)
depr_country = df_country.deprivation_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
too_exp_country = df_country.too_exp_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
delta_oop = 500
Delta_log_m = Delta_log_mortality(too_exp_country,\
  delta_oop/std_expenditure,depr_country).mean(axis=(0,1))

effects_baseline = Delta_log_m.flatten()*1000
</pre>
</div>
</div>
</li>


<li><a id="orgc8c7807"></a>at risk of poverty<br />
<div class="outline-text-5" id="text-6-1-2-2">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">idata_poverty</span> = az.from_netcdf(<span style="color: #c3e88d;">"./traces/model_poverty.nc"</span>)

<span style="color: #ffcb6b;">beta_unmet</span> = idata_poverty.posterior.beta_unmet.\
    values[:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_oop</span> = idata_poverty.posterior.b_oop.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_interaction</span> = idata_poverty.posterior.b_interaction.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]

<span style="color: #ffcb6b;">pov_country</span> = df_country.poverty_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">Delta_log_m_poverty</span> = Delta_log_mortality(too_exp_country,\
  delta_oop/std_expenditure,pov_country).mean(axis=(0,1))

effects_poverty = Delta_log_m_poverty.flatten()*1000
</pre>
</div>
</div>
</li>

<li><a id="orgf00d6c0"></a>broad definition oop<br />
<div class="outline-text-5" id="text-6-1-2-3">
<p>
We need to add expenditure on voluntary health insurance to the extended <code>oop_e</code> variable. Otherwise, the derivation of the effects is the same as in the baseline model.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">idata_voluntary</span> = az.from_netcdf(<span style="color: #c3e88d;">"./traces/model_voluntary.nc"</span>)
<span style="color: #ffcb6b;">df_nuts2</span> = df[[<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'poverty'</span>,<span style="color: #c3e88d;">'deprivation'</span>,\
            <span style="color: #c3e88d;">'unmet'</span>,<span style="color: #c3e88d;">'TOOEXP'</span>,<span style="color: #c3e88d;">'health expenditure per capita'</span>,<span style="color: #c3e88d;">'HF2_PC_CHE'</span>,<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]].\
            groupby([<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>]).mean().reset_index()
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'poverty_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'poverty'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'deprivation_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'deprivation'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'unmet_s'</span>] = (df_nuts2.unmet)/100.0
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'too_exp_s'</span>] = df_nuts2.TOOEXP/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'oop_e'</span>] = (df_nuts2[<span style="color: #c3e88d;">'HF2_PC_CHE'</span>]+df_nuts2[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>])/100

<span style="color: #ffcb6b;">poverty_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'poverty_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">deprivation_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">unmet_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'unmet_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">too_exp_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'too_exp_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]

<span style="color: #ffcb6b;">beta_unmet</span> = idata_voluntary.posterior.beta_unmet.\
    values[:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_oop</span> = idata_voluntary.posterior.b_oop.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_interaction</span> = idata_voluntary.posterior.b_interaction.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]

<span style="color: #ffcb6b;">idx</span> = df_nuts2.groupby([<span style="color: #c3e88d;">'country'</span>])[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    transform(<span style="color: #82aaff;">max</span>) == df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>]
<span style="color: #ffcb6b;">df_country</span> = df_nuts2[idx].sort_values([<span style="color: #c3e88d;">'country'</span>]).\
    drop_duplicates(subset=<span style="color: #c3e88d;">'country'</span>,keep=<span style="color: #c3e88d;">'last'</span>)
depr_country = df_country.deprivation_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
too_exp_country = df_country.too_exp_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
delta_oop = 500
Delta_log_m_voluntary = Delta_log_mortality(too_exp_country,\
  delta_oop/std_expenditure,depr_country).mean(axis=(0,1))

effects_voluntary = Delta_log_m_voluntary.flatten()*1000
</pre>
</div>
</div>
</li>


<li><a id="org4a504fc"></a>TooExp in mortality equation<br />
<div class="outline-text-5" id="text-6-1-2-4">
<p>
In the function <code>Delta_log_mortality_separate</code> we use <code>beta_too_exp</code> instead of <code>beta_unmet</code>.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">idata_separate</span> = az.from_netcdf(<span style="color: #c3e88d;">"./traces/model_separate.nc"</span>)
<span style="color: #ffcb6b;">df_nuts2</span> = df[[<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'poverty'</span>,<span style="color: #c3e88d;">'deprivation'</span>,\
            <span style="color: #c3e88d;">'unmet'</span>,<span style="color: #c3e88d;">'TOOEXP'</span>,<span style="color: #c3e88d;">'health expenditure per capita'</span>,<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]].\
            groupby([<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>]).mean().reset_index()
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'poverty_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'poverty'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'deprivation_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'deprivation'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'unmet_s'</span>] = (df_nuts2.unmet)/100.0
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'too_exp_s'</span>] = df_nuts2.TOOEXP/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'oop_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]/100

<span style="color: #ffcb6b;">poverty_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'poverty_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">deprivation_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">unmet_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'unmet_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">too_exp_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'too_exp_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]

<span style="color: #ffcb6b;">beta_too_exp</span> = idata_separate.posterior.beta_too_exp.\
    values[:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_oop</span> = idata_separate.posterior.b_oop.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_interaction</span> = idata_separate.posterior.b_interaction.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">Delta_log_mortality_separate</span>(p_too_exp,Delta_OOP,alpha):
    <span style="color: #89DDFF;">return</span> beta_too_exp * p_too_exp*(1-p_too_exp) * \
        Delta_OOP * (b_oop + b_interaction * alpha)
<span style="color: #ffcb6b;">idx</span> = df_nuts2.groupby([<span style="color: #c3e88d;">'country'</span>])[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    transform(<span style="color: #82aaff;">max</span>) == df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>]
<span style="color: #ffcb6b;">df_country</span> = df_nuts2[idx].sort_values([<span style="color: #c3e88d;">'country'</span>]).\
    drop_duplicates(subset=<span style="color: #c3e88d;">'country'</span>,keep=<span style="color: #c3e88d;">'last'</span>)
pov_country = df_country.poverty_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
too_exp_country = df_country.too_exp_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
delta_oop = 500
Delta_log_m_separate = Delta_log_mortality(too_exp_country,\
  delta_oop/std_expenditure,pov_country).mean(axis=(0,1))

effects_separate = Delta_log_m_separate.flatten()*1000
</pre>
</div>
</div>
</li>



<li><a id="org466ec59"></a>missing values<br />
<div class="outline-text-5" id="text-6-1-2-5">
<p>
The selection of data is explained above where we discuss the estimation of the model with missing values and where we generate the posterior samples for the parameters.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">age_min</span> = 35
<span style="color: #ffcb6b;">age_max</span> = 85
<span style="color: #ffcb6b;">age_range</span> = np.arange(age_max-age_min+1)[:,np.newaxis]
<span style="color: #ffcb6b;">plot_age</span> = np.arange(age_min,age_max+1)
<span style="color: #ffcb6b;">first_year</span> = 2009
<span style="color: #ffcb6b;">last_year</span> = 2019

<span style="color: #ffcb6b;">df</span> = pd.read_csv(<span style="color: #c3e88d;">'./data/data_deaths_by_age_nuts_2.csv'</span>)
<span style="color: #ffcb6b;">df</span>[<span style="color: #c3e88d;">'poverty'</span>] = df[<span style="color: #c3e88d;">'at risk of poverty'</span>]
<span style="color: #ffcb6b;">df</span>[<span style="color: #c3e88d;">'deprivation'</span>] = df[<span style="color: #c3e88d;">'percentage_material_deprivation'</span>]

df.dropna(subset=[<span style="color: #c3e88d;">'deaths'</span>,<span style="color: #c3e88d;">'population'</span>,<span style="color: #c3e88d;">'lagged_mortality'</span>,\
                  <span style="color: #c3e88d;">'health expenditure per capita'</span>,<span style="color: #c3e88d;">'UNMET'</span>,<span style="color: #c3e88d;">'HF3_PC_CHE'</span>],
                    axis=0, how =<span style="color: #c3e88d;">'any'</span>,inplace=<span style="color: #f78c6c;">True</span>)
df = df[(df.population &gt; df.deaths) &amp; (df.age &gt;= age_min) &amp; \
        (df.age &lt;= age_max) &amp; (df.year &lt;= last_year) &amp;\
        (df.year &gt;= first_year) &amp;(df.country != <span style="color: #c3e88d;">'Poland'</span>)]
df[<span style="color: #c3e88d;">'mortality'</span>] = df.deaths/df.population*100 \
    <span style="color: #676E95;"># </span><span style="color: #676E95;">mortality as a percentage</span>

<span style="color: #676E95;"># </span><span style="color: #676E95;">lagged mortality as fraction of mean lagged mortality</span>
<span style="color: #676E95;"># </span><span style="color: #676E95;">per age/gender group</span>
df[<span style="color: #c3e88d;">'lagged_mortality_s'</span>] = (df[<span style="color: #c3e88d;">'lagged_mortality'</span>])/\
    df.groupby([<span style="color: #c3e88d;">'age'</span>,<span style="color: #c3e88d;">'sex'</span>])[<span style="color: #c3e88d;">'lagged_mortality'</span>].\
    transform(<span style="color: #c3e88d;">'mean'</span>)

df[<span style="color: #c3e88d;">'unmet'</span>] = df[<span style="color: #c3e88d;">'UNMET'</span>]
<span style="color: #ffcb6b;">country_index</span>, <span style="color: #ffcb6b;">country_list</span> = pd.factorize(df.country,sort=<span style="color: #f78c6c;">True</span>)
country_code_index, country_code_list = \
  pd.factorize(df.country_code, sort=<span style="color: #f78c6c;">True</span>)
nuts2_index, nuts2_list = pd.factorize(df.nuts2,sort=<span style="color: #f78c6c;">True</span>)
nuts1_index, nuts1_list = pd.factorize(df.nuts1,sort=<span style="color: #f78c6c;">True</span>)
gender, gender_list =\
  np.array(pd.factorize(df.sex,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)
year, year_list =\
  np.array(pd.factorize(df.year,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)
age_index, age_list = \
  np.array(pd.factorize(df.age,sort=<span style="color: #f78c6c;">True</span>),dtype=<span style="color: #82aaff;">object</span>)

N_countries = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(country_index))
N_nuts1 = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(nuts1_index))
N_nuts2 = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(nuts2_index))
N_age = <span style="color: #82aaff;">len</span>(<span style="color: #82aaff;">set</span>(age_index))

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">standardize_s</span>(x):
  x_ma = np.ma.masked_invalid(x)
  <span style="color: #89DDFF;">return</span> x_ma/x_ma.std()
<span style="color: #676E95;"># </span><span style="color: #676E95;">dependent variable</span>
mortality = df.deaths.values
population = df.population.values
lagged_log_mortality = np.clip(\
    np.ma.masked_invalid(np.log(df[<span style="color: #c3e88d;">'lagged_mortality_s'</span>])),\
                         np.log(0.0001),np.log(10))

<span style="color: #676E95;"># </span><span style="color: #676E95;">nuts 2 measures</span>
poverty_s  = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'poverty'</span>]/100.0)
deprivation_s = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'deprivation'</span>]/100.0)

oop_s = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>])/100.0 <span style="color: #676E95;"># </span><span style="color: #676E95;">only oop</span>

too_exp = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'TOOEXP'</span>])/100.0
too_exp_lo = np.clip(np.log(too_exp/(1-too_exp)),np.log(0.0001),np.log(10))
unmet = np.ma.masked_invalid(df[<span style="color: #c3e88d;">'UNMET'</span>])/100.0



<span style="color: #676E95;"># </span><span style="color: #676E95;">country measures</span>
expenditure_s = standardize_s(df[<span style="color: #c3e88d;">'health expenditure per capita'</span>])
std_expenditure = np.std(df[<span style="color: #c3e88d;">'health expenditure per capita'</span>])

<span style="color: #676E95;"># </span><span style="color: #676E95;">female = (df.sex == 'F').astype('uint8').values</span>

N = <span style="color: #82aaff;">len</span>(mortality) <span style="color: #676E95;"># </span><span style="color: #676E95;">total sample size</span>
N_years = <span style="color: #82aaff;">len</span>(year_list)

<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"total sample size: {}"</span>.<span style="color: #82aaff;">format</span>(N))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of countries:       {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(country_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of NUTS 1 regions:  {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(nuts1_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of NUTS 2 regions:  {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(nuts2_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of ages:            {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(age_list)))
<span style="color: #82aaff;">print</span>(<span style="color: #c3e88d;">"number of years:           {}"</span>.<span style="color: #82aaff;">format</span>(<span style="color: #82aaff;">len</span>(year_list)))
</pre>
</div>

<pre class="example" id="orgb6afaa0">
total sample size: 69442
number of countries:       14
number of NUTS 1 regions:  25
number of NUTS 2 regions:  78
number of ages:            51
number of years:           10
/home/janboone/anaconda3/envs/env_pymc/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log
  result = getattr(ufunc, method)(*inputs, **kwargs)
/tmp/ipykernel_147322/1926443013.py:62: RuntimeWarning: divide by zero encountered in log
  too_exp_lo = np.clip(np.log(too_exp/(1-too_exp)),np.log(0.0001),np.log(10))
</pre>







<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">idata_missing</span> = az.from_netcdf(<span style="color: #c3e88d;">"./traces/model_missing.nc"</span>)
<span style="color: #ffcb6b;">df_nuts2</span> = df[[<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>,<span style="color: #c3e88d;">'poverty'</span>,<span style="color: #c3e88d;">'deprivation'</span>,\
            <span style="color: #c3e88d;">'unmet'</span>,<span style="color: #c3e88d;">'TOOEXP'</span>,<span style="color: #c3e88d;">'health expenditure per capita'</span>,<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]].\
            groupby([<span style="color: #c3e88d;">'nuts2'</span>,<span style="color: #c3e88d;">'country'</span>]).mean().reset_index()
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'poverty_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'poverty'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'deprivation_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'deprivation'</span>]/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'unmet_s'</span>] = (df_nuts2.unmet)/100.0
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'too_exp_s'</span>] = df_nuts2.TOOEXP/100
<span style="color: #ffcb6b;">df_nuts2</span>[<span style="color: #c3e88d;">'oop_s'</span>] = df_nuts2[<span style="color: #c3e88d;">'HF3_PC_CHE'</span>]/100

<span style="color: #ffcb6b;">poverty_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'poverty_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">deprivation_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">unmet_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'unmet_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">too_exp_nuts2_s</span> = df_nuts2[<span style="color: #c3e88d;">'too_exp_s'</span>].\
    to_numpy()[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>]

<span style="color: #ffcb6b;">beta_unmet</span> = idata_missing.posterior.beta_unmet.\
    values[:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_oop</span> = idata_missing.posterior.b_oop.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
<span style="color: #ffcb6b;">b_interaction</span> = idata_missing.posterior.b_interaction.\
    values[:,:,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]

<span style="color: #89DDFF;">def</span> <span style="color: #82aaff;">Delta_log_mortality_missing</span>(p_too_exp,Delta_OOP,alpha):
    <span style="color: #89DDFF;">return</span> beta_unmet * p_too_exp*(1-p_too_exp) * \
        Delta_OOP * (b_oop + b_interaction * alpha)
<span style="color: #ffcb6b;">idx</span> = df_nuts2.groupby([<span style="color: #c3e88d;">'country'</span>])[<span style="color: #c3e88d;">'deprivation_s'</span>].\
    transform(<span style="color: #82aaff;">max</span>) == df_nuts2[<span style="color: #c3e88d;">'deprivation_s'</span>]
<span style="color: #ffcb6b;">df_country</span> = df_nuts2[idx].sort_values([<span style="color: #c3e88d;">'country'</span>]).\
    drop_duplicates(subset=<span style="color: #c3e88d;">'country'</span>,keep=<span style="color: #c3e88d;">'last'</span>)
pov_country = df_country.poverty_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
too_exp_country = df_country.too_exp_s.\
    values[<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>,:,<span style="color: #f78c6c;">None</span>,<span style="color: #f78c6c;">None</span>]
delta_oop = 500
Delta_log_m_missing = Delta_log_mortality(too_exp_country,\
  delta_oop/std_expenditure,pov_country).mean(axis=(0,1))

effects_missing = Delta_log_m_missing.flatten()*1000
</pre>
</div>
</div>
</li>


<li><a id="orgd754a50"></a>saving the effects<br />
<div class="outline-text-5" id="text-6-1-2-6">
<p>
We create a dataframe with each of the effects for the different countries. Then we save this dataframe to a <code>.csv</code> file.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">df_robustness</span> = pd.DataFrame({<span style="color: #c3e88d;">'baseline'</span>:effects_baseline, <span style="color: #c3e88d;">'poverty'</span>:effects_poverty,\
                              <span style="color: #c3e88d;">'voluntary'</span>:effects_voluntary, <span style="color: #c3e88d;">'separate'</span>:effects_separate,\
                              <span style="color: #c3e88d;">'missing'</span>:effects_missing})
df_robustness.to_csv(<span style="color: #c3e88d;">'./data/robustness_effects.csv'</span>)
</pre>
</div>
</div>
</li>

<li><a id="org1a1b75b"></a>creating the figure<br />
<div class="outline-text-5" id="text-6-1-2-7">
<p>
We read in the data with the effects of the baseline model and the robustness checks.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #ffcb6b;">df_robustness</span> = pd.read_csv(<span style="color: #c3e88d;">'./data/robustness_effects.csv'</span>)
df_robustness.sort_values(<span style="color: #c3e88d;">'baseline'</span>,inplace=<span style="color: #f78c6c;">True</span>)
</pre>
</div>

<p>
Then we plot the effects of the robustness checks against the baseline outcomes for each country.
</p>

<div class="org-src-container">
<pre class="src src-jupyter-python">plt.style.use(<span style="color: #c3e88d;">'Solarize_Light2'</span>)
fig, (<span style="color: #ffcb6b;">ax1</span>) = plt.subplots(1,1,dpi=280,figsize=(6,6))
ax1.plot(df_robustness.baseline,df_robustness.poverty,linestyle=<span style="color: #c3e88d;">'--'</span>,marker=<span style="color: #c3e88d;">'o'</span>,label=<span style="color: #c3e88d;">'at risk of poverty'</span>)
ax1.plot(df_robustness.baseline,df_robustness.voluntary,linestyle=<span style="color: #c3e88d;">'--'</span>,marker=<span style="color: #c3e88d;">'P'</span>,label=<span style="color: #c3e88d;">'include voluntary'</span>)
ax1.plot(df_robustness.baseline,df_robustness.separate,linestyle=<span style="color: #c3e88d;">'--'</span>,marker=<span style="color: #c3e88d;">'X'</span>,label=<span style="color: #c3e88d;">'too expensive in mortality equation'</span>)
ax1.plot(df_robustness.baseline,df_robustness.missing,linestyle=<span style="color: #c3e88d;">'--'</span>,marker=<span style="color: #c3e88d;">'d'</span>,label=<span style="color: #c3e88d;">'include missing observations'</span>)
ax1.plot([0,35],[0,35],c=<span style="color: #c3e88d;">'k'</span>)
ax1.set_xlabel(<span style="color: #c3e88d;">'baseline effects'</span>)
ax1.set_ylabel(<span style="color: #c3e88d;">'robustness effects'</span>)
fig.suptitle(<span style="color: #c3e88d;">'Summary robustness analyses'</span>)
plt.annotate(
    <span style="color: #c3e88d;">"Romania"</span>,
    xy=(33.5,24),
    xycoords=<span style="color: #c3e88d;">"data"</span>,
    xytext=(31, 20),
    textcoords=<span style="color: #c3e88d;">"data"</span>,
    fontsize=12,
    arrowprops=<span style="color: #82aaff;">dict</span>(arrowstyle=<span style="color: #c3e88d;">"-&gt;"</span>, connectionstyle=<span style="color: #c3e88d;">"arc3,rad=.2"</span>),
)
plt.annotate(
    <span style="color: #c3e88d;">"Greece"</span>,
    xy=(22,23),
    xycoords=<span style="color: #c3e88d;">"data"</span>,
    xytext=(20, 27),
    textcoords=<span style="color: #c3e88d;">"data"</span>,
    fontsize=12,
    arrowprops=<span style="color: #82aaff;">dict</span>(arrowstyle=<span style="color: #c3e88d;">"-&gt;"</span>, connectionstyle=<span style="color: #c3e88d;">"arc3,rad=.2"</span>),
)
plt.annotate(
    <span style="color: #c3e88d;">"Bulgaria"</span>,
    xy=(14.5,14.5),
    xycoords=<span style="color: #c3e88d;">"data"</span>,
    xytext=(12, 19),
    textcoords=<span style="color: #c3e88d;">"data"</span>,
    fontsize=12,
    arrowprops=<span style="color: #82aaff;">dict</span>(arrowstyle=<span style="color: #c3e88d;">"-&gt;"</span>, connectionstyle=<span style="color: #c3e88d;">"arc3,rad=.2"</span>),
)
plt.annotate(
    <span style="color: #c3e88d;">"Hungary"</span>,
    xy=(6.5,6.5),
    xycoords=<span style="color: #c3e88d;">"data"</span>,
    xytext=(4, 10),
    textcoords=<span style="color: #c3e88d;">"data"</span>,
    fontsize=12,
    arrowprops=<span style="color: #82aaff;">dict</span>(arrowstyle=<span style="color: #c3e88d;">"-&gt;"</span>, connectionstyle=<span style="color: #c3e88d;">"arc3,rad=.2"</span>),
)

ax1.legend();
</pre>
</div>


<div id="org8b4359b" class="figure">
<p><img src="./figures/robustness_summary.png" alt="robustness_summary.png" />
</p>
</div>
</div>
</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org1190444" class="outline-2">
<h2 id="org1190444"><span class="section-number-2">7.</span> Discussion and policy implications</h2>
<div class="outline-text-2" id="text-7">
<p>
The Introduction discusses a recent literature using individual level data analyzing whether demand side cost sharing reduces expenditure on low value treatments (usually referred to as moral hazard) or whether it leads patients to postpone or forgo valuable treatments thereby negatively affecting their health. This literature is focused on US individual level data and argues that it is hard to identify negative health effects of cost sharing in aggregate data. We use European data at the (NUTS 2) regional level to show that a high share of out-of-pocket expenditures (in total healthcare expenditures) has a clear effect on mortality in regions where the fraction of low income households is high. The size of the mortality effect increases with the initial level of out-of-pocket expenditure and hence the initial fraction of people indicating they skip or postpone treatment because it is too expensive.
</p>

<p>
Healthcare costs keep increasing in most, if not all, developed countries. Demand side cost sharing is a well known instrument to curb the growth in expenditure. This paper shows that there is threshold of out-of-pocket expenditure beyond which regions with high poverty levels start to show increased mortality rates. To avoid this mortality effect, policy makers in countries with high out-of-pocket expenditure need to search for alternative instruments. Possible alternatives are means tested cost sharing or co-payments that are lower for cost-effective treatments. In the latter case, high value treatments are cheaper than low value care and hence less likely to be postponed by people on low income.
</p>
</div>
</div>


<div id="outline-container-orgadf81b7" class="outline-2">
<h2 id="orgadf81b7"><span class="section-number-2">8.</span> Bibliography</h2>
<div class="outline-text-2" id="text-8">
<div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>Abaluck, Jason, Mauricio M. Caceres Bravo, Peter Hull, and Amanda Starc. 2020. Mortality Effects and Choice across Private Health Insurance Plans, July. National Bureau of Economic Research. doi:<a href="https://doi.org/10.3386/w27578">10.3386/w27578</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>Baicker, Katherine, Sendhil Mullainathan, and Joshua Schwartzstein. 2015. Behavioral Hazard in Health Insurance. <i>The Quarterly Journal of Economics</i> 130 (4). Oxford University Press (OUP): 162367. doi:<a href="https://doi.org/10.1093/qje/qjv029">10.1093/qje/qjv029</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>Black, Bernard, Alex Hollingsworth, Leticia Nunes, and Kosali Simon. 2021. Simulated Power Analyses for Observational Studies: An Application to the Affordable Care Act Medicaid Expansion, February. National Bureau of Economic Research. doi:<a href="https://doi.org/10.3386/w25568">10.3386/w25568</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>Borgschulte, Mark, and Jacob Vogler. 2020. Did the Aca Medicaid Expansion Save Lives? <i>Journal of Health Economics</i> 72 (July). Elsevier BV: 102333. doi:<a href="https://doi.org/10.1016/j.jhealeco.2020.102333">10.1016/j.jhealeco.2020.102333</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>Brot-Goldberg, Zarek C., Amitabh Chandra, Benjamin R. Handel, and Jonathan T. Kolstad. 2017. What Does a Deductible Do? the Impact of Cost-Sharing on Health Care Prices, Quantities, and Spending Dynamics. <i>The Quarterly Journal of Economics</i> 132 (3). Oxford University Press (OUP): 12611318. doi:<a href="https://doi.org/10.1093/qje/qjx013">10.1093/qje/qjx013</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>Chandra, Amitabh, Evan Flack, and Ziad Obermeyer. 2021. The Health Costs of Cost-Sharing, February. National Bureau of Economic Research. doi:<a href="https://doi.org/10.3386/w28439">10.3386/w28439</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>Chernew, Michael E., Mayur R. Shah, Arnold Wegh, Stephen N. Rosenberg, Iver A. Juster, Allison B. Rosen, Michael C. Sokol, Kristina Yu-Isenberg, and A. Mark Fendrick. 2008. Impact of Decreasing Copayments on Medication Adherence within a Disease Management Environment. <i>Health Affairs</i> 27 (1). Health Affairs (Project Hope): 10312. doi:<a href="https://doi.org/10.1377/hlthaff.27.1.103">10.1377/hlthaff.27.1.103</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a>Chetty, Raj, Michael Stepner, Sarah Abraham, Shelby Lin, Benjamin Scuderi, Nicholas Turner, Augustin Bergeron, and David Cutler. 2016. The Association between Income and Life Expectancy in the United States, 2001-2014. <i>Jama</i> 315 (16). American Medical Association (AMA): 1750. doi:<a href="https://doi.org/10.1001/jama.2016.4226">10.1001/jama.2016.4226</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_9"></a>Cutler, David M., Adriana Lleras-Muney, and Tom Vogl. 2011. <i>Chapter 7 - Socioeconomic Status and Health: Dimensions and Mechanisms, in S. Glied and P. Smith, Editors, Oxford Handbook of Health Economics</i>. Oxford University Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_10"></a>Ellis, R.P. 1986. Rational Behavior in the Presence of Coverage Ceilings and Deductibles. <i>Rand Journal of Economics</i> 17 (2): 15875.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_11"></a>Goldin, Jacob, Ithai Z Lurie, and Janet McCubbin. 2020. Health Insurance and Mortality: Experimental Evidence from Taxpayer Outreach. <i>The Quarterly Journal of Economics</i> 136 (1). Oxford University Press (OUP): 149. doi:<a href="https://doi.org/10.1093/qje/qjaa029">10.1093/qje/qjaa029</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_12"></a>Gross, Tal, Timothy Layton, and Daniel Prinz. 2020. The Liquidity Sensitivity of Healthcare Consumption: Evidence from Social Security Payments, October. National Bureau of Economic Research. doi:<a href="https://doi.org/10.3386/w27977">10.3386/w27977</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_13"></a>Huh, Jason, and Julian Reif. 2017. Did Medicare Part D Reduce Mortality? <i>Journal of Health Economics</i> 53 (May). Elsevier BV: 1737. doi:<a href="https://doi.org/10.1016/j.jhealeco.2017.01.005">10.1016/j.jhealeco.2017.01.005</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_14"></a>Keeler, E. B., J. P. Newhouse, and C. E. Phelps. 1977. Deductibles and the Demand for Medical Care Services: The Theory of a Consumer Facing a Variable Price Schedule under Uncertainty. <i>Econometrica</i> 45 (3). [Wiley, Econometric Society]: 64155. <a href="http://www.jstor.org/stable/1911679">http://www.jstor.org/stable/1911679</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_15"></a>Khatana, Sameed Ahmed M., Anjali Bhatla, Ashwin S. Nathan, Jay Giri, Changyu Shen, Dhruv S. Kazi, Robert W. Yeh, and Peter W. Groeneveld. 2019. Association of Medicaid Expansion with Cardiovascular Mortality. <i>Jama Cardiology</i> 4 (7). American Medical Association (AMA): 671. doi:<a href="https://doi.org/10.1001/jamacardio.2019.1651">10.1001/jamacardio.2019.1651</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_16"></a>Kucukelbir, Alp, Dustin Tran, Rajesh Ranganath, Andrew Gelman, and David M. Blei. 2016. Automatic Differentiation Variational Inference.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_17"></a>Mackenbach, Johan P., Irina Stirbu, Albert-Jan R. Roskam, Maartje M. Schaap, Gwenn Menvielle, Mall Leinsalu, and Anton E. Kunst. 2008. Socioeconomic Inequalities in Health in 22 European Countries. <i>New England Journal of Medicine</i> 358 (23). Massachusetts Medical Society: 246881. doi:<a href="https://doi.org/10.1056/nejmsa0707519">10.1056/nejmsa0707519</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_18"></a>McElreath, Richard. 2020. <i>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</i>. Second. Chapman and Hall/CRC.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_19"></a>Miller, Sarah, Norman Johnson, and Laura R Wherry. 2021. Medicaid and Mortality: New Evidence from Linked Survey and Administrative Data. <i>The Quarterly Journal of Economics</i>, January. Oxford University Press (OUP). doi:<a href="https://doi.org/10.1093/qje/qjab004">10.1093/qje/qjab004</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_20"></a>Newhouse, J.P., and the Insurance Experiment Group. 1993. <i>Free for All? Lessons from the RAND Health Insurance Experiment.</i> Cambridge, Massachusetts: Harvard University Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_21"></a>Nyman, J.A. 2003. <i>The Theory of Demand for Health Insurance</i>. Stanford University Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_22"></a>OECD. 2021. <i>Health at a Glance 2021</i>. doi:<a href="https://doi.org/10.1787/ae3016b9-en">10.1787/ae3016b9-en</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_23"></a>Rothschild, M., and J. Stiglitz. 1976. Equilibrium in Competitive Insurance Markets: An Essay on the Economics of Imperfect Information. <i>The Quarterly Journal of Economics</i> 90 (4): 62949.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_24"></a>Schokkaert, Erik, and Carine van de Voorde. 2011. Chapter 15 - User Charges. In <i>Oxford Handbook of Health Economics</i>, edited by S. Glied and P. Smith, 32953. Oxford University Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_25"></a>Semyonov, Moshe, Noah Lewin-Epstein, and Dina Maskileyson. 2013. Where Wealth Matters More for Health: The Wealth-Health Gradient in 16 Countries. <i>Social Science &#38; Medicine</i> 81 (March). Elsevier BV: 1017. doi:<a href="https://doi.org/10.1016/j.socscimed.2013.01.010">10.1016/j.socscimed.2013.01.010</a>.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_26"></a>Swaminathan, Shailender, Benjamin D. Sommers, Rebecca Thorsness, Rajnish Mehrotra, Yoojin Lee, and Amal N. Trivedi. 2018. Association of Medicaid Expansion with 1-Year Mortality among Patients with End-Stage Renal Disease. <i>Jama</i> 320 (21). American Medical Association (AMA): 2242. doi:<a href="https://doi.org/10.1001/jama.2018.16504">10.1001/jama.2018.16504</a>.</div>
</div>



<p>


</p>
</div>
</div>

<div id="outline-container-orgea6a12b" class="outline-2">
<h2 id="orgea6a12b"><span class="section-number-2">9.</span> Proof of results</h2>
<div class="outline-text-2" id="text-9">
<p>
<b>Proof of Lemma <a href="#orgeb785f9">1</a></b>
First, we show that the probability of treatment, \(\delta_i^j = 1-G(\sigma_0/\sigma_i u(y^j)/u(y^j-oop_{i}))\), is increasing in \(y^j\) and decreasing in \(oop_{i}\). Taking the derivative
</p>
\begin{equation}
\label{org5d53b86}
\frac{d \left( \frac{u(y^{j})}{u(y^{j}-oop_{i})} \right)}{dy^j} = \frac{u'(y^{j})u(y^j-oop_{i}) - u(y^{j})u'(y^{j}-oop_{i})}{u(y^j-oop_{i})^2} < 0
\end{equation}
<p>
because \(u\) is positive and increasing in \(y\), \(u'>0\) is decreasing in \(y\) and \(oop_{i} >0\). Hence, the probability of treatment is increasing in income \(y\). Similarly, the treatment probability falls with \(oop\).
</p>

<p>
The expression for mortality follows from equation \eqref{orgae11a42} which we can write as:
</p>
\begin{equation}
\ln(m_{agt}) = \ln({\eta}_{ag}) + \gamma \ln \left( \frac{h_{a-1,g,t-1}}{\bar g_{a-1,g}}\right)- (1-\pi^h)-\pi^h \sum_{i \in I} \zeta_i + \alpha (\pi^l-\pi^h)(1-\sum_{i \in I} \zeta_i) \sigma_0
 \end{equation}
\begin{equation*}
+ \sum_{i \in I} \zeta_i (\sigma_i-\sigma_0) (\alpha \pi^l (1-\delta_i^l) + (1-\alpha) \pi^h (1-\delta_i^h))
\end{equation*}
<p>
We capture \({\eta}_{ag}\) with a sigmoid of age and gender fixed effects, \(\beta_{ag}\). The NUTS 2 fixed effects capture \((1-\pi^h)+\pi^h \sum_{i \in I} \zeta_i\). As \(\alpha\) denotes poverty, we have
</p>
\begin{equation}
\beta_{poverty} = (\pi^l-\pi^h)(1-\sum_{i \in I} \zeta_i) \sigma_0 > 0
\end{equation}
<p>
With the expression for <code>Unmet</code> in equation \eqref{orgd543365}, we find that
</p>
\begin{equation}
\beta_{unmet} = \frac{\sum_{i \in I} \zeta_i (\sigma_i-\sigma_0) (\alpha \pi^l (1-\delta_i^l) + (1-\alpha) \pi^h (1-\delta_i^h))}{\sum_{i \in I} \zeta_i (\alpha \pi^l (1-\delta_i^l) + (1-\alpha) \pi^h (1-\delta_i^h))}
\end{equation}
<p>
which is a weighted average of the \(\sigma_i-\sigma_0>0\) terms: if the medical needs were met, health would equal \(\sigma_i\) but for this group it is \(\sigma_0 < \sigma_{i}\). Hence, \(\beta_{unmet} = E(\sigma_i-\sigma_0)>0\).
</p>

<p>
Finally, we derive how the fraction of people that forgo treatment because it is too expensive depends on <code>OOP</code>. We first derive this for an increase in \(D\). We start from
</p>
\begin{equation}
\label{org1c4c24d}
\frac{d \text{TooExp}}{d \text{OOP}} = \frac{d \text{TooExp}}{dD} \left( \frac{d \text{OOP}}{d D}
  \right)^{-1} = \frac{d \text{TooExp}}{dD} \frac{\sum_{i \in I} \zeta_i x_i \delta_i}{\sum_{i \in I_D} \zeta_i \delta_i}
\end{equation}
<p>
where we use that in Europe oop payments tend to be small relative to yearly income and hence we use the approximation that \(\delta^j_i\) is constant across \(j\), \(\delta^{j}_i \approx \delta_{i}\):
</p>
\begin{equation}
\label{org7a76c3a}
\text{OOP} = \frac{\sum_{i \in I_{\xi}} \zeta_i \xi x_i \delta_i+ \sum_{i \in I_D} \zeta_i D \delta_i}{\sum_{i \in I} \zeta_i x_i \delta_i}
\end{equation}

<p>
Further, equation \eqref{org040d6f1} implies we can approximate the slope of <code>TooExp</code> with respect to \(D\) around 0 as:
</p>
\begin{equation}
\label{org64bf70f}
\frac{d \text{TooExp}}{d D} = \sum_{i \in I_D} \zeta_i \left( \alpha \pi^l g^l_i \frac{\sigma_{0}}{\sigma_{i}} \frac{u'(y^{l})}{u(y^{l})} + (1-\alpha) \pi^h g_i^h \frac{\sigma_{0}}{\sigma_{i}} \frac{u'(y^{h})}{u(y^h)}
\right)
\end{equation}
<p>
where we use notation \(g_{i}^j = g(\sigma_0/\sigma_i * u(y^j)/u(y^j-D))\) for \(i \in I_{D}\). Again using the approximation that \(y^{j}\) is big compared to \(D\), we have that \(g_i^j=g_i\):
</p>
\begin{equation}
\frac{d \text{TooExp}}{d D} = \sum_{i \in I_D} \zeta_i g_i \frac{\sigma_0}{\sigma_i} \left[ \pi^h \frac{u'(y^{h})}{u(y^h)} + \alpha \left( \pi^l \frac{u'(y^{l})}{u(y^l)}- \pi^h \frac{u'(y^{h})}{u(y^h)}  \right)
\right]
\end{equation}
<p>
where \(\left( \pi^l \frac{u'(y^{l})}{u(y^l)}- \pi^h \frac{u'(y^{h})}{u(y^h)}  \right) > 0\) because \(\pi^l > \pi^h, u'(y^{l}) > u'(y^h)\) and \(u(y^l) < u(y^h)\). A similar derivation shows
</p>
\begin{equation}
\frac{d \text{TooExp}}{d \xi} = \sum_{i \in I_\xi} \zeta_i x_i g_i \frac{\sigma_0}{\sigma_i} \left[ \pi^h \frac{u'(y^{h})}{u(y^h)} + \alpha \left( \pi^l \frac{u'(y^{l})}{u(y^l)}- \pi^h \frac{u'(y^{h})}{u(y^h)}  \right)
\right]
\end{equation}
<p>
Using equation \eqref{org1c4c24d}, we find that
</p>
\begin{equation}
\label{org00b345f}
\frac{d \text{TooExp}}{d \text{OOP}} =\left[ \pi^h \frac{u'(y^{h})}{u(y^h)} + \alpha \left( \pi^l \frac{u'(y^{l})}{u(y^l)}- \pi^h \frac{u'(y^{h})}{u(y^h)}  \right)
\right]  \sum_{i \in I_D} \zeta_i g_i \frac{\sigma_0}{\sigma_i}
\frac{\sum_{i \in I} \zeta_i x_i \delta_{i}}{\sum_{i \in I_D} \zeta_i \delta_i}
\end{equation}
<p>
And, similarly, for \(\xi\):
</p>
\begin{equation}
\frac{d \text{TooExp}}{d \text{OOP}} =\left[ \pi^h \frac{u'(y^{h})}{u(y^h)} + \alpha \left( \pi^l \frac{u'(y^{l})}{u(y^l)}- \pi^h \frac{u'(y^{h})}{u(y^h)}  \right)
\right]  \sum_{i \in I_\xi} \zeta_i x_{i} g_i \frac{\sigma_0}{\sigma_i}
\frac{\sum_{i \in I} \zeta_i x_i \delta_i}{\sum_{i \in I_\xi} \zeta_i \delta_i x_i}
\end{equation}
<p>
Using that \(\delta_i = 1-G_i\), we can write the last term in \eqref{org00b345f} as:
</p>
\begin{equation}
\sum_{i \in I_D} \zeta_i g_i \frac{\sigma_0}{\sigma_i}
\frac{\sum_{i \in I} \zeta_i x_i \delta_{i}}{\sum_{i \in I_D} \zeta_i \delta_i}
= \left(\sum_{i \in I} \zeta_i x_i \delta_i\right) \sum_{i \in I_{D}} \frac{\zeta_i \delta_i}{\sum_{i \in I_D} \zeta_i \delta_i} \frac{g_i \frac{\sigma_0}{\sigma_i}}{1-G_i} = \left(\sum_{i \in I} \zeta_i x_i \delta_i\right) \kappa
\end{equation}
<p>
where \(\kappa > 0\) denotes the parameter of the Pareto distribution:
</p>
\begin{equation}
1-G(\nu) = \left( \underline \nu/{\nu} \right)^{\kappa}
\end{equation}
<p>
if \(\nu \geq \underline \nu\) and 1 other wise. With this distribution we have \(g(\nu)\nu/(1-G(\nu)) = \kappa\) for each \(\nu > \underline \nu\). It is routine to verify that we get the same expression for the expansion with respect to \(\xi\). If we assume that \(G(\nu)\) denotes the cumulative distribution function of a Pareto distribution, the linear expansion that we use below is exact. Otherwise, it is an approximation as \(\kappa\) is a function of \(\delta_i\) and hence of \(\xi\) and \(D\).
</p>

<p>
Hence, irrespective of whether we expand with respect to \(D\) or \(\xi\), we find that
</p>
\begin{equation}
\frac{d \text{TooExp}}{d \text{OOP}} = \kappa \left[ \pi^h \frac{u'(y^{h})}{u(y^h)} + \alpha \left( \pi^l \frac{u'(y^{l})}{u(y^l)}- \pi^h \frac{u'(y^{h})}{u(y^h)}  \right)
\right] \sum_{i \in I} \zeta_i x_i \delta_i
\end{equation}
<p>
where we capture \(\sum_{i \in I} \zeta_i x_i \delta_i\) with expenditure per head in our data.
</p>

<p>
Using this, we estimate the following linear expansion \(\text{TooExp} = b_0 + \frac{d \text{TooExp}}{d \text{OOP}} \text{OOP}\):
</p>
\begin{equation}
\label{org4f98306}
\text{TooExp}_{2t} = b_{0,2} + b_{0,t} +  \text{OOP}_{ct} \bar x_{ct} \left( b_{oop,c}+ b_{interaction,c} \text{Poverty}_{2t} \right)
\end{equation}
<p>
where
</p>
\begin{equation}
b_{oop,c} = \kappa \pi^h u'(y^h)/u(y^h) >0
\end{equation}
<p>
and
</p>
\begin{equation}
b_{interaction,c} = \kappa \left( \pi^l \frac{u'(y^{l})}{u(y^l)}- \pi^h \frac{u'(y^{h})}{u(y^h)}  \right) > 0
\end{equation}
<p>
As it is hard to know what determines the intercept for this linear expansion, we allow it to vary with NUTS 2 region and calendar year: \(b_0 = b_{0,2} + b_{0,t}\). Finally, to facilitate the estimation of this equation we assume that <code>TooExp</code> has a logit-normal distribution. That is, the log-odds of <code>TooExp</code> is normally distributed with the mean given by equation \eqref{org4f98306}. This ensures that <code>TooExp</code> in the estimation always lies between 0 and 1.
</p>

<p>
 <p style="text-align:right"></p>

</p>
</div>
</div>


<div id="outline-container-org4b0354e" class="outline-2">
<h2 id="org4b0354e"><span class="section-number-2">10.</span> Data</h2>
<div class="outline-text-2" id="text-10">
<p>
All our variables come from Eurostat. Table <a href="#org06208ba">5</a> shows the dimensions over which our variables vary: country, NUTS 2, calendar time, age and sex. We also present a clickable link to the variable on the Eurostat website for ease of reference. The file <a href="./getting_data.html">./getting_data.html</a> presents the code to download the Eurostat data.<sup><a id="fnr.12" class="footref" href="#fn.12" role="doc-backlink">12</a></sup>
</p>


<table id="org06208ba" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 5:</span> Variables and the dimensions over which they vary.</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">variable</th>
<th scope="col" class="org-left">country</th>
<th scope="col" class="org-left">NUTS 2</th>
<th scope="col" class="org-left">time</th>
<th scope="col" class="org-left">age</th>
<th scope="col" class="org-left">sex</th>
<th scope="col" class="org-left">reference</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">population</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/DEMO_R_D2JAN/default/table?lang=en&amp;category=demo.demopreg">link</a></td>
</tr>

<tr>
<td class="org-left">deaths</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/DEMO_R_MAGEC/default/table?lang=en&amp;category=demo.demomreg">link</a></td>
</tr>

<tr>
<td class="org-left">at-risk-of-poverty</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/tgs00103/default/table?lang=en">link</a></td>
</tr>

<tr>
<td class="org-left">material deprivation</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/tgs00104/default/table?lang=en">link</a></td>
</tr>

<tr>
<td class="org-left">fraction too expensive</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/hlth_silc_08_r/default/table?lang=en">link</a></td>
</tr>

<tr>
<td class="org-left">unmet</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/hlth_silc_08_r/default/table?lang=en">link</a></td>
</tr>

<tr>
<td class="org-left">out-of-pocket</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/hlth_sha11_hf/default/table?lang=en">link</a></td>
</tr>

<tr>
<td class="org-left">voluntary</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/hlth_sha11_hf/default/table?lang=en">link</a></td>
</tr>

<tr>
<td class="org-left">expenditure per head</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">x</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left"><a href="https://ec.europa.eu/eurostat/databrowser/view/hlth_sha11_hc/default/table?lang=en">link</a></td>
</tr>
</tbody>
</table>



<p>
The variables on poverty, deprivation and access to care (unmet and too expensive) come from the <a href="https://ec.europa.eu/eurostat/statistics-explained/index.php?title=EU_statistics_on_income_and_living_conditions_(EU-SILC)_methodology">EU statistics on income and living conditions (EU-SILC)</a> survey.
</p>

<p>
From the <a href="https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:At-risk-of-poverty_rate">Eurostat Glossary:</a> "The at-risk-of-poverty rate is the share of people with an equivalised disposable income (after social transfers) below the at-risk-of-poverty threshold, which is set at 60 % of the national median equivalised disposable income after social transfers. This indicator does not measure wealth or poverty, but low income in comparison to other residents in that country, which does not necessarily imply a low standard of living. The equivalised disposable income is the total income of a household, after tax and other deductions, that is available for spending or saving, divided by the number of household members converted into equalised adults; household members are equalised or made equivalent by weighting each according to their age, using the so-called modified OECD equivalence scale."
</p>

<p>
"<a href="https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Material_deprivation">Material deprivation</a> refers to a state of economic strain and durables, defined as the enforced inability (rather than the choice not to do so) to pay unexpected expenses, afford a one-week annual holiday away from home, a meal involving meat, chicken or fish every second day, the adequate heating of a dwelling, durable goods like a washing machine, colour television, telephone or car, being confronted with payment arrears (mortgage or rent, utility bills, hire purchase instalments or other loan payments)." Our variable "material deprivation" equals the share of people in a NUTS 2 region in material deprivation.
</p>

<p>
Fraction of people with self-reported unmet needs for medical examination is based on the same survey. In particular, the definition of this item is "Self-reported unmet needs for health care: Proportion of people in need of health care reporting to have experienced delay in getting health care in the previous 12 months for reasons of financial barriers, long waiting lists, distance or transportation problems.". We use both the general definition of unmet needs and the specific reason that treatment was too expensive.
</p>

<p>
We characterize how generous a health insurance system is using the variable <code>OOP</code> in our analysis. This variable is derived from data on health care expenditure by financing scheme. For our <code>OOP</code> measure we focus on voluntary healthcare payment schemes (<code>voluntary</code>) and household out-of-pocket payment (<code>out-of-pocket</code>). Both measured as share of total current health expenditure. The baseline specification uses <code>out-of-pocket</code> only.
</p>

<p>
Expenditure per head refers to healthcare expenditure per head at the country level.
</p>
</div>
</div>

<div id="outline-container-org11eafba" class="outline-2">
<h2 id="org11eafba"><span class="section-number-2">11.</span> Estimation</h2>
<div class="outline-text-2" id="text-11">
<p>
This section presents the trace plots for the baseline model, the table with the relevant coefficients and the derivation of the change in mortality as a function of the change in oop.
</p>
</div>

<div id="outline-container-org1025c52" class="outline-3">
<h3 id="org1025c52"><span class="section-number-3">11.1.</span> trace plots</h3>
<div class="outline-text-3" id="text-11-1">
<p>
Figure <a href="#orgd05479e">9</a> gives the trace plots for the parameters that we are interested in. That is, we leave out the traces for the (age, calendar year and region) fixed effects.
</p>

<p>
As explained in the main text, we are interested in three features in the plots on the right. First, the plots are stationary; second, condensed zig-zagging and third, the four chains cover the same regions of the parameter space.
</p>


<div id="orgd05479e" class="figure">
<p><img src="./figures/trace_plot_baseline.png" alt="trace_plot_baseline.png" />
</p>
<p><span class="figure-number">Figure 9: </span>Trace plots of the coefficients of interest</p>
</div>
</div>
</div>


<div id="outline-container-org816174e" class="outline-3">
<h3 id="org816174e"><span class="section-number-3">11.2.</span> table of coefficients baseline model</h3>
<div class="outline-text-3" id="text-11-2">
<p>
Table <a href="#orgfaa2c26">6</a> provides summary statistics for the posteriors of the coefficients we are interested in. For some countries the <code>hdi_3%</code> lower bound for the <code>b_oop</code> or <code>b_interaction</code> equals zero. This is compatible with the <code>OOP</code> effect on mortality being bounded away from zero as the coefficients can be correlated: say, low <code>b_oop</code> going together with high <code>b_interaction</code> leading to an overall strictly positive effect.
</p>

<p>
Hence, to understand the mortality effects of an increase in oop, we use equation \eqref{org28669b2} with the posterior distributions substituted in for all the parameters. This gives us Figure <a href="#orgeff8d5d">2</a>.
</p>



<table id="orgfaa2c26" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 6:</span> Summary statictics for estimated coefficients</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">mean</th>
<th scope="col" class="org-right">sd</th>
<th scope="col" class="org-right">hdi_3%</th>
<th scope="col" class="org-right">hdi_97%</th>
<th scope="col" class="org-right">ess_bulk</th>
<th scope="col" class="org-right">r_hat</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">beta_unmet</td>
<td class="org-right">0.09</td>
<td class="org-right">0.02</td>
<td class="org-right">0.06</td>
<td class="org-right">0.13</td>
<td class="org-right">2507.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">beta_lagged_log_mortality</td>
<td class="org-right">0.54</td>
<td class="org-right">0.00</td>
<td class="org-right">0.53</td>
<td class="org-right">0.54</td>
<td class="org-right">2535.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">beta_poverty</td>
<td class="org-right">0.01</td>
<td class="org-right">0.01</td>
<td class="org-right">0.00</td>
<td class="org-right">0.01</td>
<td class="org-right">2840.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Bulgaria]</td>
<td class="org-right">0.83</td>
<td class="org-right">0.64</td>
<td class="org-right">0.00</td>
<td class="org-right">2.00</td>
<td class="org-right">1230.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Croatia]</td>
<td class="org-right">1.91</td>
<td class="org-right">1.50</td>
<td class="org-right">0.00</td>
<td class="org-right">4.60</td>
<td class="org-right">1245.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Denmark]</td>
<td class="org-right">2.54</td>
<td class="org-right">0.52</td>
<td class="org-right">1.57</td>
<td class="org-right">3.54</td>
<td class="org-right">855.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Finland]</td>
<td class="org-right">0.04</td>
<td class="org-right">0.04</td>
<td class="org-right">0.00</td>
<td class="org-right">0.11</td>
<td class="org-right">3337.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Greece]</td>
<td class="org-right">20.01</td>
<td class="org-right">0.64</td>
<td class="org-right">18.77</td>
<td class="org-right">21.14</td>
<td class="org-right">928.00</td>
<td class="org-right">1.01</td>
</tr>

<tr>
<td class="org-left">b_oop[Hungary]</td>
<td class="org-right">0.12</td>
<td class="org-right">0.12</td>
<td class="org-right">0.00</td>
<td class="org-right">0.34</td>
<td class="org-right">2260.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Ireland]</td>
<td class="org-right">6.64</td>
<td class="org-right">0.85</td>
<td class="org-right">4.90</td>
<td class="org-right">8.11</td>
<td class="org-right">1264.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Lithuania]</td>
<td class="org-right">3.44</td>
<td class="org-right">1.49</td>
<td class="org-right">0.62</td>
<td class="org-right">6.07</td>
<td class="org-right">1811.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Norway]</td>
<td class="org-right">0.03</td>
<td class="org-right">0.03</td>
<td class="org-right">0.00</td>
<td class="org-right">0.07</td>
<td class="org-right">3025.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Romania]</td>
<td class="org-right">13.61</td>
<td class="org-right">1.70</td>
<td class="org-right">10.36</td>
<td class="org-right">16.65</td>
<td class="org-right">1041.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Slovakia]</td>
<td class="org-right">1.90</td>
<td class="org-right">1.10</td>
<td class="org-right">0.00</td>
<td class="org-right">3.75</td>
<td class="org-right">757.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Slovenia]</td>
<td class="org-right">0.33</td>
<td class="org-right">0.31</td>
<td class="org-right">0.00</td>
<td class="org-right">0.91</td>
<td class="org-right">2474.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Sweden]</td>
<td class="org-right">0.48</td>
<td class="org-right">0.27</td>
<td class="org-right">0.00</td>
<td class="org-right">0.94</td>
<td class="org-right">539.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_oop[Switzerland]</td>
<td class="org-right">0.02</td>
<td class="org-right">0.02</td>
<td class="org-right">0.00</td>
<td class="org-right">0.06</td>
<td class="org-right">2059.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Bulgaria]</td>
<td class="org-right">27.49</td>
<td class="org-right">2.05</td>
<td class="org-right">23.74</td>
<td class="org-right">31.33</td>
<td class="org-right">1695.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Croatia]</td>
<td class="org-right">2.45</td>
<td class="org-right">1.88</td>
<td class="org-right">0.00</td>
<td class="org-right">5.88</td>
<td class="org-right">1535.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Denmark]</td>
<td class="org-right">36.41</td>
<td class="org-right">3.16</td>
<td class="org-right">30.67</td>
<td class="org-right">42.50</td>
<td class="org-right">2411.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Finland]</td>
<td class="org-right">0.71</td>
<td class="org-right">0.68</td>
<td class="org-right">0.00</td>
<td class="org-right">1.93</td>
<td class="org-right">2556.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Greece]</td>
<td class="org-right">3.80</td>
<td class="org-right">2.32</td>
<td class="org-right">0.01</td>
<td class="org-right">7.75</td>
<td class="org-right">1226.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Hungary]</td>
<td class="org-right">56.73</td>
<td class="org-right">2.68</td>
<td class="org-right">51.98</td>
<td class="org-right">61.99</td>
<td class="org-right">1006.00</td>
<td class="org-right">1.01</td>
</tr>

<tr>
<td class="org-left">b_interaction[Ireland]</td>
<td class="org-right">3.08</td>
<td class="org-right">2.17</td>
<td class="org-right">0.00</td>
<td class="org-right">6.93</td>
<td class="org-right">2799.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Lithuania]</td>
<td class="org-right">2.70</td>
<td class="org-right">1.96</td>
<td class="org-right">0.00</td>
<td class="org-right">6.11</td>
<td class="org-right">1987.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Norway]</td>
<td class="org-right">25.39</td>
<td class="org-right">2.90</td>
<td class="org-right">20.18</td>
<td class="org-right">30.88</td>
<td class="org-right">1989.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Romania]</td>
<td class="org-right">18.73</td>
<td class="org-right">2.95</td>
<td class="org-right">13.12</td>
<td class="org-right">24.03</td>
<td class="org-right">2239.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Slovakia]</td>
<td class="org-right">1.23</td>
<td class="org-right">1.08</td>
<td class="org-right">0.00</td>
<td class="org-right">3.24</td>
<td class="org-right">2618.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Slovenia]</td>
<td class="org-right">2.08</td>
<td class="org-right">1.62</td>
<td class="org-right">0.01</td>
<td class="org-right">5.05</td>
<td class="org-right">2362.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Sweden]</td>
<td class="org-right">10.35</td>
<td class="org-right">2.81</td>
<td class="org-right">5.01</td>
<td class="org-right">15.45</td>
<td class="org-right">1722.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">b_interaction[Switzerland]</td>
<td class="org-right">22.36</td>
<td class="org-right">1.70</td>
<td class="org-right">19.20</td>
<td class="org-right">25.55</td>
<td class="org-right">1927.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">sd_prior_b</td>
<td class="org-right">2.94</td>
<td class="org-right">0.08</td>
<td class="org-right">2.79</td>
<td class="org-right">3.08</td>
<td class="org-right">1391.00</td>
<td class="org-right">1.00</td>
</tr>

<tr>
<td class="org-left">sd_prior_beta</td>
<td class="org-right">0.22</td>
<td class="org-right">0.04</td>
<td class="org-right">0.14</td>
<td class="org-right">0.31</td>
<td class="org-right">3505.00</td>
<td class="org-right">1.00</td>
</tr>
</tbody>
</table>
</div>
</div>


<div id="outline-container-orgadf9726" class="outline-3">
<h3 id="orgadf9726"><span class="section-number-3">11.3.</span> derivation of the effect of oop on mortality</h3>
<div class="outline-text-3" id="text-11-3">
<p>
As we assume that <code>TooExp</code> has a logit-normal distribution, the derivative of the expression in Lemma <a href="#orgeb785f9">1</a> with respect to \(OOP \bar{x}\) is given by
</p>
\begin{equation}
\frac{dTooExp}{d(OOP \bar{x})} = TooExp(1-TooExp) (b_{oop,c} + b_{interaction,c} Poverty_{2t})
\end{equation}
<p>
In the simulation we work with a 500 euro increase in oop: \(d(OOP \bar{x})=500\). That is, we multiply the fraction of healthcare expenditure paid oop with average healthcare expenditure per head. This gives us oop in euro terms. We assume that the increase in <code>TooExp</code> translates one-for-one in an increase in <code>Unmet</code>. Hence, the change in mortality is given by:
</p>
\begin{equation}
\label{orgda13003}
\frac{dm_{ga2t}}{m_{ga2t}} = \beta_{unmet} TooExp(1-TooExp) 500 (b_{oop,c} + b_{interaction,c} Poverty_{2t})
\end{equation}
<p>
This is the increase in deaths per one dead. In Figure <a href="#orgeff8d5d">2</a> we multiply this expression by 1000: number of deaths per 1000 dead.
</p>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">This does not imply that the aggregate statistics perfectly represent everyone's insurance situation (e.g. some people may buy complementary insurance where others do not), but it may be representative enough to identify the interaction effect of poverty and oop payments we are interested in.</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">See the github repository: <a href="https://github.com/janboone/out_of_pocket_payments_and_health">https://github.com/janboone/out_of_pocket_payments_and_health</a>.</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">A further simplification is that we do not analyze dynamic incentives like: accepting this treatment fills up my deductible which makes future treatment (weakly) cheaper for me.</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4" role="doc-backlink">4</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">See question 12 in <a href="https://qdd.oecd.org/data/HSC">https://qdd.oecd.org/data/HSC</a> specifying for most European countries a spending cap.</p></div></div>

<div class="footdef"><sup><a id="fn.5" class="footnum" href="#fnr.5" role="doc-backlink">5</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">To ease notation we do not let \(\sigma_0\) vary with \(i\).</p></div></div>

<div class="footdef"><sup><a id="fn.6" class="footnum" href="#fnr.6" role="doc-backlink">6</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">Note that we do not model the decision to buy insurance. In Europe (almost) all citizens are covered by automatic or mandatory insurance.</p></div></div>

<div class="footdef"><sup><a id="fn.7" class="footnum" href="#fnr.7" role="doc-backlink">7</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">Although we think of \(\gamma>0\), we allow for \(\gamma<0\). The interpretation in the latter case would be that some people with low health status in cohort \(a-1\) passed away early, increasing average health for people remaining in this cohort.</p></div></div>

<div class="footdef"><sup><a id="fn.8" class="footnum" href="#fnr.8" role="doc-backlink">8</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">A rough estimate of the max. number of observations that we could have is: 78 (regions) \(*\) 10 (years) \(*\) 50 (ages) \(*\) 2 (genders) \(=78k\). Missing observations on some of the key variables reduces this to 50k.</p></div></div>

<div class="footdef"><sup><a id="fn.9" class="footnum" href="#fnr.9" role="doc-backlink">9</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">In this sense, the observation in Table <a href="#org4542675">1</a> that in some countries expenditure per head is below 500 euro is not a problem here.</p></div></div>

<div class="footdef"><sup><a id="fn.10" class="footnum" href="#fnr.10" role="doc-backlink">10</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">Note that we use here that <code>TooExp</code> is smaller than 0.5: \(d(x(1-x))/dx = 1-2x >0\) for \(x<0.5\). As Table <a href="#orgd77a371">2</a> shows, <code>TooExp</code> is indeed below 0.5 in our data.</p></div></div>

<div class="footdef"><sup><a id="fn.11" class="footnum" href="#fnr.11" role="doc-backlink">11</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">We use the icd-10 classification here.</p></div></div>

<div class="footdef"><sup><a id="fn.12" class="footnum" href="#fnr.12" role="doc-backlink">12</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">This file can be found in the github repository: <a href="https://github.com/janboone/out_of_pocket_payments_and_health">https://github.com/janboone/out_of_pocket_payments_and_health</a>.</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Jan Boone</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
